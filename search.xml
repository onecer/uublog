<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[python装饰器]]></title>
    <url>%2Farticle%2F20180924%2Fpython-decorator%2F</url>
    <content type="text"><![CDATA[个人觉得装饰器就是Python对闭包的一种的语法糖。 可以灵活抽离出一些雷同代码，通过装饰器方便地调用，使得程序更加简单专注于逻辑的处理。 例子： 1234567891011121314151617def check_data(func): def check(*args, **kwargs): print('in decorator') print(args) print(kwargs) func(*args, **kwargs) return check@check_datadef echo_name(name): print(name)echo_name(name='jack')print('--------')echo_name(name='bob') 结果 123456789in decorator()&#123;&apos;name&apos;: &apos;jack&apos;&#125;jack--------in decorator(&apos;bob&apos;,)&#123;&#125;bob]]></content>
      <categories>
        <category>python</category>
        <category>foundation</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>decorator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用nginx-upsync-module同步consul服务到nginx upstream]]></title>
    <url>%2Farticle%2F20180814%2Fnginx-upsync-module-sync-consul-service%2F</url>
    <content type="text"><![CDATA[用&lt;Centos7配置LNMP nginx10+mariadb+php5.6&gt;安装nginx后, 是没有nginx-upsync-module的.如此一来可能还不如直接编译安装, 但是这样安装好处在于,可以方便使用systemtl来管理nginx,不需要自己去添加服务,懒人必备. 然后再找同样版本的nginx,编译安装一遍,加进自己的模块. 安装编译工具全家桶 yum groupinstall &#39;Development Tools&#39; 下载源码 123wget http://nginx.org/download/nginx-1.12.1.tar.gztar -zxvf nginx-1.12.1.tar.gzgit clone https://github.com/weibocom/nginx-upsync-module.git 安装编译依赖组件yum install -y zlib zlib-devel openssl openssl-devel pcre pcre-devel 编译nginx 123cd nginx-1.12.1./configure --add-module=../nginx-upsync-modulemake &amp;&amp; make install 注意路径,我这里安装好后,路径是/usr/local/nginx/ 添加软连接到常用路径ln -s /usr/local/nginx/sbin/nginx /usr/sbin/nginx 添加服务文件:vim /usr/lib/systemd/system/nginx 服务描述文件里面 /run/nginx.pid 一定要和 nginx.conf 地址对应上.不然启动获取不到pid. 123456789101112131415[Unit]Description=The NGINX HTTP and reverse proxy serverAfter=syslog.target network.target remote-fs.target nss-lookup.target[Service]Type=forkingPIDFile=/run/nginx.pidExecStartPre=/usr/sbin/nginx -tExecStart=/usr/sbin/nginxExecReload=/usr/sbin/nginx -s reloadExecStop=/bin/kill -s QUIT $MAINPIDPrivateTmp=true[Install]WantedBy=multi-user.target 添加nginx配置 运行nginx systemctrl enable/start nginx 123456789101112131415161718 upstream illstrator-plus-web &#123; server 127.0.0.1:11111; upsync 127.0.0.1:8500/v1/health/service/illstrator-plus-web upsync_timeout=6m upsync_interval=500ms upsync_type=consul_health strong_dependency=off; upsync_dump_path /usr/local/nginx/conf/servers/servers_illstrator-plus-web.conf; &#125;server &#123; listen 80; server_name xxx.com; location / &#123; proxy_pass http://illstrator-plus-web/; proxy_read_timeout 300s; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125; 发现行不通,服务我是部署在docker swarm里面的.我获取的服务数据是这样的.[ServiceAddress]里面注册的是内网IP 1234567891011121314151617181920212223242526272829303132[ &#123; "ID": "ce711dca-f8fb-f1c3-4043-66a08040255e", "Node": "node1", "Address": "172.31.93.37", "Datacenter": "dc1", "TaggedAddresses": &#123; "lan": "172.31.93.37", "wan": "172.31.93.37" &#125;, "NodeMeta": &#123; "consul-network-segment": "" &#125;, "ServiceKind": "", "ServiceID": "chahuashi:illstrator-plus-web.1.8gjsduc64vor8runu9dw31m4k:8816", "ServiceName": "illstrator-plus-web", "ServiceTags": [], "ServiceAddress": "10.0.0.15", "ServiceMeta": &#123; "port": "8816" &#125;, "ServicePort": 8816, "ServiceEnableTagOverride": false, "ServiceProxyDestination": "", "ServiceConnect": &#123; "Native": false, "Proxy": null &#125;, "CreateIndex": 41480, "ModifyIndex": 41480 &#125;] 现在有几条路走. Fork nginx-upsync-module 的源码 修改 ngx_http_upsync_consul_health_parse_json(void *data) 函数的处理,让它返回node的Address 摒弃全自动,手动添加节点信息到Consul KV 别用这种方式了,直接添加nginx节点. nginx装集群内 我选了第二种方法.主要是第一种的话,固然方便点,但是最终还是走routing mesh,性能没有提升. 第四种麻烦,第三种增加服务会中断服务才能更新. 修改nginx配置 123456upstream illstrator-plus-web &#123; server 127.0.0.1:11111; # upsync 127.0.0.1:8500/v1/health/service/illstrator-plus-web upsync_timeout=6m upsync_interval=500ms upsync_type=consul_health strong_dependency=off; upsync 127.0.0.1:8500/v1/kv/upstreams/illstrator-plus-web upsync_timeout=6m upsync_interval=500ms upsync_type=consul strong_dependency=off; upsync_dump_path /usr/local/nginx/conf/servers/servers_illstrator-plus-web.conf;&#125; 然后将节点信息添加到 consul 1curl -X PUT http://47.52.20.113:8500/v1/kv/upstreams/illstrator-plus-web/172.31.93.37:8816 参考资料 CentOS 7.2安装Nginx 1.10.2 nginx-upsync-module Github]]></content>
      <categories>
        <category>microservice</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>consul</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Swarm Mode中容器多网络多IP registrator注册服务IP的问题]]></title>
    <url>%2Farticle%2F20180812%2Fdocker-swarm-mode-registrator-problem-with-multi-network%2F</url>
    <content type="text"><![CDATA[问题描述在这篇文章《Docker Swarm Mode中部署SpringCloud微服务》之后 遇到了点新问题。 在运行时指定自己网络的时候，容器里面多个网络，多个IP，但是注册的不是固定注册某个网卡的IP作为服务IP。 这就导致有时候注册的IP不是属于overlay网络的IP。服务访问就会出现问题。 如果是用rencher部署的话，它有一个label记录了容器IP。可以用registrator的-useIpFromLabel读取它label。而docker swarm并没有记录相关IP到label 也就不能用这个参数。 所以我fork了registrator的最新源码，做了点修改。让它支持可以传入在运行docker时，attach的network名字，根据这个网络名字在它container信息中取得它IP。 如我前面运行docker的服务的时候指定--network=micro-service 那么我运行registrator的时候，用我修改过的镜像doubleshit/registrator:v7指定-useIpFromNetworkName=micro-service参数即可。 如： 1234567891011docker run -d \ --restart=always \ --name=registrator \ --net=host \ --volume=/var/run/docker.sock:/tmp/docker.sock \ doubleshit/registrator:v7 \ -cleanup \ -internal \ -ip &lt;NODE_IP&gt; \ -useIpFromNetworkName=micro-service \ consul://&lt;NODE_IP&gt;:8500 修改后的源码：https://github.com/onecer/registrator commit的时候信息network写成了netword无视就好 哈哈]]></content>
      <categories>
        <category>microservice</category>
      </categories>
      <tags>
        <tag>registrator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins Docker插件故障 JSONException]]></title>
    <url>%2Farticle%2F20180812%2Ftroubleshooting-jenkins-json-expection%2F</url>
    <content type="text"><![CDATA[有同志容器的日志写到了自己容器里面。但是出问题后，一直写，导致磁盘写满。 以上是问题出现的前奏。 我接着清理下无用的容器，先快速释放部分空间出来。 1docker system prune -a 紧接着我就出去帮忙别的东西了。 过一会被告知，Jenkins构建失败，而不止一个项目。每个项目出错如下： 123456789101112131415161718192021222324252627282930ERROR: Build step failed with exceptionnet.sf.json.JSONException: A JSONObject text must begin with '&#123;' at character 0 of at net.sf.json.util.JSONTokener.syntaxError(JSONTokener.java:499) at net.sf.json.JSONObject._fromJSONTokener(JSONObject.java:919) at net.sf.json.JSONObject._fromString(JSONObject.java:1145) at net.sf.json.JSONObject.fromObject(JSONObject.java:162) at net.sf.json.JSONObject.fromObject(JSONObject.java:132) at org.jenkinsci.plugins.docker.commons.credentials.DockerRegistryToken$1.call(DockerRegistryToken.java:102) at org.jenkinsci.plugins.docker.commons.credentials.DockerRegistryToken$1.call(DockerRegistryToken.java:82) at hudson.remoting.LocalChannel.call(LocalChannel.java:45) at org.jenkinsci.plugins.docker.commons.credentials.DockerRegistryToken.newKeyMaterialFactory(DockerRegistryToken.java:82) at org.jenkinsci.plugins.docker.commons.credentials.DockerRegistryEndpoint.newKeyMaterialFactory(DockerRegistryEndpoint.java:219) at org.jenkinsci.plugins.docker.commons.credentials.DockerRegistryEndpoint.newKeyMaterialFactory(DockerRegistryEndpoint.java:204) at org.jenkinsci.plugins.docker.commons.credentials.DockerRegistryEndpoint.newKeyMaterialFactory(DockerRegistryEndpoint.java:196) at com.cloudbees.dockerpublish.DockerBuilder$Perform.executeCmd(DockerBuilder.java:455) at com.cloudbees.dockerpublish.DockerBuilder$Perform.executeCmd(DockerBuilder.java:431) at com.cloudbees.dockerpublish.DockerBuilder$Perform.buildAndTag(DockerBuilder.java:373) at com.cloudbees.dockerpublish.DockerBuilder$Perform.exec(DockerBuilder.java:311) at com.cloudbees.dockerpublish.DockerBuilder$Perform.access$100(DockerBuilder.java:291) at com.cloudbees.dockerpublish.DockerBuilder.perform(DockerBuilder.java:262) at hudson.tasks.BuildStepMonitor$1.perform(BuildStepMonitor.java:20) at hudson.model.AbstractBuild$AbstractBuildExecution.perform(AbstractBuild.java:744) at hudson.maven.MavenModuleSetBuild$MavenModuleSetBuildExecution.build(MavenModuleSetBuild.java:945) at hudson.maven.MavenModuleSetBuild$MavenModuleSetBuildExecution.doRun(MavenModuleSetBuild.java:896) at hudson.model.AbstractBuild$AbstractBuildExecution.run(AbstractBuild.java:504) at hudson.model.Run.execute(Run.java:1724) at hudson.maven.MavenModuleSetBuild.run(MavenModuleSetBuild.java:543) at hudson.model.ResourceController.execute(ResourceController.java:97) at hudson.model.Executor.run(Executor.java:429)Build step 'Docker Build and Publish' marked build as failure 问题排查看提示，是json数据问题，在想会不会是插件向docker请求数据的时候，没有返回正确的格式。联想到是我清理容器命令后出现的问题貌似，所以，重启了下docker。 问题依旧，感觉事态严重。百度谷姐都没有什么有用的信息。 后来想会不会是Jenkins什么东西被破坏了。迁移数据目录，快速重装了一下Jenkins，问题依旧。 然后新建一个项目 build，没问题，加上docker插件，又有问题了。 到此基本确定是docker插件的问题了。 接着测试了下，去掉认证，可能正常build。 加上仓库认证后，就出错了。 这里基本确定是仓库认证的问题了。 之前我们登录仓库认证，它会生成一个～/.docker/config.json或~/.dockercfg 来保存认证token。恰好是json格式。找到发现它是空的，有点符合出错的描述，不是一个有效的json格式。 删除之，构建，一气呵成。 料想是写满的时候，构建的时候，认证生成token写入到该文件的时候，能创建文件，但是写不了信息。而文件存在的时候，它又不会重新认证写入，直接读取导致出的问题。 解决方案具体步骤可以按如下： 登录Jenkins查看信息 http://&lt;Jenkins Address&gt;/systemInfo 确定Jenkins HOME 的位置，我这里就是/var/lib/jenkins 删除仓库认证信息 rm -f /var/lib/jenkins/.dockercfg]]></content>
      <categories>
        <category>troubleshooting</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python根据指定日期生成日历]]></title>
    <url>%2Farticle%2F20180805%2Fpython-generate-calendar%2F</url>
    <content type="text"><![CDATA[根据给定日期，生成 5*7的日历。自动补齐前面的日期。 含计算日期，计算星期几等函数。生生复习了一遍闰年和星期几计算。记录下留档。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105# _*_ coding:utf-8 _*_# Author: Onecer &lt;LDH@QQ.COM&gt;# Date: 7/26/18 10:20 PMdef is_leap_year(year): """ 判断闰年 :param year: :return: """ if year % 4 == 0 and year % 100 != 0 or year % 400 == 0: return True else: return Falsedef get_days_of_month(year, month): """ 返回一个月有几天 :param year: :param month: :return: """ if month in (1, 3, 5, 7, 8, 10, 12): return 31 elif month in (4, 6, 9, 11): return 30 elif month ==2: if is_leap_year(year): return 29 else: return 28def get_day(years, months, days): """ 获取星期几 :param years: :param months: :param days: :return: """ num = 0 for year in range(1800, years): if is_leap_year(year): num += 366 else: num += 365 for month in range(1,months): num += get_days_of_month(years, month) num += days-1 return (3 + num) % 7def inc_date(year, month, day, num): """ 加日期 :param year: :param month: :param day: :param num: :return: """ if num == 0: week_day = get_day(year, month, day) return '[&#123;&#125;-&#123;&#125;-&#123;&#125;/&#123;&#125;]'.format(year, month, day, week_day) else: for i in range(0,num): if get_days_of_month(year, month) &gt; day: day +=1 else: month += 1 day = 1 if month &gt; 12: month = 1 year += 1 week_day = get_day(year, month, day) return '[&#123;&#125;-&#123;&#125;-&#123;&#125;/&#123;&#125;]'.format(year, month, day, week_day)def repay_date(year, month, day): week_day = get_day(year, month, day) if week_day != 0: if day - week_day == 0: month = month - 1 if month == 0: month = 12 year = year - 1 day = get_days_of_month(year, month) else: day = day - week_day count = 0 for x in range (0,5): str = '' for y in range(0,7): str += inc_date(year,month,day,count) + ',' count += 1 print(str)repay_date(2018,7,26)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>calendar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Swarm Mode中部署SpringCloud微服务]]></title>
    <url>%2Farticle%2F20180805%2Fdocker-swarm-deploy-micro-services%2F</url>
    <content type="text"><![CDATA[[TOC] 在Docker Swarm中部署Spring Cloud的服务. 本来服务注册是由Eureka做的,但是Eureka团队停止对该项目支持.于是我们转而转向consul. 经实践,最终定下来新的微服务部署用到的技术如下. Docker+Consul+Registrator 实验环境三台机： node1：192.168.99.100 node2：192.168.99.101 node3：192.168.99.102 规划如下： node1: Consul Server,Docker Swarm master node2: Consul Server,Docker Swarm node node3: Consul Client,Docker Swarm node 一般建议consul server数量为3~5个，做高可用，但是由于是演示，机器也比较渣，就不启用多台作为实验。 创建一个Overlay网络123456789101112131415161718192021Usage: docker network create [OPTIONS] NETWORKCreate a networkOptions: --attachable Enable manual container attachment --aux-address map Auxiliary IPv4 or IPv6 addresses used by Network driver (default map[]) --config-from string The network from which copying the configuration --config-only Create a configuration only network -d, --driver string Driver to manage the Network (default &quot;bridge&quot;) --gateway strings IPv4 or IPv6 Gateway for the master subnet --ingress Create swarm routing-mesh network --internal Restrict external access to the network --ip-range strings Allocate container ip from a sub-range --ipam-driver string IP Address Management Driver (default &quot;default&quot;) --ipam-opt map Set IPAM driver specific options (default map[]) --ipv6 Enable IPv6 networking --label list Set metadata on a network -o, --opt map Set driver specific options (default map[]) --scope string Control the network&apos;s scope --subnet strings Subnet in CIDR format that represents a network segment 在node1上执行 1docker network create --attachable --driver overlay micro-service 创建一个可被普通容器附加的overlay网络，名字为micro-service。 用swarm默认的ingress不支持服务发现,会出现服务无法被调用的情况。所以另行创建了一个网络。 现在node1的网络如下： 1234567docker@node1:~$ docker network lsNETWORK ID NAME DRIVER SCOPE64c3669ce14f bridge bridge local176814588fd1 docker_gwbridge bridge local52b2424b81ec host host localqmkx8kk9j9ic ingress overlay swarm5kjkaxmaw2ei micro-service overlay swarm 由于我没有清空实验环境，之前搭建过，所以这里还看到有一个创建docker swarm后默认的ingress网络 搭建Consul集群和server高可用官方建议是docker容器方式运行的时候,用host网络模式,因为一致性和gossip对延迟比较敏感. 但是如此一来,在调用consul的时候,负载均衡还要用nginx之类的实现,我打算加入routing mesh网络,然后用服务名来调用,让routing mesh实现负载均衡. node1上执行,安装consul server 1234567891011121314docker run -d -p 8500:8500 -p 8300-8302:8300-8302 -p 8600:8600 \--restart=always \-h node1 \--name consul \--network micro-service \-v /data/consul:/consul/data \consul agent \-server \-bootstrap-expect=2 \-node=node1 \-rejoin \-client 0.0.0.0 \-advertise 192.168.99.100 \-ui 在node2上执行，安装consul server,和第一条有点区别，没有UI 123456789101112docker run -d -p 8500:8500 -p 8300-8302:8300-8302 -p 8600:8600 \--restart=always \-h node2 \--name consul \--network micro-service \consul agent \-server \-node=node2 \-rejoin \-client 0.0.0.0 \-join 192.168.99.100 \-advertise 192.168.99.101 在node3上执行，安装consul client 1234567891011docker run -d -p 8500:8500 -p 8300-8302:8300-8302 -p 8600:8600 \--restart=always \-h node3 \--name consul \--network micro-service \consul agent \-node=node3 \-rejoin \-client 0.0.0.0 \-join 192.168.99.100 \-advertise 192.168.99.102 现在在node1容器里面执行consul的命令是可以看到有三个节点信息，其中两个server 一个client，如下 12345docker@node1:~$ docker exec consul consul membersNode Address Status Type Build Protocol DC Segmentnode1 192.168.99.100:8301 alive server 1.2.2 2 dc1 &lt;all&gt;node2 192.168.99.101:8301 alive server 1.2.2 2 dc1 &lt;all&gt;node3 192.168.99.102:8301 alive client 1.2.2 2 dc1 &lt;default&gt; 这里只是测试，很多参数都没特别带上，有些还蛮重要的，比如配置和数据目录，广域网宣告IP，建议去consul官方文档看看，或者看我整理的信息，如下 consul agent命令可选参数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203Usage: consul agent [options] Starts the Consul agent and runs until an interrupt is received. The agent represents a single node in a cluster.HTTP API Options -datacenter=&lt;value&gt; Datacenter of the agent.Command Options -advertise=&lt;value&gt; 设置的主机IP，不设置，通过容器运行的话，获取的是容器里面的IP -advertise-wan=&lt;value&gt; Sets address to advertise on WAN instead of -advertise address. 设置广域网IP，一般跨局域网的话 要指定这个。 -bind=&lt;value&gt; Sets the bind address for cluster communication. 集群中绑定的IP，默认0.0.0.0 -bootstrap Sets server to bootstrap mode. 引导模式，自动选择为raft领导者。多个节点指定这个参数将导致一致性不能保证。 属于遗留的参数。 -bootstrap-expect=&lt;value&gt; Sets server to expect bootstrap mode. 预期服务器的数量，达到预期数量后，自动选举领导者。一般不建议指定。 -client=&lt;value&gt; Sets the address to bind for client access. This includes RPC, DNS, HTTP and HTTPS (if configured). 绑定的客户端地址，绑定才能访问。 -config-dir=&lt;value&gt; Path to a directory to read configuration files from. This will read every file ending in '.json' as configuration in this directory in alphabetical order. Can be specified multiple times. 配置目录 -config-file=&lt;value&gt; Path to a JSON file to read configuration from. Can be specified multiple times. 配置文件 -config-format=&lt;value&gt; Config files are in this format irrespective of their extension. Must be 'hcl' or 'json' 配置格式 -data-dir=&lt;value&gt; Path to a data directory to store agent state. 数据卷目录 -dev Starts the agent in development mode. 开发模式，数据将不写入磁盘 -disable-host-node-id Setting this to true will prevent Consul from using information from the host to generate a node ID, and will cause Consul to generate a random node ID instead. 关闭后，Consul不使用节点信息来生成确定性标示，并随机生成标示。挺有有的，可以在一台机运行多个实例的情况避免了node id冲突。当然如果用docker swarm应该是没这方面担忧的，因为它本身就生成了随机的id作为hostname -disable-keyring-file Disables the backing up of the keyring to a file. -dns-port=&lt;value&gt; DNS port to use. 监听的dns端口，默认是8600 -domain=&lt;value&gt; Domain to use for DNS interface. 接管解析改域，不会递归查询 -enable-script-checks Enables health check scripts. 开启健康检查脚本 -encrypt=&lt;value&gt; Provides the gossip encryption key. 解密consul流量的key，base64编码的16字节，创建方法是consul keygen -hcl=&lt;value&gt; hcl config fragment. Can be specified multiple times. -http-port=&lt;value&gt; Sets the HTTP API port to listen on. 绑定的http api端口 默认是8500 -join=&lt;value&gt; Address of an agent to join at start time. Can be specified multiple times. 启动时加入其它节点 -join-wan=&lt;value&gt; Address of an agent to join -wan at start time. Can be specified multiple times. 加入其它局域网节点时用这个。 -log-level=&lt;value&gt; Log level of the agent. 日志等级，可以看consul moniter获取更多信息。 -node=&lt;value&gt; Name of this node. Must be unique in the cluster. 节点名字，必须在集群中唯一。 -node-id=&lt;value&gt; A unique ID for this node across space and time. Defaults to a randomly-generated ID that persists in the data-dir. 如果不指定，则自动生成，这个ID会被保存在数据目录中，以便重启后，还能获取到它信息。 -node-meta=&lt;key:value&gt; An arbitrary metadata key/value pair for this node, of the format `key:value`. Can be specified multiple times. -non-voting-server (Enterprise-only) This flag is used to make the server not participate in the Raft quorum, and have it only receive the data replication stream. This can be used to add read scalability to a cluster in cases where a high volume of reads to servers are needed. 企业版独有。不参与raft仲裁 -pid-file=&lt;value&gt; Path to file to store agent PID. 代理启动的pid文件路径，如果指定可以方便找到代理pid，方便其进程管理。 -protocol=&lt;value&gt; Sets the protocol version. Defaults to latest. 设置consul协议版本，默认最新。consul -v可看 -raft-protocol=&lt;value&gt; Sets the Raft protocol version. Defaults to latest. 设置raft协议版本 -recursor=&lt;value&gt; Address of an upstream DNS server. Can be specified multiple times. 设置上游DNS服务，用于递归查询一般。 -rejoin Ignores a previous leave and attempts to rejoin the cluster. 在服务器暂时断开后，重连重新加入集群 -retry-interval=&lt;value&gt; Time to wait between join attempts. 尝试重连的间隔 -retry-interval-wan=&lt;value&gt; Time to wait between join -wan attempts. -retry-join=&lt;value&gt; Address of an agent to join at start time with retries enabled. Can be specified multiple times. -retry-join-wan=&lt;value&gt; Address of an agent to join -wan at start time with retries enabled. Can be specified multiple times. -retry-max=&lt;value&gt; Maximum number of join attempts. Defaults to 0, which will retry indefinitely. -retry-max-wan=&lt;value&gt; Maximum number of join -wan attempts. Defaults to 0, which will retry indefinitely. -segment=&lt;value&gt; (Enterprise-only) Sets the network segment to join.777 -serf-lan-bind=&lt;value&gt; Address to bind Serf LAN listeners to. -serf-lan-port=&lt;value&gt; Sets the Serf LAN port to listen on. -serf-wan-bind=&lt;value&gt; Address to bind Serf WAN listeners to. -serf-wan-port=&lt;value&gt; Sets the Serf WAN port to listen on. -server Switches agent to server mode. 启用server模式 -server-port=&lt;value&gt; Sets the server port to listen on. 设置server端口 -syslog Enables logging to syslog. 记录日志去syslog，windows系统不可用 -ui Enables the built-in static web UI server. 启用内置UI面板，不能和下面那个同时启用。 -ui-dir=&lt;value&gt; Path to directory containing the web UI resources. 搭建Docker Swarm Mode集群为了方便进行服务扩缩容，我决定将服务运行在docker swarm上。 下面就搭建一下docker swarm mode集群。 控制节点，初始化docker swarm 1docker swarm init --advertise-addr 192.168.99.100 可选参数 1234567891011121314151617Usage: docker swarm init [OPTIONS]Initialize a swarmOptions: --advertise-addr string Advertised address (format: &lt;ip|interface&gt;[:port]) --autolock Enable manager autolocking (requiring an unlock key to start a stopped manager) --availability string Availability of the node ("active"|"pause"|"drain") (default "active") --cert-expiry duration Validity period for node certificates (ns|us|ms|s|m|h) (default 2160h0m0s) --data-path-addr string Address or interface to use for data path traffic (format: &lt;ip|interface&gt;) --dispatcher-heartbeat duration Dispatcher heartbeat period (ns|us|ms|s|m|h) (default 5s) --external-ca external-ca Specifications of one or more certificate signing endpoints --force-new-cluster Force create a new cluster from current state --listen-addr node-addr Listen address (format: &lt;ip|interface&gt;[:port]) (default 0.0.0.0:2377) --max-snapshots uint Number of additional Raft snapshots to retain --snapshot-interval uint Number of log entries between Raft snapshots (default 10000) --task-history-limit int Task history retention limit (default 5) 增加docker swarm节点 在其它机器(node2,node3)上执行命令 1docker swarm join --token SWMTKN-1-4oz1xnoqi9psb9aty5zfjkeyw2wkq2ziyursfas1eo563dxwpp-1nmwsqsm9l3wsyqkyus8075y0 192.168.99.100:2377 这个命令是你在docker swarm init后生成的。如果你忘记保存了，没关系，在控制节点上用docker swarm join-token可以找到它 Usage: docker swarm join-token [OPTIONS] (worker|manager) 如： 1234docker@node1:~$ docker swarm join-token workerTo add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-4oz1xnoqi9psb9aty5zfjkeyw2wkq2ziyursfas1eo563dxwpp-8vdgujjb6dp1i7jxv6nlm4r70 192.168.99.100:2377 执行完毕后，在node1（控制节点）应该可以看到有三个节点 12345docker@node1:~$ docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSIONqx9075p5x2ipteiikkccgqfqp * node1 Ready Active Leader 18.06.0-cehwkh4iajbtuv6gxto9gpdpe42 node2 Ready Active 18.06.0-cek709bftfox5vyannyj3py0hya node3 Ready Active 18.06.0-ce Consul服务发现注册Consul服务发现与注册我是选用了，Registrator来完成的,至于为什么用它，可以看前面我发过的文章。 在每台机上执行这个 12345678910docker run -d \ --restart=always \ --name=registrator \ --net=host \ --volume=/var/run/docker.sock:/tmp/docker.sock \ gliderlabs/registrator:latest \ -cleanup \ -internal \ -ip &lt;NODE_IP&gt; \ consul://&lt;NODE_IP&gt;:8500 至此，整个搭建就告一段落了。 重点是-internal和-ip参数。 开始我用的是默认的，采用根据暴露到外部的端口来自动注册服务，但是很快发现这种方式不适用docker swarm方式运行的服务。 因为它无法识别到routing mesh方式暴露的端口。后来改为用内部暴露的端口注册，这样我们用docker swarm部署的也可以注册上consul了。 这个很多百度谷歌来的文章没提到，一度差点放弃registrator，后来还是老老实实看官方文档发现了这个参数。 另外我觉得你们肯定也会遇到多网络多IP注册的问题的 建议运行的时候用我修改过的registrator吧。详情看这里 《Docker Swarm Mode中容器多网络多IP registrator注册服务IP的问题》 1234567891011docker run -d \ --restart=always \ --name=registrator \ --net=host \ --volume=/var/run/docker.sock:/tmp/docker.sock \ doubleshit/registrator:v7 \ -cleanup \ -internal \ -ip &lt;NODE_IP&gt; \ -useIpFromNetworkName=micro-service \ consul://&lt;NODE_IP&gt;:8500 因为注册上去的是根据内部端口，为了能正确访问到，所以在运行的时候，-p &lt;extenal_port&gt;:&lt;internal_ip&gt; 暴露的端口必须一致！！！ 部署微服务主要注意两点： 暴露的端口和内部端口号必须一样。 网络必须指定一样的如我们创建的：--network overlay 其它没什么好讲的了，运行服务 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970Usage: docker service create [OPTIONS] IMAGE [COMMAND] [ARG...]Create a new serviceOptions: --config config Specify configurations to expose to the service --constraint list Placement constraints --container-label list Container labels --credential-spec credential-spec Credential spec for managed service account (Windows only) -d, --detach Exit immediately instead of waiting for the service to converge --dns list Set custom DNS servers --dns-option list Set DNS options --dns-search list Set custom DNS search domains --endpoint-mode string Endpoint mode (vip or dnsrr) (default &quot;vip&quot;) --entrypoint command Overwrite the default ENTRYPOINT of the image -e, --env list Set environment variables --env-file list Read in a file of environment variables --generic-resource list User defined resources --group list Set one or more supplementary user groups for the container --health-cmd string Command to run to check health --health-interval duration Time between running the check (ms|s|m|h) --health-retries int Consecutive failures needed to report unhealthy --health-start-period duration Start period for the container to initialize before counting retries towards unstable (ms|s|m|h) --health-timeout duration Maximum time to allow one check to run (ms|s|m|h) --host list Set one or more custom host-to-IP mappings (host:ip) --hostname string Container hostname --init Use an init inside each service container to forward signals and reap processes --isolation string Service container isolation mode -l, --label list Service labels --limit-cpu decimal Limit CPUs --limit-memory bytes Limit Memory --log-driver string Logging driver for service --log-opt list Logging driver options --mode string Service mode (replicated or global) (default &quot;replicated&quot;) --mount mount Attach a filesystem mount to the service --name string Service name --network network Network attachments --no-healthcheck Disable any container-specified HEALTHCHECK --no-resolve-image Do not query the registry to resolve image digest and supported platforms --placement-pref pref Add a placement preference -p, --publish port Publish a port as a node port -q, --quiet Suppress progress output --read-only Mount the container&apos;s root filesystem as read only --replicas uint Number of tasks --reserve-cpu decimal Reserve CPUs --reserve-memory bytes Reserve Memory --restart-condition string Restart when condition is met (&quot;none&quot;|&quot;on-failure&quot;|&quot;any&quot;) (default &quot;any&quot;) --restart-delay duration Delay between restart attempts (ns|us|ms|s|m|h) (default 5s) --restart-max-attempts uint Maximum number of restarts before giving up --restart-window duration Window used to evaluate the restart policy (ns|us|ms|s|m|h) --rollback-delay duration Delay between task rollbacks (ns|us|ms|s|m|h) (default 0s) --rollback-failure-action string Action on rollback failure (&quot;pause&quot;|&quot;continue&quot;) (default &quot;pause&quot;) --rollback-max-failure-ratio float Failure rate to tolerate during a rollback (default 0) --rollback-monitor duration Duration after each task rollback to monitor for failure (ns|us|ms|s|m|h) (default 5s) --rollback-order string Rollback order (&quot;start-first&quot;|&quot;stop-first&quot;) (default &quot;stop-first&quot;) --rollback-parallelism uint Maximum number of tasks rolled back simultaneously (0 to roll back all at once) (default 1) --secret secret Specify secrets to expose to the service --stop-grace-period duration Time to wait before force killing a container (ns|us|ms|s|m|h) (default 10s) --stop-signal string Signal to stop the container -t, --tty Allocate a pseudo-TTY --update-delay duration Delay between updates (ns|us|ms|s|m|h) (default 0s) --update-failure-action string Action on update failure (&quot;pause&quot;|&quot;continue&quot;|&quot;rollback&quot;) (default &quot;pause&quot;) --update-max-failure-ratio float Failure rate to tolerate during an update (default 0) --update-monitor duration Duration after each task update to monitor for failure (ns|us|ms|s|m|h) (default 5s) --update-order string Update order (&quot;start-first&quot;|&quot;stop-first&quot;) (default &quot;stop-first&quot;) --update-parallelism uint Maximum number of tasks updated simultaneously (0 to update all at once) (default 1) -u, --user string Username or UID (format: &lt;name|uid&gt;[:&lt;group|gid&gt;]) --with-registry-auth Send registry authentication details to swarm agents -w, --workdir string Working directory inside the container 参考资料]]></content>
      <categories>
        <category>microservice</category>
      </categories>
      <tags>
        <tag>consul</tag>
        <tag>docker swarm</tag>
        <tag>microservice</tag>
        <tag>spring cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7+Docker部署Consul集群]]></title>
    <url>%2Farticle%2F20180802%2Fconsul-cluster%2F</url>
    <content type="text"><![CDATA[[TOC] Consul整理了一些觉得有用的资料和踩过的坑. 为什么选用consul1.因为Eureka即将停止维护了 2.Consul要更强大点,带配置中心 每台机都必须运行一个consul agent. consul agent有两种模式,1,server模式 2,client模式. consul server,每个数据中心会有一个leader有server选举出来,故障后会重新选举. consul server,保持数据一致性,维护集群状态,转发查询,转发请求给leader或者远程数据中心,交换wan gossip. consul client用于注册服务,运行健康检查和转发对server的查询. node名字必须在集群中唯一 Consulの初体验运行一个Consul Server12345678910111213docker run -d -p 8500:8500 -p 8300-8302:8300-8302 -p 8600:8600 \--restart=always \-h node1 \--name consul \-v /data/consul:/consul/data \consul agent \-server \-bootstrap-expect=1 \-node=node1 \-rejoin \-client 0.0.0.0 \-advertise 192.168.99.100 \-ui 端口作用不赘述,其它参数作用如下. -h node1 指定hostname -server 以server模式运行,不添加默认以client模式运行. -bootstrap-expect=1 组成集群需要启动的server数量 -node=node1 指定节点名,同集群内不能重复 -rejoin 在意外断开连接后,会不会自动重新加入集群 -client 可以访问的ip -advertise 宣传IP.不写的话,通过registrator注册,服务没有指定IP环境变量的话.consul上默认的是 consul server所在的容器的内网IP.写一个能访问到你服务的IP. -ui 是否启用面板管理 Consul Server是一个有状态的容器,它有两个目录可以挂载本地的目录进去,方便改动配置和数据持久化. /consul/config 配置目录,如果agent可以把json配置放这里,会自动加载 /consul/data consul数据目录,存放节点,KV,datacenter等数据 为了consul server能稳定提供服务,一般都建议有3-5个consul server组成集群. 如果有很多台机器,在启动足够的consul server后,其它主机可以都作为client运行. 运行一个Consul Client12345678910docker run -d -p 8500:8500 -p 8300-8302:8300-8302 -p 8600:8600 \--restart=always \-h node2 \--name consul \consul agent \-node=node2 \-rejoin \-client 0.0.0.0 \-join 192.168.99.100 \-advertise 192.168.99.101 整个命令和运行consul是非常像的,就是少了几个配置.注意 -join到consul server即可 服务发现consul提供了很多方式来注册,如通过json配置服务,放到相关目录,让agent注册,服务调用相关API注册,Docker容器发现. 由于我们服务都是运行在Docker之中,用Docker容器发现相关技术会方便点,所以优先考虑了这个. 1.可以在不改动代码的同时实现服务发现注册 2.可以和eureka发现同时存在,可以平缓过度. 相关实现的开源可选工具官方推荐了两个ContainerPilot和Registrator. 由于ContainerPilot使用更为复杂点,registrator比较简单,文档多,所以优先考虑了它. - Docker Registrator主要特点 通过docker socket直接监听容器event，根据容器启动/停止等event来注册/注销服务 每个容器的每个exposed端口对应不同的服务 支持可插拔的registry backend，默认支持Consul, etcd and SkyDNS 自身也是docker化的，可以容器方式启动 用户可自定义配置，如服务TTL（time-to-live）、服务名称、服务tag等 运行registrator- 12345678docker run -d \ --name=registrator \ --net=host \ --volume=/var/run/docker.sock:/tmp/docker.sock \ gliderlabs/registrator:latest \ -internal \ -ip 192.168.99.101 \ consul://192.168.99.101:8500 每台机都要运行一个Registrator,consul地址填同机的consul agent 这时候,你只要在机子上运行任意一个docker容器,只要它暴露端口,就会被当成一个服务注册过去,如果没有指定服务名字之类的,默认取得服务名字作为服务名,服务id则为[hostname+端口]. Registrator服务对象- 12345678type Service struct &#123; ID string // unique service instance ID Name string // service name IP string // IP address service is located at Port int // port service is listening on Tags []string // extra tags to classify service Attrs map[string]string // extra attribute metadata&#125; 可以通过运行docker服务的时候,传入环境变量SERVICE_&lt;属性&gt;=值,Registrator会读取得到它的相关的环境变量. 如: 1234docker run -d --name redis.0 -p 10000:6379 \ -e "SERVICE_NAME=db" \ -e "SERVICE_TAGS=master,backups" \ -e "SERVICE_REGION=us2" progrium/redis 参考资料 现有系统如何集成Consul服务发现 Registrator Quickstart Registrator Service Object Consul Docker Consul Documentation Consul API Consul Documentation Translation]]></content>
      <categories>
        <category>microservice</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>consul</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[以Docker容器方式运行rabbitmq]]></title>
    <url>%2Farticle%2F20180726%2Frun-rabbitmq-in-docker%2F</url>
    <content type="text"><![CDATA[主要注意挂载目录以便数据持久化,命名hostname. 1docker run -d --name rabbitmq -p 4369:4369 -p 8080:15672 -p 5671-5672:5671-5672 --restart=always --hostname my-rabbit -v /data/rabbitmq:/var/lib/rabbitmq rabbitmq:3-management]]></content>
      <categories>
        <category>operations</category>
      </categories>
      <tags>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python使用pika连接rabbitmq]]></title>
    <url>%2Farticle%2F20180725%2Fpython-rabbitmq-pika%2F</url>
    <content type="text"><![CDATA[一个连接rabbitmq的python例子. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# coding: utf-8import jsonimport pika# from selenium.webdriver.common.by import Byfrom house_info import HouseInfo# CONFIG AREAAMQP_CONFIG = &#123; 'host': '127.0.0.1', 'port': 5672, 'username': 'guest', 'password': 'guest'&#125;AMQP_QUEUE_NAME = 'house-inquery'AMQP_FEEDBACK_QUEUE_NAME = 'house-inquery-result'# 因为反馈回去的队列要求在不同队列,所以重新建立了一个新的队列连接def process_feedback(msg): mq_credential = pika.PlainCredentials( username=AMQP_CONFIG['username'], password=AMQP_CONFIG['password'] ) mq_conn = pika.BlockingConnection(pika.ConnectionParameters( host=AMQP_CONFIG['host'], credentials=mq_credential )) mq_channel = mq_conn.channel() mq_channel.queue_declare(queue=AMQP_FEEDBACK_QUEUE_NAME, durable=True) return mq_channel.basic_publish(exchange='', routing_key=AMQP_FEEDBACK_QUEUE_NAME, body=msg, properties=pika.BasicProperties( delivery_mode=2, content_encoding='UTF-8', content_type='text/plain' ) )user_pwd = pika.PlainCredentials(AMQP_CONFIG['username'], AMQP_CONFIG['password'])s_conn = pika.BlockingConnection(pika.ConnectionParameters(AMQP_CONFIG['host'], credentials=user_pwd))channel = s_conn.channel()channel.queue_declare(queue=AMQP_QUEUE_NAME, durable=True)def callback(ch, method, properties, body): print(body) query_data = json.loads(body) if not query_data: return try: # 一些业务逻辑代码 # 应答消息 ch.basic_ack(delivery_tag=method.delivery_tag) except Exception as e: print(e)# 设置一次只获取一条消息处理channel.basic_qos(prefetch_count=1)# 启用ack,防止异常消息丢失 确认处理后再删除消息channel.basic_consume(callback, queue=AMQP_QUEUE_NAME, no_ack=False)channel.start_consuming()]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python实现通过Web执行Docker容器里面的shell命令]]></title>
    <url>%2Farticle%2F20180614%2Fpython-docker-web-console%2F</url>
    <content type="text"><![CDATA[其实就是通过flask接受url传递过来的命令，然后调用SDK相关API执行docker exec命令，然后将结果返回给页面。 1pip install flask docker 123456789101112131415161718192021222324# coding: utf-8from flask import Flaskfrom flask import render_templatefrom flask import requestimport dockerapp = Flask(__name__, template_folder='./templates', static_folder="", static_url_path="")client = docker.from_env()@app.route('/cmd', methods=['GET', 'POST'])def exec_cmd(): if request.method == 'GET': return render_template('cmd.html') if request.method == 'POST': container = client.containers.get('gmb-index') # 这里我写死了获取本地这个容器 cmd = request.form.get('cmd') result = container.exec_run(cmd=cmd) output = result.output.decode() return render_template('cmd.html', output=output)if __name__=='__main__': app.run(host='127.0.0.1', port=8888) 模板 12345678910111213141516171819&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Console&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div&gt; &lt;form action="/cmd" method="post"&gt; &lt;input type="text" name="cmd"&gt; &lt;input type="submit" value="Submit"&gt; &lt;/form&gt; &lt;textarea rows="100" cols="200" readonly="readonly"&gt;&#123;&#123; output &#125;&#125; &lt;/textarea&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 如图： 参考资料 Docker SDK for Python]]></content>
      <categories>
        <category>python</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python给Excel表格去重]]></title>
    <url>%2Farticle%2F20180611%2Fpython-excel-data-deduplication%2F</url>
    <content type="text"><![CDATA[某日看到妹子整理表格，需要对excel一万多条记录中的重复数据删除处理。 但是处理两小时没好，耽误了两人看动漫时间，最后帮她搞了这个脚本。 为了速度，存在很多硬编码，但是应该不影响阅读。 12345678910111213141516171819202122232425# coding: utf-8import xlrdimport xlwtdata = xlrd.open_workbook("/Users/phan/Desktop/work/深圳_4.xls")table = data.sheets()[0]workbook = xlwt.Workbook(encoding='utf-8')sheet_w = workbook.add_sheet('data')nrows = table.nrowsncols = table.ncolscol = []ws = 0count=0for i in range(1,nrows): # 去重条件 if not table.row_values(i)[3] in col and table.row_values(i)[14]!='F': col.append(table.row_values(i)[3]) for j in range(ncols): sheet_w.write(ws,j,table.row_values(i)[j]) ws = ws + 1 else: count += 1workbook.save("/Users/phan/Desktop/work/深圳_去重.xls")]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker清理]]></title>
    <url>%2Farticle%2F20180521%2Fdocker-clean%2F</url>
    <content type="text"><![CDATA[已经经历两次开发环境磁盘占用满的情况的。 第一次是部署太频繁，然后有很多无用的images没有删除掉。 第二次是docker容器，某些服务写了很多日志，导致磁盘被写满。 撇开这些设置不当的问题，怎么清理掉一些“垃圾”，让docker占用空间变得小一点？ Docker占用磁盘的主要有以下几样东西： Docker Images Docker Containers Docker Logs 对于输出日志特别多的程序，Logs还是不容小觑的。 尤其是开发服务器，频繁的部署，会导致产生很多用不上的Images也占用在空间。 而Container占用空间突然增大，一般也主要是一些异常产生的文件太多，写了太多logs在容器内所致。 清理dangling镜像、退出的容器、无用的数据卷和网络、未使用的镜像 自动档 1docker system prune -a 如果有些服务意外退出，然后被清理掉，还是蛮蛋疼的。慎用。 手动档 删除所有关闭的容器 docker ps -a | grep Exit | cut -d &#39; &#39; -f 1 | xargs docker rm 删除所有dangling镜像(即无tag的镜像)： docker rmi $(docker images | grep &quot;^&lt;none&gt;&quot; | awk &quot;{print $3}&quot;) 删除所有dangling数据卷(即无用的volume)： docker volume rm $(docker volume ls -qf dangling=true) 清理容器内的垃圾1docker system df -v 可以先用这个找出异常的容器 或者到相关目录执行du命令也行，如： 12345cd /var/lib/docker/overlay2du --max-depth=1 -h ./cd /var/lib/docker/containersdu --max-depth=1 -h ./ 然后哪个容器占用过大，就清理哪个,这样靠谱点，连同日志文件都计算在内 清理docker日志文件1ls -lh $(find /var/lib/docker/containers/ -name *-json.log) 单独列出日志文件大小。 清空日志文件1truncate -s 0 /path/to/your/textfile]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos java jdk安装和环境配置]]></title>
    <url>%2Farticle%2F20180402%2Fjava-jdk-install-setp%2F</url>
    <content type="text"><![CDATA[环境配置这东西 大多时候用一次找一次 不胜其烦。 今记录一下Centos Java的jdk直接从源安装。相比编译之类的，已经是极大的幸福感提升。 12345678910111213yum -y list java*yum -y install java-1.7.0-openjdk*yum list installed | grep java # 以上分别查找 安装 确定是否安装vim /etc/profile---JAVA_HOME=/usr/lib/jvm/jre-1.7.0-openjdk-1.7.0.171-2.6.13.0.el7_4.x86_64PATH=$PATH:$JAVA_HOME/binCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar----export JAVA_HOME CLASSPATH PATHsource /etc/profileecho $JAVA_HOME 补充一个，路径我是 rpm -ql java-1.7.0-openjdk.x86_64找出来的]]></content>
      <categories>
        <category>other</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jdk</tag>
        <tag>jre</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[慕学网强力Django教程例子存在认证逻辑漏洞 可修改任意用户密码]]></title>
    <url>%2Farticle%2F20180309%2Fsecurity-django-mxonline-reset-password%2F</url>
    <content type="text"><![CDATA[最近在看慕学网《强力Django+xadmin打造在线云课堂》这个教程。 感觉还不错。昨日看到用户模块，修改密码功能的逻辑编写，觉得存在比较大的安全隐患。刚刚按照思路小撸了一下，可以修改任意用户密码。 0x01 漏洞分析文件apps/users/views.py12345678910111213141516171819202122232425# 用户进入到重置密码页面class ResetView(View): def get(self, request, active_code): all_records = EmailVerifyRecord.objects.filter(code=active_code) if all_records: for records in all_records: email = records.email return render(request, 'password_reset.html', &#123;'email': email&#125;) # return render(request, 'active_fail.html')# 用户在重置密码页面提交新密码class ModifyPwdView(View): def post(self, request): modify_form = ModifyPwdForm(request.POST) email = request.POST.get('email', '') if modify_form.is_valid(): pwd1 = request.POST.get('password1', '') pwd2 = request.POST.get('password2', '') if pwd1 != pwd2: return render(request, 'password_reset.html', &#123;'email': email, 'msg': '密码不一致！'&#125;) user = UserProfile.objects.get(email=email) user.password = make_password(pwd2) user.save() return render(request, 'login.html') 首先他逻辑是这样的，通过ResetView来展示修改密码页面，然后修改数据POST给ModifyPwdView修改，其实我觉得大可在ResetView中处理POST动作就好了。 ModifyPwdView主要问题有几处: 没有校验验证码是否有效，是否存在。。。 没有鉴定验证码是否属于修改密码的类型的。验证码是同个表。意味着注册认证码也是能进入到修改页面的。 从用户页面获取email。这个我不是很理解，因为保存验证码的时候，其实有保存了email字段，根据验证码直接取email即可。也就是这里可以在用户页面修改email，达到修改其它账户密码。 没有删除掉验证码。可以同个验证码无限使用。 0x02利用开始想着，连校验验证码都没，From只是对密码长度做了限制。直接构造数据post就行了。 但是由于Django CSRF机制存在，没有成功。于是转向了另一种简单粗暴的方式，一个chrome浏览器搞定。 首先注册用户 它会生成一个验证码存到相应数据库。并给你发送一封激活邮件来激活你的账户。里面链接格式：http://[网站]/active/[验证码]比如我收到的激活链接应该是这样的：http://127.0.0.1:8000/actice/UCZDRMPO7lVErxM5 构造修改页面的链接 提取验证码组合出以下重置密码的链接：http://127.0.0.1:8000/reset/UCZDRMPO7lVErxM5通过审查可以看到有个隐藏的input，里面有email。 修改email和密码 修改email为其它账户的email，密码随便设置一个。提交的数据： 最后用图中所示的账户和密码登录成功. 0x03 修补方法许多，我自己处理如下：POST同样在ResetView里面处理。 123456789101112131415161718192021222324252627class ResetView(View): def get(self, request, reset_code): records = VerifyRecord.objects.filter(verify_code=reset_code) for record in records: if record.send_type == 'forget': return render(request=request, template_name='password_reset.html', context=&#123;'reset_code': reset_code&#125;) else: return render(request, 'msg_box.html', &#123;"msg": "验证码类型错误"&#125;) else: return render(request=request, template_name='verify_expire.html') def post(self, request, reset_code): reset_form = ResetForm(request.POST) records = VerifyRecord.objects.filter(verify_code=reset_code) if not reset_form.is_valid(): return for record in records: user = UserProfile.objects.filter(email=record.email) if user and record.send_type == 'forget': password1 = request.POST.get('password', '') password2 = request.POST.get('password2', '') if password1 == password2: user.update(password=make_password(password1)) record.delete() return render(request, 'msg_box.html', &#123;"msg": "修改密码成功"&#125;) else: return render(request=request, template_name='verify_expire.html') 另外html模板也要修改一下：把传入的reset_code组合出POST URL。1&lt;form id="reset_password_form" action="&#123;% url 'reset_pwd' reset_code %&#125;" method="post"&gt;]]></content>
      <categories>
        <category>security</category>
      </categories>
      <tags>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux rm 删除文件 argument too long]]></title>
    <url>%2Farticle%2F20180305%2Ftroubleshooting-linux-rm-argument-too-long%2F</url>
    <content type="text"><![CDATA[刚登录一台测试服务器,习惯性地ll查看下home目录下的文件. 结果,我差点卡死了… 原因是当前目录下居然有6,7万条记录.类似下面这种1index.php?i=361&amp;c=entry&amp;do=cron&amp;m=qidong_saishi.62468 原因是开发在crontab添加了一个定时每分钟 wget一下某个网址.没用curl. 每分钟就下载一个网页到home目录. 然后我改为curl后,想删除掉文件,rm -f index.php?* 然后报错1argument too long 也是第一次遇到这个问题.可能是一下子删除的文件太多? 于是打算用 xargs来逐条删除. 1ll | grep index | awk &apos;&#123;print $9&#125;&apos;|xargs rm -f 前面三条主要是想吧路径单独列出来. done.]]></content>
      <categories>
        <category>troubleshooting</category>
      </categories>
      <tags>
        <tag>error</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django出错Xadmin后台报list index out of range]]></title>
    <url>%2Farticle%2F20180304%2Fdjango-error-list-index-out-of-range%2F</url>
    <content type="text"><![CDATA[闲置一阵没折腾django后,再续上次学习进度捣鼓demo的时候发现了这.1list index out of range 看看报错和xadmin模块有关,但是我之前没报错,而我又没对它做过改动,一脸懵逼. 主要是在注册的数据模型中新增数据,都会报这个错.在django原生的admin模块后台是没这个错误的. 基本锁定和xadmin有关了. 遂百度 xadmin list index out of range.果然有发现,见参考资料文章. 说是django升级后出现新标签导致的这个错误.而我之前对django升级过.django 1.11.12. 文中介绍了如何修改xadmin达到目的.我懒,降级了django回 django 1.11 没毛病老铁. 参考资料Django2集成xadmin详解-4-list index out of range报错追踪和处理]]></content>
      <categories>
        <category>troubleshooting</category>
        <category>django</category>
      </categories>
      <tags>
        <tag>xadmin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[杰奇CMS wap插件的两个个SQL注入漏洞0DAY Getshell和提权]]></title>
    <url>%2Farticle%2F20180304%2Fjieqicms-plugin-hon6-wap-sql-injection%2F</url>
    <content type="text"><![CDATA[百度了一圈，没人发过，算是0day吧。 近日有朋友发了一个小说站，日流量很可观，几万IP一天。 后来就留意， 近日得到一套该站用的wap端的源码，看了下信息是个人写的。感觉可能会有漏洞，就瞄了几眼，果然发现点端倪。 首先是mysql.class.php的类。 它有个checksql()的方法，每次调用都会获取所有的GET，POST，COOKIE的参数。进行正则匹配，企图发现恶意注入的SQL内容。 但是SQL过滤不是很严，还是有绕过的空间。比如十六进制，一些注释符，过滤的sql语句比较有限。 主要内容 123456789101112131415161718192021private $getfilter = "'|(and|or)\\b.+?(&gt;|&lt;|=|in|like)|\\/\\*.+?\\*\\/|&lt;\\s*script\\b|\\bEXEC\\b|UNION.+?SELECT|UPDATE.+?SET|INSERT\\s+INTO.+?VALUES|(SELECT|DELETE).+?FROM|(CREATE|ALTER|DROP|TRUNCATE)\\s+(TABLE|DATABASE)";private $postfilter = "\\b(and|or)\\b.&#123;1,6&#125;?(=|&gt;|&lt;|\\bin\\b|\\blike\\b)|\\/\\*.+?\\*\\/|&lt;\\s*script\\b|\\bEXEC\\b|UNION.+?SELECT|UPDATE.+?SET|INSERT\\s+INTO.+?VALUES|(SELECT|DELETE).+?FROM|(CREATE|ALTER|DROP|TRUNCATE)\\s+(TABLE|DATABASE)";private $cookiefilter = "\\b(and|or)\\b.&#123;1,6&#125;?(=|&gt;|&lt;|\\bin\\b|\\blike\\b)|\\/\\*.+?\\*\\/|&lt;\\s*script\\b|\\bEXEC\\b|UNION.+?SELECT|UPDATE.+?SET|INSERT\\s+INTO.+?VALUES|(SELECT|DELETE).+?FROM|(CREATE|ALTER|DROP|TRUNCATE)\\s+(TABLE|DATABASE)";function __construct()&#123;&#125;function checksql()&#123; foreach($_GET as $key=&gt;$value)&#123;$this-&gt;stopattack($key,$value,$this-&gt;getfilter);&#125; foreach($_POST as $key=&gt;$value)&#123;$this-&gt;stopattack($key,$value,$this-&gt;postfilter);&#125; foreach($_COOKIE as $key=&gt;$value)&#123;$this-&gt;stopattack($key,$value,$this-&gt;cookiefilter);&#125;&#125;/** * 参数检查并写日志 */public function stopattack($StrFiltKey, $StrFiltValue, $ArrFiltReq)&#123; if(is_array($StrFiltValue))$StrFiltValue = implode($StrFiltValue); if (preg_match("/".$ArrFiltReq."/is",$StrFiltValue) == 1)&#123; $this-&gt;writeslog($_SERVER["REMOTE_ADDR"]." ".strftime("%Y-%m-%d %H:%M:%S")." ".$_SERVER["PHP_SELF"]." ".$_SERVER["REQUEST_METHOD"]." ".$StrFiltKey." ".$StrFiltValue); exit('您提交的参数非法,系统已记录您的本次操作！'); &#125;&#125; 要说构造语句添加信息或者查询信息还是不容易的。所以利用起来似乎也不容易。 在看到用户模块的时候，倒是发现新大陆了。 看修改用户资料的处理代码。controllers/user.class.php123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110public function information()&#123; global $smartyObj; global $db; $db-&gt;checksql(); $step = isset($_GET["step"])?trim($_GET["step"]):""; $info_nickname = isset($_POST["info_nickname"])?$_POST["info_nickname"]:""; $info_emial = isset($_POST["info_emial"])?$_POST["info_emial"]:""; $info_sex = isset($_POST["info_sex"])?$_POST["info_sex"]:""; $info_sign = isset($_POST["info_sign"])?$_POST["info_sign"]:""; $info_intro = isset($_POST["info_intro"])?$_POST["info_intro"]:""; $iserror = 0; $userinfo = $db-&gt;clogin(); if($step=="ok") &#123; if ($iserror == 0 and $info_nickname == "") &#123; $iserror = 1; $tourl = urlconfigs::URL_auto(array("m" =&gt; "user/information")); $pagecontent = "保存失败！&lt;br/&gt;"; $pagecontent .= "昵称不能为空！&lt;br/&gt;"; &#125; if ($iserror == 0) &#123; $a1 = $db-&gt;query_num("select uid from " . JIEQI_DB_PREFIX . "_system_users where name ='" . $info_nickname . "' and uid !=" . $userinfo-&gt;uid); if ($a1) &#123; $iserror = 1; $tourl = urlconfigs::URL_auto(array("m" =&gt; "user/information")); $pagecontent = "保存失败！&lt;br/&gt;"; $pagecontent .= "该昵称已经存在！&lt;br/&gt;"; &#125; &#125; if ($iserror == 0 and $info_emial == "") &#123; $iserror = 1; $tourl = urlconfigs::URL_auto(array("m" =&gt; "user/information")); $pagecontent = "保存失败！&lt;br/&gt;"; $pagecontent .= "邮箱不能为空！&lt;br/&gt;"; &#125; if ($iserror == 0) &#123; $a2 = $db-&gt;query_num("select uid from " . JIEQI_DB_PREFIX . "_system_users where email ='" . $info_emial . "' and uid !=" . $userinfo-&gt;uid); if ($a2) &#123; $iserror = 1; $tourl = urlconfigs::URL_auto(array("m" =&gt; "user/information")); $pagecontent = "保存失败！&lt;br/&gt;"; $pagecontent .= "该邮箱已经存在！&lt;br/&gt;"; &#125; &#125; if ($iserror == 0) &#123; if (!ereg("^([a-zA-Z0-9_-])+@([a-zA-Z0-9_-])+(\.[a-zA-Z0-9_-])+", $info_emial)) &#123; $iserror = 1; $tourl = urlconfigs::URL_auto(array("m" =&gt; "user/information")); $pagecontent = "保存失败！&lt;br/&gt;"; $pagecontent .= "请填写正确的邮箱地址！&lt;br/&gt;"; &#125; &#125; if ($iserror == 0 and mb_strlen($info_sign, "utf-8") &gt; 60) &#123; $iserror = 1; $tourl = urlconfigs::URL_auto(array("m" =&gt; "user/information")); $pagecontent = "保存失败！&lt;br/&gt;"; $pagecontent .= "您输入的签名长度超过60，请删减！&lt;br/&gt;"; &#125; if ($iserror == 0 and mb_strlen($info_intro, "utf-8") &gt; 60) &#123; $iserror = 1; $tourl = urlconfigs::URL_auto(array("m" =&gt; "user/information")); $pagecontent = "保存失败！&lt;br/&gt;"; $pagecontent .= "您输入的个人简介长度超过60，请删减！&lt;br/&gt;"; &#125; &#125; if($iserror == 0)&#123; if($step == "ok")&#123; $db-&gt;query("UPDATE ".JIEQI_DB_PREFIX."_system_users SET name='".$info_nickname."',email='".$info_emial."',sex=".$info_sex.",sign='".$info_sign."',intro='".$info_intro."' WHERE uid=".$userinfo-&gt;uid); $tourl = urlconfigs::URL_auto(array("m"=&gt;"user/home")); $userinfo-&gt;name = $info_nickname; $userinfo-&gt;email = $info_emial; $userinfo-&gt;sex = $info_sex; $userinfo-&gt;sign = $info_sign; $userinfo-&gt;intro = $info_intro; $iserror = 1; $pagecontent = "保存成功！&lt;br/&gt;部分信息需要您重新登陆后才能显示最新信息哦！"; &#125;else&#123; $smartyObj-&gt;assign('getuserinfo',$db-&gt;query_object("select name,email,sex,sign,intro from ".JIEQI_DB_PREFIX."_system_users where uid=".$userinfo-&gt;uid)); &#125; &#125; if($iserror == 0)&#123; $smartydate = array("pagetitle" =&gt; "资料修改"); $tplpath = "user/information.tpl"; &#125;else&#123; $smartydate = array("pagetitle" =&gt; "资料修改", "pagecontent" =&gt; $pagecontent, "tourl" =&gt; $tourl, "redirecturl" =&gt; $tourl, ); $tplpath = "public.tpl"; &#125; $smartyObj-&gt;Creatpage($tplpath,$smartydate);&#125; info_sex性别的字段居然可以是字符串型，不转为整型，而且也没对它做长度检查。反倒是info_intro做了长度检查。经过sqlcheck后就进入以下语句直接查询了。 1$db-&gt;query("UPDATE ".JIEQI_DB_PREFIX."_system_users SET name='".$info_nickname."',email='".$info_emial."',sex=".$info_sex.",sign='".$info_sign."',intro='".$info_intro."' WHERE uid=".$userinfo-&gt;uid); 利用思路： 注册一个普通用户，然后利用注入修改用户组为管理员组。 修改用户信息的时候，拦截POST内容。然后修改`sex=1`为`sex=1,groupid=2`,杰奇cms是开源的，所以我能看到表字段，groupid为2的是系统管理员，有着后台所有权限。 搞定。 文件包含漏洞发现他升级了后台，数据库备份不能用，也不能上传PHP，因为系统默认限制这个。因为是Linux系统，所以也没一些目录解析漏洞可以利用。利用前提是magic_quotes_gpc 处于关闭状态。杰奇因为限制一定要要zend3.3.x解密，所以用的php版本是5.3以下的,这就有了文件名截断的漏洞可以利用，有了这个，文件包含漏洞也就更加有可能了。好在经过一番寻找，发现了一个文件包含漏洞，利用起来更加方便，可以直接getshell。就在处理动态加载脚本广告的时候。 book.class.php1234567891011public function ad()&#123; header('Content-type: text/javascript'); $addate = include_once("configs/ad/".$_GET["js"].".php"); $jsarray = explode("\n",$addate["adcontent"]); foreach($jsarray as $jsstr) &#123; echo "document.write(\""; echo str_replace("\r","",addslashes($jsstr)); echo "\");\n"; &#125; exit();&#125; 利用简述一下吧符合条件的,直接头像上传php一句话,后缀名为.jpg.取得图片地址. 构造url”http://domain/configs/ad/{头像相对路径}%00.php“ 截断后面的php即可. 后面的你都知道了.]]></content>
      <categories>
        <category>security</category>
      </categories>
      <tags>
        <tag>sql injection</tag>
        <tag>jieqicms</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django生成验证码]]></title>
    <url>%2Farticle%2F20180125%2Fdjango-simple-captcha%2F</url>
    <content type="text"><![CDATA[Django使用django-simple-captcha 生成验证码。 django-simple-captcha Github地址 安装 pip install django-simple-captcha 添加captcha 到 settings.py的INSTALLED_APPSL里面。 运行python manage.py migrate 生成数据表 配置urls.py 123urlpatterns += [ url(r'^captcha/', include('captcha.urls')),] 引用新建forms.py123456from captcha.fields import CaptchaFieldclass RegisterForm(forms.Form): email = forms.EmailField(required=True) password = forms.CharField(required=True, min_length=6) captcha = CaptchaField(error_messages=&#123;"invalid": u"验证码错误"&#125;) models.py直接验证表单是否通过，验证码字段会一并校验。12345678910111213141516class RegisterView(View): def get(self, request): register_form = RegisterForm() return render(request=request, template_name='register.html', context=&#123;"register_form": register_form&#125;) def post(self, request): register_form = RegisterForm(request.POST) if register_form.is_valid(): user_profile = UserProfile() user_name = request.POST.get('username', '') pass_word = request.POST.get('password', '') user_profile.username = user_name user_profile.email = user_name user_profile.password = make_password(password=pass_word) else: return render(request=request, template_name='register.html', context=&#123;"register_form": register_form&#125;) 参考资料Django-simple-captcha Document]]></content>
      <categories>
        <category>python</category>
        <category>django</category>
      </categories>
      <tags>
        <tag>captcha</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django使用form处理表单信息]]></title>
    <url>%2Farticle%2F20180123%2Fdjango-use-forms%2F</url>
    <content type="text"><![CDATA[form算是和一个和安全问题有关的一个东西了。 用来设置一些规则，对用户提交的字段进行一些筛选。 把不符合要求的字段过滤在外，这个一般前端也会做相应的处理。 但是有时候是可以被绕过的，比如提交正常的POST数据，然后拦截数据包，修改后，再POST。 新建&lt;path-to-your-app&gt;/forms.py比如我登录认证的表单中含有username和password两个字段，那我可以定义这两个字段的规则。 它的使用方式有点像我们定义models一样，都是前面变量为关键字段名，后面跟着字段类型和属性。 以下设置了两个字段为必填项，并且对长度做了一些限制123456from django import formsclass LoginForm(forms.Form): username = forms.CharField(required=True, max_length=50) password = forms.CharField(required=True, min_length=6) 然后可以在具体的逻辑中引用它 如我在前面一个文章中提到的登录验证中调用它is_valid()方法来认证views.py1234567891011121314151617class LoginView(View): def get(self, request): return render(request, 'login.html') def post(self, request): login_form = LoginForm(request.POST) if login_form.is_valid(): user_name = request.POST.get('username', '') pass_word = request.POST.get('password', '') user = authenticate(request, username=user_name, password=pass_word) if user is not None: login(request, user) return render(request, 'index.html') else: return render(request, 'login.html', &#123;"msg": "用户或密码错误"&#125;) else: return render(request, 'login.html', &#123;"login_form": login_form&#125;) 结果传递给页面，页面可以处理，并展示它的返回错误信息之类的。 如模板中遍历它错误的值，打印出来。1&#123;% for key,value in login_form.errors.items %&#125;&#123;&#123; value &#125;&#125;&#123;% endfor %&#125;]]></content>
      <categories>
        <category>python</category>
        <category>django</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django用户认证功能]]></title>
    <url>%2Farticle%2F20180122%2Fdjango-authentification-of-user%2F</url>
    <content type="text"><![CDATA[Django提供了比较方便的用户认证模块，只要导入它，就可以很方便就完成用户认证。 用户认证主流有两种写法，一个是直接写成函数，一个写成类，重载get和post方法 用函数实现&lt;path-to-your-app&gt;/views.py主要的函数就两个authenticate()和login()一个是认证登录，一个是保存登录信息。1234567891011121314from django.contrib.auth import authenticate, logindef login_view(request): if request.method == 'POST': user_name = request.POST.get('username', '') pass_word = request.POST.get('password', '') user = authenticate(request, username=user_name, password=pass_word) if user is not None: login(request, user) return render(request, 'index.html') else: return render(request, 'login.html', &#123;"msg": "用户或密码错误"&#125;) if request.method == 'GET': return render(request, 'login.html') 然后在urls.py12345678from users.views import login_viewurlpatterns = [ url(r'^xadmin/', xadmin.site.urls), url(r'^form/$', get_form), url(r'^$', TemplateView.as_view(template_name="index.html"), name="index"), url(r'^login/$', login_view),] 用类重载get，post方法实现（推荐）12345678910111213class LoginView(View): def get(self, request): return render(request, 'login.html') def post(self, request): user_name = request.POST.get('username', '') pass_word = request.POST.get('password', '') user = authenticate(request, username=user_name, password=pass_word) if user is not None: login(request, user) return render(request, 'index.html') else: return render(request, 'login.html', &#123;"msg": "用户或密码错误"&#125;) urls.py123456789from users.views import LoginViewurlpatterns = [ url(r'^xadmin/', xadmin.site.urls), url(r'^form/$', get_form), url(r'^$', TemplateView.as_view(template_name="index.html"), name="index"), # url(r'^login/$', login_view), url(r'^login/$', LoginView.as_view()),] 用户名或邮箱如果需要用户用邮箱也能登录，则重载authenticate方法就行了。首先定义和重载authenticate方法，调用用户模型，利用Q对象组合查询条件，实现或，且等条件查询。这里用|，或组合查询。确定存在这个账户后，调用check_password对比密码，如果符合，就返回用户信息。&lt;path-to-your-app&gt;/views.py12345678910111213141516from django.contrib.auth.backends import ModelBackendfrom django.db.models import Qfrom .models import UserProfile# Create your views here.class CustomBackend(ModelBackend): def authenticate(self, request, username=None, password=None, **kwargs): try: user = UserProfile.objects.get(Q(username=username) | Q(email=username)) if user.check_password(password): return user except Exception as e: return None 然后将上面的类注册到settings.py123AUTHENTICATION_BACKENDS = ( 'users.views.CustomBackend',) done.]]></content>
      <categories>
        <category>python</category>
        <category>django</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>authenticate</tag>
        <tag>authentificate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django 注册模型到xadmin管理和修改展示字段]]></title>
    <url>%2Farticle%2F20180122%2Fdjango-register-models-on-xadmin%2F</url>
    <content type="text"><![CDATA[添加了模型，想在后台管理，使用xadmin的话，和django有一点点不一样。 注册模型到后台在每个app下面新建一个adminx.py,导入相应的模型xadmin.site.register(UserFavorite, UserFavoriteAdmin)1234567891011121314151617181920212223242526272829303132333435363738394041# _*_ coding:utf-8 _*_import xadminfrom .models import UserMessage, UserAsk, UserCourse, UserFavorite, CourseCommetsclass UserMessageAdmin(object): list_display = ['user', 'message', 'has_read', 'add_time'] list_filter = ['user', 'message', 'has_read', 'add_time'] search_fields = ['user', 'message']class UserAskAdmin(object): list_display = ['name', 'mobile', 'course_name', 'add_time'] list_filter = ['name', 'mobile', 'course_name', 'add_time'] search_fields = ['name', 'mobile', 'course_name']class UserFavoriteAdmin(object): list_display = ['user', 'course', 'fav_id', 'fav_type', 'add_time'] list_filter = ['user', 'course', 'fav_id', 'fav_type', 'add_time'] search_fields = ['user', 'course']class CourseCommetsAdmin(object): list_display = ['user', 'course', 'comment', 'add_time'] list_filter = ['user', 'course', 'comment', 'add_time'] search_fields = ['user', 'course', 'comment']class UserCourseAdmin(object): list_display = ['user', 'course', 'add_time'] list_filter = ['user', 'course', 'add_time'] search_fields = ['user', 'course']xadmin.site.register(UserFavorite, UserFavoriteAdmin)xadmin.site.register(UserCourse, UserCourseAdmin)xadmin.site.register(UserAsk, UserAskAdmin)xadmin.site.register(UserMessage, UserMessageAdmin)xadmin.site.register(CourseCommets, CourseCommetsAdmin) list_display是在后台展示的列list_filter是在后台提供过滤器的字段search_fields是开启搜索功能的字段最后将模型和定义的模型管理注册一些。 修改模型名字注册到后台后，菜单那里默认显示的模型名是我们定义的英文名，要想改成中文，需要修改以下两个地方。 &lt;path-to-you-app&gt;/apps.py增加verbose_name 123class OperationConfig(AppConfig): name = 'operation' verbose_name = u'用户操作' &lt;path-to-you-app&gt;/__init__.py修改默认app配置为我们指定的。 1default_app_config = 'operation.apps.OperationConfig']]></content>
      <categories>
        <category>python</category>
        <category>django</category>
      </categories>
      <tags>
        <tag>xadmin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django Xadmin 常用设置]]></title>
    <url>%2Farticle%2F20180121%2Fdjango-xadmin-settings%2F</url>
    <content type="text"><![CDATA[xadmin github 地址: https://github.com/sshwsfc/xadmin 因为在使用的过程中避免不了会对xadmin做一些更改，所以，一般都是建议git clone源码到自己项目中使用。 替换django原有的admin也比较简单。 在urls.py中 12345import xadminurlpatterns = patterns('', url(r'xadmin/', xadmin.site.urls),) 即可 开启主题，后台站名和页脚文字修改在app的adminx.py中重载基础设置和全局设置。1234567891011121314from xadmin import viewsclass BaseSettings(object): enable_themes = True use_bootswatch = True # 一个主题插件class GlobalSettings(object): site_title = '开源课程网' site_footer = '开源课程网' menu_style = 'accordion' # 设置菜单可收缩,手风琴 accordionxadmin.site.register(views.BaseAdminView, BaseSettings)xadmin.site.register(views.CommAdminView, GlobalSettings) 待持续更新…也可能再也不更新… 2018/01/21]]></content>
      <categories>
        <category>python</category>
        <category>django</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>xadmin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django设置语言和时区]]></title>
    <url>%2Farticle%2F20180120%2Fdjango-set-language-timezone%2F</url>
    <content type="text"><![CDATA[忘记几次，还是打算记下来，虽然就三行。 123456# Internationalization# https://docs.djangoproject.com/en/1.9/topics/i18n/LANGUAGE_CODE = 'zh-hans'TIME_ZONE = 'Asia/Shanghai'USE_TZ = False 最后一个才是重点，否则保存时间的时候，还是使用UTC的时间。]]></content>
      <categories>
        <category>python</category>
        <category>django</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>time zone</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django设置搜索路径]]></title>
    <url>%2Farticle%2F20180120%2Fdjango-setup-search-path%2F</url>
    <content type="text"><![CDATA[总会遇到有些自定义的包或者自己生成的app需要放到一些特定的目录下，方便项目维护，让目录结构更加清晰。 但是把模块移动到非项目根目录下后，会遇到import错误。 这个时候需要设置下环境变量，将我们的目录加入到django运行时的环境变量中。 具体方法是，导入sys模块，插入自己的新目录地址。 我这里的样例如下： 123456import sys# Build paths inside the project like this: os.path.join(BASE_DIR, ...)BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))sys.path.insert(0, os.path.join(BASE_DIR, 'extra_apps'))sys.path.insert(0, os.path.join(BASE_DIR, 'apps'))]]></content>
      <categories>
        <category>python</category>
        <category>django</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>apps</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django导入xadmin源码模块出错]]></title>
    <url>%2Farticle%2F20180120%2Fdjango-xadmin-source-import-error%2F</url>
    <content type="text"><![CDATA[因项目需要对xadmin源码做修改，所以，没有直接使用pip安装的xadmin。卸载后，直接从github上下载了一份xadmin的最新版。 然后复制xadmin到项目当中，运行的时候发现少了一些模块。 用pip安装以下模块即可 1pip install future six httplib2 django-import-export 2018/01/21 更新是我瞎，其实源码路径下有个requestments.txt 安装里面的依赖包即可。]]></content>
      <categories>
        <category>troubleshooting</category>
        <category>django</category>
      </categories>
      <tags>
        <tag>xadmin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django继承用户模型，生成自己的用户表]]></title>
    <url>%2Farticle%2F20180119%2Fdjango-inherit-users-models%2F</url>
    <content type="text"><![CDATA[Django已经给我们提供了一个用户模型，但是它的字段不多，在某些场景下无法满足我们的使用需求，所以我们还要重新定义个数据模型，来描述我们用户数据表。 原来的auth_user表123456789101112131415+--------------+--------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+--------------+--------------+------+-----+---------+----------------+| id | int(11) | NO | PRI | NULL | auto_increment || password | varchar(128) | NO | | NULL | || last_login | datetime | YES | | NULL | || is_superuser | tinyint(1) | NO | | NULL | || username | varchar(30) | NO | UNI | NULL | || first_name | varchar(30) | NO | | NULL | || last_name | varchar(30) | NO | | NULL | || email | varchar(254) | NO | | NULL | || is_staff | tinyint(1) | NO | | NULL | || is_active | tinyint(1) | NO | | NULL | || date_joined | datetime | NO | | NULL | |+--------------+--------------+------+-----+---------+----------------+ 编辑我们的新建的用户app的models.py先import AbstractUser，然后定义我们的类的时候，继承它就好了。12345678910111213141516171819from django.contrib.auth.models import AbstractUser# Create your models here.class UserProfile(AbstractUser): nickname = models.CharField(verbose_name=u"用户名", max_length=50) birthday = models.DateField(verbose_name=u"生日", null=True, blank=True) gender = models.CharField(verbose_name=u"性别", choices=(("male", u'男'), ("female", u'女')), default="female", max_length=5) address = models.CharField(verbose_name=u"地址", max_length=100, default=u"") mobile = models.CharField(verbose_name=u"手机", max_length=11, null=True, blank=True) image = models.ImageField(verbose_name=u"头像", upload_to="images/%Y/%M", default=u"images/default.jpg") class Meta: verbose_name = u"用户资料" verbose_name_plural = verbose_name def __unicode__(self): return self.username 完事后在settings.py 注册我们的app， 再加上一条AUTH_USER_MODEL = &quot;users.UserProfile&quot; 指定我们新的用户模型生成数据表12makemigrations usersmigrate users 增加后新的表12345678910111213141516171819202122MySQL [opencourse]&gt; desc users_userprofile;+--------------+--------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+--------------+--------------+------+-----+---------+----------------+| id | int(11) | NO | PRI | NULL | auto_increment || password | varchar(128) | NO | | NULL | || last_login | datetime | YES | | NULL | || is_superuser | tinyint(1) | NO | | NULL | || username | varchar(30) | NO | UNI | NULL | || first_name | varchar(30) | NO | | NULL | || last_name | varchar(30) | NO | | NULL | || email | varchar(254) | NO | | NULL | || is_staff | tinyint(1) | NO | | NULL | || is_active | tinyint(1) | NO | | NULL | || date_joined | datetime | NO | | NULL | || nickname | varchar(50) | NO | | NULL | || birthday | date | YES | | NULL | || gender | varchar(5) | NO | | NULL | || address | varchar(100) | NO | | NULL | || mobile | varchar(11) | YES | | NULL | || image | varchar(100) | NO | | NULL | |+--------------+--------------+------+-----+---------+----------------+ done.]]></content>
      <categories>
        <category>python</category>
        <category>django</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django数据模型增删改查]]></title>
    <url>%2Farticle%2F20180119%2Fdjango-models-crud%2F</url>
    <content type="text"><![CDATA[先导入自己的数据模型from .models import UserMessage 增123456user_message = UserMessage()user_message.name = 'bob'user_message.email = 'test@qq.com'user_message.address = 'guangzhou'user_message.message = 'sth.'user_message.save() 结果：123456MySQL [opencourse]&gt; select * from message_usermessage;+----+------+-------------+-----------+---------+| id | name | email | address | message |+----+------+-------------+-----------+---------+| 1 | bob | test@qq.com | guangzhou | sth. |+----+------+-------------+-----------+---------+ 删删除的话，调用继承过来的delete()方法即可。下面删除ID为1的结果12345 user_message = UserMessage.objects.filter(id=1)# user_message = UserMessage.objects.all()# user_message.delete() for message in user_message: message.delete() 可以直接user_message.delete()所有符合结果的都删除，或者遍历删除，看情况选择使用。12for message in user_message: message.delete() 改两种方法12user_message = UserMessage.objects.filter(id=1)user_message.update(address='shenzhen') 或者123user_message = UserMessage.objects.get(id=1)user_message.address = 'nanjing'user_message.save() 结果12345678910111213141516第一种方法MySQL [opencourse]&gt; select * from message_usermessage;+----+------+-------------+----------+---------+| id | name | email | address | message |+----+------+-------------+----------+---------+| 1 | bob | test@qq.com | shenzhen | sth. |+----+------+-------------+----------+---------+1 row in set (0.00 sec)第二种方法结果MySQL [opencourse]&gt; select * from message_usermessage;+----+------+-------------+---------+---------+| id | name | email | address | message |+----+------+-------------+---------+---------+| 1 | bob | test@qq.com | nanjing | sth. |+----+------+-------------+---------+---------+1 row in set (0.00 sec) 查询查询方法还是灵活多变的。filter和get区别。简单来说get的如果多于两条数据，或者没有数据就会报错，它返回对象形式。而filter会返回数组形式。12345UserMessage.objects.all()UserMessage.objects.all().values('name') # 只取user列UserMessage.objects.all().values_list('id', 'name') # 取出id和name列UserMessage.objects.get(id=1)UserMessage.objects.filter(name='bob') 参考资料Django-Model操作数据库(增删改查、连表结构）]]></content>
      <categories>
        <category>python</category>
        <category>django</category>
      </categories>
      <tags>
        <tag>CRUD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django数据库模型生成数据表]]></title>
    <url>%2Farticle%2F20180119%2Fdjango-make-models%2F</url>
    <content type="text"><![CDATA[django是通过ORM访问数据库的，所以，它需要自己定义数据模型。 打开相应app/models.py123456789class UserMessage(models.Model): name = models.CharField(verbose_name=u"名字", max_length=50) email = models.EmailField(verbose_name=u"邮箱地址") address = models.CharField(verbose_name=u"联系地址", max_length=100) message = models.CharField(verbose_name=u"留言", max_length=100) class Meta: verbose_name = u'用户记录' verbose_name_plural = verbose_name 定义字段，字段类型，长度，描述名。除了上诉的字符类型，还有以下的数据类型可以定义12345678910__all__ = [str(x) for x in ( 'AutoField', 'BLANK_CHOICE_DASH', 'BigIntegerField', 'BinaryField', 'BooleanField', 'CharField', 'CommaSeparatedIntegerField', 'DateField', 'DateTimeField', 'DecimalField', 'DurationField', 'EmailField', 'Empty', 'Field', 'FieldDoesNotExist', 'FilePathField', 'FloatField', 'GenericIPAddressField', 'IPAddressField', 'IntegerField', 'NOT_PROVIDED', 'NullBooleanField', 'PositiveIntegerField', 'PositiveSmallIntegerField', 'SlugField', 'SmallIntegerField', 'TextField', 'TimeField', 'URLField', 'UUIDField',)] 在&lt;path-to-your-project&gt;/settings.py添加自己的app到INSTALLED_APPS123456789INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'message',] 然后运行命令12345678910111213141516manage.py@opencourse &gt; makemigrations messageMigrations for &apos;message&apos;: 0001_initial.py: - Create model UserMessageFollowing files were affected /g/project/opencourse/apps/message/migrations/0001_initial.pyProcess finished with exit code 0manage.py@opencourse &gt; migrate messagemigrate message /g/project/opencourse&quot;Operations to perform: Apply all migrations: messageRunning migrations: Rendering model states... DONE Applying message.0001_initial... OKProcess finished with exit code 0 这个时候就可以看到数据库已经生成了一个新的表：12345678910111213141516171819202122232425262728293031MySQL [opencourse]&gt; show tables;+----------------------------+| Tables_in_opencourse |+----------------------------+| auth_group || auth_group_permissions || auth_permission || auth_user || auth_user_groups || auth_user_user_permissions || django_admin_log || django_content_type || django_migrations || django_session || message_usermessage |+----------------------------+11 rows in set (0.00 sec)MySQL [opencourse]&gt; desc message_usermessage;+---------+--------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+---------+--------------+------+-----+---------+----------------+| id | int(11) | NO | PRI | NULL | auto_increment || name | varchar(50) | NO | | NULL | || email | varchar(254) | NO | | NULL | || address | varchar(100) | NO | | NULL | || message | varchar(100) | NO | | NULL | |+---------+--------------+------+-----+---------+----------------+5 rows in set (0.00 sec)MySQL [opencourse]&gt; 除此之外，还可以定义索引，自定义表名等。 ##参考资料 Model field referenceModel Meta options]]></content>
      <categories>
        <category>python</category>
        <category>django</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>models</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django渲染模板文件]]></title>
    <url>%2Farticle%2F20180118%2Fdjango-load-templates-files%2F</url>
    <content type="text"><![CDATA[编写views方法，渲染模板 设置静态文件路径 设置URL规则 编写渲染的方法在相应的app下面找到views.py&lt;path-to-your-app&gt;/views.py12def getform(request): return render(request,'message_form.html') 设置静态文件路径因为模板引用了一些静态资源，但是你得告诉django它路径在哪里。新增配置STATICFILES_DIRS，指定静态URL。1234STATIC_URL = '/static/'STATICFILES_DIRS = [ os.path.join(BASE_DIR,'static'),] ## 编辑&lt;path-to-your-project&gt;/urls.py先导入自己的app的getform方法，配置URL url(r&#39;^form/$&#39;,getform)12345from &lt;path-to-your-app&gt;.views import getformurlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^form/$',getform),] done.]]></content>
      <categories>
        <category>python</category>
        <category>django</category>
      </categories>
      <tags>
        <tag>django render</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django配置MySQL数据库]]></title>
    <url>%2Farticle%2F20180117%2Fdjango-mysql-settings%2F</url>
    <content type="text"><![CDATA[##更改配置 &lt;project_name&gt;/settings.py 一开始是使用sqlite3的，改成MySQL的就好123456789DATABASES = &#123; &apos;default&apos;: &#123; &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;, &apos;NAME&apos;: &apos;opencourse&apos;, &apos;USER&apos;: &apos;opencourse&apos;, &apos;PASSWORD&apos;: &apos;opencourse&apos;, &apos;HOST&apos;: &apos;172.25.254.10&apos; &#125;&#125; 安装驱动 *如果没有安装MySQL驱动的，就pip install MySQL-python 安装一个.如果出现错误，提示没有找到mysql_config的。Ubuntu类的安装apt install libmysqlclient-dev,Redhat类yum install -y mysql-devel 在确保安装了libmysqlclient-dev或者mysql-devel的同学，如果使用pycharm的话，直接File-&gt;Settins-&gt;Project Interpreter点加号+ 搜索mysql,然后点击Install Package即可。 生成数据库表python manage.py makemigrations,或者pycharm中，Tools-&gt;Run manage.py Task 直接输入makemigrations，然后migrate。 如下：12345678910111213141516171819manage.py@opencourse &gt; makemigrationsNo changes detectedmanage.py@opencourse &gt; migrateOperations to perform: Apply all migrations: admin, contenttypes, auth, sessionsRunning migrations: Rendering model states... DONE Applying contenttypes.0001_initial... OK Applying auth.0001_initial... OK Applying admin.0001_initial... OK Applying admin.0002_logentry_remove_auto_add... OK Applying contenttypes.0002_remove_content_type_name... OK Applying auth.0002_alter_permission_name_max_length... OK Applying auth.0003_alter_user_email_max_length... OK Applying auth.0004_alter_user_username_opts... OK Applying auth.0005_alter_user_last_login_null... OK Applying auth.0006_require_contenttypes_0002... OK Applying auth.0007_alter_validators_add_error_messages... OK Applying sessions.0001_initial... OK]]></content>
      <categories>
        <category>python</category>
        <category>django</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python使用filter map reduce的简单例子]]></title>
    <url>%2Farticle%2F20171127%2Fpython-prime-filter-reduce-map%2F</url>
    <content type="text"><![CDATA[第一个print是100内的质数列表。第二个是列表的数字求和第三个是列表数字换成它的平方数 123456789101112131415#!/usr/bin/env pythondef is_prime(x): if x&lt;=1: return False for i in range(2,x): if x % i == 0: return False return Trueif __name__ == '__main__': n = [x for x in range(1,101)] # 生成1-199的列表 print(filter(is_prime,n)) # 筛选出100内的质数 print(reduce(lambda x,y:x+y,n)) # 用reduce特性求和 print(map(lambda x:x*x,n)) # 用map求平方 Output:123[2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97]5050[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98, 100, 102, 104, 106, 108, 110, 112, 114, 116, 118, 120, 122, 124, 126, 128, 130, 132, 134, 136, 138, 140, 142, 144, 146, 148, 150, 152, 154, 156, 158, 160, 162, 164, 166, 168, 170, 172, 174, 176, 178, 180, 182, 184, 186, 188, 190, 192, 194, 196, 198, 200] 参考资料:PEP 8 – Style Guide for Python Code]]></content>
      <categories>
        <category>python</category>
        <category>foundation</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>reduce</tag>
        <tag>map</tag>
        <tag>filter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx配置https出现no ssl_certificate错误]]></title>
    <url>%2Farticle%2F20171122%2Ftroubleshooting-nginx-https-error-no-ssl-certificate%2F</url>
    <content type="text"><![CDATA[今天给测试环境配置https的时候遇到了问题。 先后排除了证书错误，防火墙，nginx -V确定相关模块存在，但是依然不行。 查看 nginx error日志 发现如下结果： 12017/11/22 12:18:11 [error] 18365#18365: *10 no &quot;ssl_certificate&quot; is defined in server listening on SSL port while SSL handshaking, client: 120.197.49.xxx, server: 0.0.0.0:443 寻找资料，提到是监听了443端口，但是没有指定证书之类的东西。 于是我cat /etc/nginx/conf.d/* | grep 443发现一条123456server &#123; listen *:443 default; server_name _; return 444; access_log off;&#125; 之前为了屏蔽空主机名瞎访问，我添加了一条80端口的，又想当然地配置了一个443的。 现在把这个注释掉，重启nginx。一切正常。 参考资料参考资料]]></content>
      <categories>
        <category>troubleshooting</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux挂载NTFS但是不可写 Read-only]]></title>
    <url>%2Farticle%2F20171119%2Ftroubleshooting-ntfs-cant-read-only%2F</url>
    <content type="text"><![CDATA[错误提示： xxx :Read-only file system 尝试了用 ntfs-3g挂载，fstab也写明是rw权限，但是就是不行。 最后还是用 sudo ntfsfix /dev/sdbxxx 指定NTFS格式的磁盘。 然后remount一下就好了。 —更新 主要原因还是windows开启了快速启动。 12345 The disk contains an unclean file system (0, 0).Metadata kept in Windows cache, refused to mount.Falling back to read-only mount because the NTFS partition is in anunsafe state. Please resume and shutdown Windows fully (no hibernationor fast restarting.) metadata存在cache，Linux挂载的时候，不敢清除这些cache，所以只能以只读方式打开。 在BIOS关闭快速启动后，如果还不行，进去windows，电源-更改当前不可用设置-快速启动去掉。]]></content>
      <categories>
        <category>troubleshooting</category>
      </categories>
      <tags>
        <tag>mount</tag>
        <tag>read-only</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python求二叉树最大深度]]></title>
    <url>%2Farticle%2F20171109%2Fpython-binary-tree-max-depth%2F</url>
    <content type="text"><![CDATA[继前面Python二叉树递归和遍历 二叉树图 123456def max_depth(node): if not node: return 0 ldepth = max_depth(node.left) rdepth = max_depth(node.right) return max(ldepth,rdepth) + 1 结果：4]]></content>
      <categories>
        <category>python</category>
        <category>algorithms</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>binary tree</tag>
        <tag>max depth</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Crontab执行命令失败 手工执行成功]]></title>
    <url>%2Farticle%2F20171109%2Foperations-crontab-execute-fialed%2F</url>
    <content type="text"><![CDATA[今天开发说有一台服务器crontab任务执行异常。 同样的账户上去手动运行命令就能正确执行该命令。当时就感觉遇到灵异事件了。 吃完饭再仔细看看。 先把crontab要执行的命令重定向错误输出到文件。 1*/ * * * * xxxx xxxx &gt; ~/errors 2&gt;&amp;1 发现是如下错误： /usr/bin/env: php: No such file or directory 说找不到PHP。基本可以判定是环境变量问题。可能当初php安装的时候没有加入到一个常用的路径中。 which php 得到php路径。 新建了一个脚本专门执行这条之前的命令，前面指定。 123#!/bin/bashexport PATH=$PATH:/usr/local/binxxxx xxxx 或者直接导入环境变量再执行。 1*/ * * * * source ~/.bashrc &amp;&amp; xxxx xxxx &gt; ~/errors 2&gt;&amp;1]]></content>
      <categories>
        <category>troubleshooting</category>
      </categories>
      <tags>
        <tag>crontab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python二叉树递归和遍历]]></title>
    <url>%2Farticle%2F20171108%2Fpython-algorithms-btree-recursive-traversal%2F</url>
    <content type="text"><![CDATA[描述树有这么一个二叉树 上面图片由graphviz生成，描绘该树的.dot文件内容如下： 1234567891011121314151617181920digraph G &#123; node [shape = record ,height=.1]; node0[label = &quot;&lt;f0&gt; |&lt;f1&gt; A|&lt;f2&gt; &quot;]; node1[label = &quot;&lt;f0&gt; |&lt;f1&gt; B|&lt;f2&gt; &quot;]; node2[label = &quot;&lt;f0&gt; |&lt;f1&gt; C|&lt;f2&gt; &quot;]; node3[label = &quot;&lt;f0&gt; |&lt;f1&gt; D|&lt;f2&gt; &quot;]; node4[label = &quot;&lt;f0&gt; |&lt;f1&gt; E|&lt;f2&gt; &quot;]; node5[label = &quot;&lt;f0&gt; |&lt;f1&gt; F|&lt;f2&gt; &quot;]; node6[label = &quot;&lt;f0&gt; |&lt;f1&gt; G|&lt;f2&gt; &quot;]; node7[label = &quot;&lt;f0&gt; |&lt;f1&gt; H|&lt;f2&gt; &quot;]; node8[label = &quot;&lt;f0&gt; |&lt;f1&gt; I|&lt;f2&gt; &quot;]; &quot;node0&quot;:f0 -&gt; &quot;node1&quot;:f1; &quot;node0&quot;:f2 -&gt; &quot;node2&quot;:f1; &quot;node1&quot;:f2 -&gt; &quot;node3&quot;:f1; &quot;node2&quot;:f0 -&gt; &quot;node4&quot;:f1; &quot;node2&quot;:f2 -&gt; &quot;node5&quot;:f1; &quot;node4&quot;:f0 -&gt; &quot;node6&quot;:f1; &quot;node5&quot;:f0 -&gt; &quot;node7&quot;:f1; &quot;node5&quot;:f2 -&gt; &quot;node8&quot;:f1;&#125; 生成树图：dot -Tgif btree.dot -o btree.gif 该树用Python描述如下：1234567891011121314151617181920class TreeNode(object): def __init__(self,data,left=None,right=None): self.data = data self.left = left self.right = right def __str__(self): return str(self.data)def create_btree(): A,B,C,D,E,F,G,H,I = [TreeNode(x) for x in 'ABCDEFGHI'] A.left = B A.right = C B.right = D C.left = E C.right = F E.left = G F.left = H F.right = I return A 类TreeNode用来描述二叉树结构。create_btree函数用来生成上图描述的树，并返回根节点。 深度优先搜索递归遍历二叉树前序遍历1234567# Depth-first Searchdef preorder(node): if node is None: return print(node.data) preorder(node.left) preorder(node.right) 中序遍历123456def inorder(node): if node is None: return inorder(node.left) print(node.data) inorder(node.right) 后序遍历123456def postorder(node): if node is None: return postorder(node.left) postorder(node.right) print(node.data) 迭代遍历二叉树前序遍历123456789101112def preorder_iter(root): s = [] node = root while True: while node: print(node) s.append(node) node = node.left if not s: break node = s.pop().right 广度优先搜索层序遍历用队列实现，子节点插后面，子节点的子节点也插在队列后面，从队列左边访问，永远都是层数高的在前面，实现层序遍历。 1234567891011121314# Breadth-first Searchfrom collections import dequedef level_order(node): s = deque() while True: print(node) if node.left: s.append(node.left) if node.right: s.append(node.right) if not s: break node = s.popleft() 运行、结果123456789101112if __name__ == '__main__': root = create_btree() print('preorder:') preorder(root) print('inorder:') inorder(root) print('postorder:') postorder(root) print('preorder_iter') preorder_iter(root) print('level_order') level_order(root) 结果:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950preorder:ABDCEGFHIinorder:BDAGECHFIpostorder:DBGEHIFCApreorder_iterABDCEGFHIlevel_orderABCDEFGHI 参考资料Tree TraversalBinay Tree]]></content>
      <categories>
        <category>python</category>
        <category>algorithms</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>btree</tag>
        <tag>binary tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构 流程图等的做图工具推荐 graphviz]]></title>
    <url>%2Farticle%2F20171108%2Ftools-graphviz%2F</url>
    <content type="text"><![CDATA[来自 AT&amp;T 实验室。 有时候需要做一些图，比如流程图，数据结构图之类的。自己画吧，不工整，排版又头疼。最后发现了一款这玩意。 一些用这个工具做的效果在这里 http://www.graphviz.org/Gallery.php 参考资料下载地址帮助文档CSDN一些应用示例dotguidePython生成Btree]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>tools</tag>
        <tag>graphviz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python生成器 生产消费者模型 迭代器]]></title>
    <url>%2Farticle%2F20171103%2Fpython-generator-producer-consumer%2F</url>
    <content type="text"><![CDATA[环境： Python 3.5 列表解析和生成器假设要生成一个1到10000的列表a，供其它功能去遍历它的话。 用Python列表解析的话，如下： 1a = [ x for x in range(1,10000)] 但是有这么一个情况。我每次也不是非要遍历完这个列表，而且某些情况我可能根本不会用到这个列表。 但是一开始就定义好这个列表。它是会即时生成这个列表。如果这个表很大，毫无疑问比较浪费时间，和占用内存。 应对上述的问题，可以用生成器来解决。 1a = ( x for x in range(1,10000)) 语法上和列表解析的差别主要就是一个是用[],一个是用() 同样，可以用for去遍历它 12for n in a: print(n) 另外可以通过next属性去访问它的值。12345678910# python 2.x 属性是 next()# python 3.x 属性是 __next()# 所以建议用next()获取 比较通用点。whlie True: try: n = next(a) print('n:', n) except StopIteration as e: print('Generator return value:', e.value) break Generator function现在知道了( x for x in range(1,10000))这种生成器形式。但是我想要生成更复杂点的数据怎么办？ 比如斐波那契数列。这个时候就用到yield了，通过yield去生成生成器的数据。简单点理解，它就是普通函数的return，只不过yield是专门将数据返回给生成器。 123456# 生成10位fabnacci数列def fab(): a,b=1,1 for i in range(1,10): yield a a,b=b,a+b console查看类型如下： 1234In [2]: fabnacci = fab()In [3]: type(fabnacci)Out[3]: generator 打印数据： 1234567891011In [6]: for i in fabnacci: print(i) 112358132134 生产者消费者模型 协程关于对生成器的应用，一个很好的例子是实现生产者消费者模型 执行由串行变成并行。 1234567891011121314151617def consumer(name): print("I'm crazy &#123;name&#125;,I'm ready to kill some mother fucker.".format(name=name)) while True: fucker = yield print('&#123;name&#125;:&#123;fucker&#125; guys has been killed.'.format(name=name,fucker=fucker))def producer(): tom = consumer('Tom') bob = consumer('Bob') next(tom) next(bob) for i in range(1,10): tom.send(i) bob.send(i)producer() Out: 1234567891011121314151617181920I&apos;m crazy Tom,I&apos;m ready to kill some mother fucker.I&apos;m crazy Bob,I&apos;m ready to kill some mother fucker.Tom:1 guys has been killed.Bob:1 guys has been killed.Tom:2 guys has been killed.Bob:2 guys has been killed.Tom:3 guys has been killed.Bob:3 guys has been killed.Tom:4 guys has been killed.Bob:4 guys has been killed.Tom:5 guys has been killed.Bob:5 guys has been killed.Tom:6 guys has been killed.Bob:6 guys has been killed.Tom:7 guys has been killed.Bob:7 guys has been killed.Tom:8 guys has been killed.Bob:8 guys has been killed.Tom:9 guys has been killed.Bob:9 guys has been killed. 可迭代对象和迭代器 可以迭代的主要分两种，一个是可迭代对象（Iterable）的和迭代器（Iterator）。 迭代器一定是可迭代对象，可迭代对象不一定是迭代器。 可迭代对象都可以用for x in xx:语句来遍历对象。 而迭代器还可以用next()函数逐个访问下一个值。遍历结束会遇到StopIteration异常。 可以看做迭代器是可迭代对象一个更高级的实现。 如何判断 可以用isinstance函数来查看。 记得先导入Iterable，Iterator。 12from collections import Iterablefrom collections import Iterator 123456789101112131415In [19]: fabnacci = fab()In [20]: a = [ x for x in range(1,10000)]In [21]: isinstance(fabnacci,Iterable)Out[21]: TrueIn [22]: isinstance(fabnacci,Iterator)Out[22]: TrueIn [23]: isinstance(a,Iterable)Out[23]: TrueIn [24]: isinstance(a,Iterator)Out[24]: False 可以用dir函数查看是否有next的方法 如果存在就是迭代器。 如何转换用iter()函数。可以将iterable的数据变为iterator。]]></content>
      <categories>
        <category>python</category>
        <category>foundation</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>generator</tag>
        <tag>producer</tag>
        <tag>consumer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Let's Encrypted申请SSL证书 实现HTTPS]]></title>
    <url>%2Farticle%2F20171024%2Fadd-letsencrypted-certificate%2F</url>
    <content type="text"><![CDATA[之前的话，一直在阿里云申请免费的赛门铁克的SSL证书。但是如果站点多，又有不同客户的话，全放一个地方其实也不太合适，另外申请时间也稍微慢点，要等个好几分钟，有时候半个小时。管理起来比较麻烦。 所以再三考虑，使用了let’s encrypted这货也是免费的。更加极客点，相对来讲，权威性没赛门铁克那么高，不过都得到大部分浏览器厂商的认可，所以还是能用的。 由于开放了申请接口，所以部分工具或者网站源码集成了申请证书的功能。我知道的有 cPanel，宝塔，WordPress之类的。 let’s encrypted 证书有效期只有60天，还是蛮短的。不过好在它提供了很多好用的脚本或者程序来提供我们续签，整体来说还是比较方便的。 ACME是它一个提供用来辅助申请的脚本，大大简化了申请流程，有些做到可视化，还算是比较方便的。涵盖了各种语言。 ACME客户端列表 我的话用 ACME.sh 测试SSL强度 nginx如果有配置限制了 .* 目录的访问的话，要修改确保 web目录下 .well-known 目录下的内容可访问。]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>ssl</tag>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LN链接文件include路径异常情况。]]></title>
    <url>%2Farticle%2F20171017%2Ftroubleshooting-php-ln-include-error%2F</url>
    <content type="text"><![CDATA[昨天有开发叫把部署时候，替换配置文件原本用cp换成ln。说是为了修改配置方便。 但是如果一个目录有很多个配置，含子目录，用ln -r是不行的。逐个ln很是麻烦。 不过，开发说啥就是啥。。。 但是今天一些URL访问出现异常。 大致错误如下。 1PHP message: PHP Fatal error: require(): Failed opening required '/wwwroot/resources_do_not_delete/xxxx/frontend/web/../../common/config/bootstrap.php' (include_path='.:/app/php56/lib/php') in /wwwroot/resources_do_not_delete/xxxx/frontend/web/index.php on line 7" while reading response header from upstream, client: 14.xxx.xxx.180, server: qdtest.laoganbu.cn, request: "GET /help-web/index HTTP/1.1", upstream: "fastcgi://127.0.0.1:9000", host: "xxx.xxx.cn" 发现php文件 require文件的时候，路径跑到被链接的文件目录去了。而我们所需要的是获取链接文件所在的目录下的文件。 知道问题就好办了。把ln -s改为ln -d硬链接。 可以自己写个php，然后分别用这两种方式做链接到web目录。 123&lt;? echo __DIR__;?&gt; usage： ln -[s|d] 源文件 链接文件 测试结果如下：ln -s : 源文件所在的目录ln -d : 链接文件所在的目录]]></content>
      <categories>
        <category>troubleshooting</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>ln</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[file_get_contents 获取HTTPS链接内容出错]]></title>
    <url>%2Farticle%2F20171013%2Fphp-file-get-contents-errors-troubleshooting%2F</url>
    <content type="text"><![CDATA[今天遇到php用 file_get_contents 函数获取 https 链接的数据的时候，遇到如下错误。 1operation failed with code 1. OpenSSL Error messages:error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed 我服务器环境是 Centos 7. 检查已经安装了 openssl包，并在php.ini中开启了 php_openssl 模块。测试发现问题依旧，最后在stackoverflow上找到了答案。 在php.ini中增加一行 openssl.cafile=/etc/pki/tls/certs/ca-bundle.crt 至于如果不确定php的配置文件位置，最好用phpinfo函数打印出来看看。如果机子只有单个环境 直接执行php -i | grep config 找。]]></content>
      <categories>
        <category>troubleshooting</category>
      </categories>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux远程连接Windows桌面工具]]></title>
    <url>%2Farticle%2F20170831%2Ftools-rdp-remmina-rdesktop%2F</url>
    <content type="text"><![CDATA[机子Ubuntu，之前一直用的rdesktop连接的远程桌面。 由于是命令行，加上不常用，总会经常性忘记命令参数，又要查阅帮助，不慎其烦。而且也不能保存密码。 于是苦苦搜寻，还真找到一款满意的工具。支持 RDP和SSH协议。 似乎前身就是 csclient 官网：http://www.remmina.org/ 源码:https://github.com/FreeRDP/Remmina/wiki 安装 123sudo apt-add-repository ppa:remmina-ppa-team/remmina-nextsudo apt-get updatesudo apt-get install remmina remmina-plugin-rdp libfreerdp-plugins-standard 用法： 图形简单清晰，不用介绍]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>tools</tag>
        <tag>rdesktop</tag>
        <tag>remmina</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pygame实现的太空射击类小游戏]]></title>
    <url>%2Farticle%2F20170825%2Fpython-pygame-fantasyshooter%2F</url>
    <content type="text"><![CDATA[FantasyShooter入门必搞的太空射击小游戏。 如果还没安装pygame模块的 sudo pip install pygame or pip install -r requirements.txt 安装好模块后直接 python fantasyshooter.py 即可进行激情射击。 目前实现： 敌机 炸弹 战机 子弹 统计分数和miss数 项目代码下载地址]]></content>
      <categories>
        <category>python</category>
        <category>pygame</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pygame</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python的常见类型]]></title>
    <url>%2Farticle%2F20170814%2Fpython-foundation-more-types%2F</url>
    <content type="text"><![CDATA[NoneNone一句话就是有点类似其它语言的NULL。是个无类型的值。None等于False。 Dictionaries 字典类型。其实就是常见的 Key =&gt; Value 键值对类型，当索引的key不存在的时候，会抛出KeyError 类型实例 1234mydict = &#123;'a':1,'b':2&#125;print(mydict['a'])1 字典类型的key必须是不可以变的。 字典的赋值十分简单，无论key存在与否，都可以直接赋值。存在的话就改变值，不存在就自动新建一个。 判断key是否存在 in 和 not in例子： 12345678nums = &#123; 1:'a', 2:'b', 3:'c', &#125;print(1 in nums)print(a not in nums)print(3 in nums) 结果：123TrueTrueTrue 字典一个比较有用的函数 get当你访问一个不存在的key的时候，它会返回一个特殊值None，还可以自定义缺省值，找不到就返回某个值。 例子： 12345678nums = &#123; 1:'a', 2:'b', 3:'c', &#125;print(nums.get(1))print(nums.get(4))print(nums.get(4,"字典里没有4")) 结果：123aNone字典里没有4]]></content>
      <categories>
        <category>python</category>
        <category>foundation</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python数组append比insert有效率]]></title>
    <url>%2Farticle%2F20170814%2Fpython-foundation-insert-append%2F</url>
    <content type="text"><![CDATA[由于list的实现不是传统意义上的链表实现，采用的是在一块连续的内存空间。所以在Insert的时候，经常要将插入的位置右边的数据挪一下。而append并不需要。 所以能用append的尽量用append。]]></content>
      <categories>
        <category>python</category>
        <category>foundation</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7 安装最新版Jenkins]]></title>
    <url>%2Farticle%2F20170805%2Fcentos-install-jenkins-latest-version%2F</url>
    <content type="text"><![CDATA[配置jenkins源12sudo wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins-ci.org/redhat/jenkins.reposudo rpm --import https://jenkins-ci.org/redhat/jenkins-ci.org.key 直接 yum install jenkins是安全版本非最新版。 可以去 https://pkg.jenkins.io/redhat-stable/下载自己喜欢的版本比如我安装最新版1yum install https://pkg.jenkins.io/redhat-stable/jenkins-2.89.4-1.1.noarch.rpm vim /etc/sysconfig/jenkins 编辑下配置文件 我主要改了端口和home目录 启动 1systemctl start/enable jenkins http://120.79.138.224:10086/generic-webhook-trigger/invoke?token=offence-reporting-servicehttps://wiki.jenkins.io/display/JENKINS/CloudBees+Docker+Build+and+Publish+plugin #参考资料 Installing Jenkins on Red Hat distributions]]></content>
      <categories>
        <category>other</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用supervisor来监控进程]]></title>
    <url>%2Farticle%2F20170713%2Fpython-supervisor-process-moniter%2F</url>
    <content type="text"><![CDATA[Supervisor简述关于Java进程监控，一直都是要搞的。至于怎么实现，一直比较纠结，也就拖了很久。 最近看到supervisor，感觉还不错，打算试试。 简单简单一句话描述supervisor的作用的话。 可以把一个命令变成daemon进程管理，可以实现异常重启 另外还提供了API，这为提供WEB式管理提供了便利，官方有带了一个简陋的web界面，也有一些第三方的似乎看起来也不错。 通过supervisor运行的，都成为supervisor的子进程，它也是通过这个去管理进程，比通过pid文件管理更稳定。因为有时候进程异常退出，pid存放的数据就是错的，有可能导致其它进程被意外终结。 支持的平台Supervisor works on just about everything except for Windows. 准确点说，基本UNIX-Like系统都支持。 主要组件supervisordsupervisor的服务进程，响应客户端的命令、管理子进程 使用的时候要读取配置文件。寻找配置文件的优先级如下: 123456$CWD/supervisord.conf$CWD/etc/supervisord.conf/etc/supervisord.conf/etc/supervisor/supervisord.conf (since Supervisor 3.3.0)../etc/supervisord.conf (Relative to the executable)../supervisord.conf (Relative to the executable) 不过建议还是启动的时候，制定配置文件所在的绝对路径。 supervisorctlsupervisor的命令行客户端 配置项在 [supervisorctl] Web Serversupervisor的web服务，web提供少量功能管理supervisor。 配置[inet_http_server]项 XML-RPCAPI接口 介绍：XML-RPC API Documentation 安装 sudo pip install supervisor or esay_install supervisor 安装完运行echo_supervisord_conf，如果能输出配置，那就安装完成了。 使用说明配置其实在echo_supervisord_conf后，前面几行就有官方的配置说明文档链接:http://supervisord.org/configuration.html 不过未免巨细无遗了。 根据需求，我们需要监控进程，需要可以在线管控进程状态，简单配置几项就行了。配置文件语法是Windows-INI Style。 创建配置启动supervisord组件的时候，它会从前面提到的搜寻文件路径，按优先级去找配置文件。为了避免加载到非我们修改的配置，建议启动的时候-c指定一些配置文件。 这里为了方便管理配置文件，我把它放到/etc/supervisor/supervisor.conf program的配置文件放到 `./conf.d/.conf` * 12# mkdir -p /etc/supervisor/conf.d/# echo_supervisord_conf &gt; /etc/supervisor/supervisor.conf 修改配置 vim /etc/supervisor/supervisor.conf 主要改动如下内容: 1234[inet_http_server] ; inet (TCP) server disabled by defaultport=127.0.0.1:9001 ; ip_address:port specifier, *:port for all ifaceusername=onecer ; default is no username (open server)password=youpassword ; default is no password (open server) 这里port，如果你想可以通过外网IP+端口访问web dashboard，那就改为*:9001或者0.0.0.0:9001 这里我打算到时候用nginx做反向代理，绑定域名，所以就无所谓，127.0.0.1 。 username和password就是管理账户。 12[include]files = conf.d/*.conf 这里原本是ini后缀的，但是我想入乡随俗，在linux就改为conf后缀的配置文件吧。用的相对路径，如果我们加载的是/etc/supervisor/supervisor.conf 那这个就表加载/etc/supervisor/conf.d/目录下所有的conf文件。 事实这个可以省了，program配置直接写在主配置文件里面。不过，如果程序多的话，还是建议分开。像nginx一样，这样利于以后维护各个配置。 主配置里面有很多program的配置示例，可以复制一个过去修改即可使用。 新建一个配置vim /etc/supervisor/conf.d/java_room_status.conf 复制主配置里面一段program的配置出来贴上，稍作修改即可。123456789101112131415161718192021222324252627282930[program:roomstatus_dev]command=/usr/bin/java -jar /data/www/room/devshixin.jar ; the program (relative uses PATH, can take args);process_name=%(program_name)s ; process_name expr (default %(program_name)s);numprocs=1 ; number of processes copies to start (def 1);directory=/tmp ; directory to cwd to before exec (def no cwd);umask=022 ; umask for process (default None);priority=999 ; the relative start priority (default 999)autostart=true ; start at supervisord start (default: true);startsecs=1 ; # of secs prog must stay up to be running (def. 1);startretries=3 ; max # of serial start failures when starting (default 3)autorestart=unexpected ; when to restart if exited after running (def: unexpected);exitcodes=0,2 ; &apos;expected&apos; exit codes used with autorestart (default 0,2);stopsignal=QUIT ; signal used to kill process (default TERM);stopwaitsecs=10 ; max num secs to wait b4 SIGKILL (default 10);stopasgroup=false ; send stop signal to the UNIX process group (default false);killasgroup=false ; SIGKILL the UNIX process group (def false);user=chrism ; setuid to this UNIX account to run the program;redirect_stderr=true ; redirect proc stderr to stdout (default false)stdout_logfile=/var/log/dev_room.log ; stdout log path, NONE for none; default AUTOstdout_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB)stdout_logfile_backups=10 ; # of stdout logfile backups (0 means none, default 10);stdout_capture_maxbytes=1MB ; number of bytes in &apos;capturemode&apos; (default 0);stdout_events_enabled=false ; emit events on stdout writes (default false)stderr_logfile=/var/log/err_dev_room.log ; stderr log path, NONE for none; default AUTOstderr_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB)stderr_logfile_backups=10 ; # of stderr logfile backups (0 means none, default 10);stderr_capture_maxbytes=1MB ; number of bytes in &apos;capturemode&apos; (default 0);stderr_events_enabled=false ; emit events on stderr writes (default false);environment=A=&quot;1&quot;,B=&quot;2&quot; ; process environment additions (def no adds);serverurl=AUTO ; override serverurl computation (childutils) 参考资料 Supervisor Documents]]></content>
      <categories>
        <category>python</category>
        <category>tools</category>
      </categories>
      <tags>
        <tag>supervisor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pyrsync使用说明]]></title>
    <url>%2Farticle%2F20170630%2Fpyrsync-readme%2F</url>
    <content type="text"><![CDATA[Pyrsync调用rsync同步文件，从yaml文件读取配置。简化rsync使用，和方便管理备份项更改。未来将提供web界面添加yaml配置。 安装依赖sudo pip install -r requirements.txt sudo yum install -y rsync 使用说明 新建项目yaml配置文件 cp playbook/default.yaml.template playbook/default.yaml 配置好项目使用哪个账户复制，ip、备份目录之类的。 要提前做好要备份的主机公钥认证，好让rsync不用输入密码。 执行 ./pyrsync.py yaml配置文件说明 actor 项说明 项 作用 name 做了ssh公钥认证登录的用户 IP 要备份的内容所在的服务器IP port ssh端口 action rsync的参数项可以自由写 如：-avz –delete execute 项说明 脚本统一放在script目录 填写脚本文件名，理论支持shell，Python等，一定要在脚本开头定义好解析器。如bash #！/bin/bash 项 作用 pre-local 同步前在本机执行 pre-remote 同步前在远程机执行 post-remote 同步后在远程机执行 post-local 同步后在本机执行 playbook剧本sences场景项说明 一个场景配置一个目录、和一个排除文件，排除文件目录在exclude，填写文件名即可。排除支持通配符，一行一个筛选项。cvs.txt是例子。 项 作用 item 要备份的目录 savepath 保存到本地的目录 exclude 描述排除文件的文件名 在exclude目录 使用场景我要定时对 192.168.168.19上的三个项目的uploads目录进行同步备份。 分别是 /data/web1/uploads /data/web2/uploads /data/web3/uploads 还要定时导出MySQL数据库test2，到/data/sql,并同步备份过来。但是过滤掉.git目录、.svn目录。 备份内容保存到本地 /backup/node1 目录 根据上面信息，可以配置一个如下的yaml文件。 test.yaml （名字可以随意取，后缀一定得是yaml）123456789101112131415161718192021222324252627282930actor: name: root ip: 192.168.168.19 port: 22 action: -avzexecute: pre-local: pre-remote: test.sh post-remote: post-local:playbook: sences: - 1: item: /data/web1/uploads savepath: /backup/web1 exclude: cvs.txt - 2: item: /data/web2/uploads savepath: /backup/web2 exclude: cvs.txt - 3: item: /data/web3/uploads savepath: /backup/web3 exclude: cvs.txt - 4: item: /data/sql savepath: /backup/sql exclude: cvs.txt 上面pre-remote的test.sh内容如下 123#!/bin/bashmysqldump -uroot -predhat test2 &gt; /data/sql/test2.sql 备份前目录情况如下： 远程机/data/ : 12345678910111213141516171819/data├── .git│ └── 11├── sql├── web1│ ├── .git│ │ └── master│ └── uploads│ └── web1.html├── web2│ ├── .svn│ │ └── entries│ └── uploads│ └── web2.png└── web3 └── uploads └── web3.php10 directories, 6 files 本机 /backup/node1/: 123node10 directories, 0 files 现在执行./pyrsync.py 执行后 123456789101112131415/backup/├── sql│ └── sql│ └── test2.sql├── web1│ └── uploads│ └── web1.html├── web2│ └── uploads│ └── web2.png└── web3 └── uploads └── web3.php8 directories, 4 files 项目地址： https://github.com/onecer/Pyrsync]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python写的备份小工具]]></title>
    <url>%2Farticle%2F20170628%2Fpython-pyrsync%2F</url>
    <content type="text"><![CDATA[项目地址： https://github.com/onecer/Pyrsync readme: https://uublog.com/article/20170630/pyrsync-readme/ =========================================================================== 打算用rsync同步，刚刚在写shell的时候，尝试了下，项目多了，目录多了。shell代码就眼花缭乱。 所以，这样封装了一下，备份的项目用yaml描述。100行代码，可以更方便的去管理备份源。 项目代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111#!/usr/bin/env python# coding:utf-8# Author: phanimport osimport yamlimport commandsimport timeimport codecs# 配置区域# 日志路径LOGFILE = '/var/log/pyrsync.log'# 是否开启日志ENABLE_LOG = True# 啰嗦模式VERBOSE_MODE = True# 自定义常量BASEDIR = os.path.dirname(__file__)# 获取目录文件列表def get_file_lists(dirpath): filelists = [] for filename in os.listdir(dirpath): filelists.append(os.path.join(dirpath,filename)) return filelists# 获取当前时间def get_time(): return time.strftime('%Y-%m-%d %H:%M:%S ',time.localtime(time.time()))# 记录日志def logger(line): if ENABLE_LOG: if os.path.isfile(LOGFILE): with codecs.open(LOGFILE,'a','utf-8') as f: f.write("&#123;time&#125;&#123;logline&#125;\n".format(time=get_time(), logline=line)) else: with codecs.open(LOGFILE,'w','utf-8') as f: f.write("&#123;time&#125;&#123;logline&#125;\n".format(time=get_time(), logline=line))# 记录命令日志def logger_commands(status,result): logger('result:&#123;status&#125;'.format(status=status)) if VERBOSE_MODE: logger(result)# 执行命令def runcommand(commandline): return commands.getstatusoutput(commandline)# 部署场景def deploy_sences(isLocal,shellfile,actor=''): commandline = os.path.join(BASEDIR, 'script', shellfile) if isLocal: (status,result) = runcommand(commandline) logger_commands(status,result) else: upload_script = 'scp &#123;command&#125; &#123;name&#125;@&#123;ip&#125;:/tmp/pyrsync_&#123;scriptName&#125;'.format( command=commandline, name=actor['name'], ip=actor['ip'], scriptName=os.path.basename(commandline) ) (status,result) = runcommand(upload_script) logger_commands(status, result) commandline = 'ssh &#123;name&#125;@&#123;ip&#125; "chmod u+x /tmp/pyrsync_&#123;command&#125; &amp;&amp; /tmp/pyrsync_&#123;command&#125; &amp;&amp; rm -f /tmp/pyrsync_&#123;command&#125;"'.format( name=actor['name'], ip=actor['ip'], command=os.path.basename(commandline), ) (status,result) = runcommand(commandline) logger_commands(status, result)# 同步文件def sync_files(actor,sence): rsyncCommand = 'rsync &#123;action&#125; --exclude-from="&#123;exclude&#125;" &#123;name&#125;@&#123;ip&#125;:&#123;path&#125; &#123;savepath&#125;'.format( action=actor['action'], exclude=os.path.join(BASEDIR,'exclude',sence['exclude']), name=actor['name'], ip=actor['ip'], port=actor['port'], path=sence['item'], savepath=sence['savepath'] ) logger('Command:&#123;command&#125;'.format(command=rsyncCommand)) (status,result) = runcommand(rsyncCommand) logger_commands(status,result)# 执行剧本def play_playbooks(filelists): for filelist in filelists: if os.path.isfile(filelist) and os.path.splitext(filelist)[-1]=='.yaml': with open(filelist,'r') as f: playbook = yaml.load(f) sences = playbook['playbook']['sences'] for sence in sences: if playbook['execute']['pre-local']: deploy_sences(True,playbook['execute']['pre-local']) if playbook['execute']['pre-remote']: deploy_sences(False, playbook['execute']['pre-remote'],playbook['actor']) sync_files(playbook['actor'],sence) if playbook['execute']['post-remote']: deploy_sences(False,playbook['execute']['post-remote'],playbook['actor']) if playbook['execute']['post-local']: deploy_sences(True,playbook['execute']['post-local'])if __name__=='__main__': play_playbooks(get_file_lists(os.path.join(BASEDIR,'playbook'))) 配置格式如下：123456789101112131415161718192021222324252627282930actor: name: root ip: 192.168.168.19 port: 22 action: -avzexecute: pre-local: pre-remote: test.sh post-remote: post-local:playbook: sences: - 1: item: /data/web1/uploads savepath: /backup/web1 exclude: cvs.txt - 2: item: /data/web2/uploads savepath: /backup/web2 exclude: cvs.txt - 3: item: /data/web3/uploads savepath: /backup/web3 exclude: cvs.txt - 4: item: /data/sql savepath: /backup/sql exclude: cvs.txt 安装Pyrsync调用rsync同步文件，从yaml文件读取配置。简化rsync使用，和方便管理备份项更改。未来将提供web界面添加yaml配置。 安装依赖sudo pip install -r requirements.txt sudo yum install -y rsync 使用说明 新建项目yaml配置文件 cp playbook/default.yaml.template playbook/default.yaml 配置好项目使用哪个账户复制，ip、备份目录之类的。 要提前做好要备份的主机公钥认证，好让rsync不用输入密码。 执行 ./pyrsync.py]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git用webhook实现自动更新网站]]></title>
    <url>%2Farticle%2F20170613%2Fgit-use-webhook-auto-update-web%2F</url>
    <content type="text"><![CDATA[最近公司大部分项目从SVN过渡到Git。所以代码自动化部署也有了更多的想象空间。 之前使用SVN更新代码到开发环境的时候，都是用crontab定时svn update。间隔是一分钟，虽然一分钟不算长，甚至有时候等待并不需要这么久。 但是总归是无法做到及时更新。算是自动主动更新，而Git有webhook的存在，就可以做到触发式更新。 我们代码是放在 git.oschina.net 码云上。 原理每次git提交的时候，都会触发webhook，webhook会访问我们设置的URL。 URL触发我们的更新代码。 所以，我们还需要架一个网站，提供一个webhook访问的URL，访问的时候触发代码。 实践时间原因，轮子就不自己造了，所以，我找到一份还不错的webhook管理平台。 git-webhook: https://github.com/NetEaseGame/git-webhook 安装git-webhook环境： Centos7 这里用docker部署 123456789101112# 安装启动docker# yum install docker# systemctl restart docker# systemctl enable docker# 安装 Docker Compose# yum install docker-compose# 下载源码# git clone https://github.com/NetEaseGame/git-webhook.git# 修改配置# cd git-webhook# cp app/config_docker_example.py app/config.py# vim app/config.py GITHUB: GitHub 登陆配置，可以到 OAuth applications 自行申请，登陆 Callback 地址为： your_domain/github/callback. 配置好后，就可以执行 1# docker-compose up 第一次启动的时候会docker会pull几个需要的镜像，所以时间要长点。 以后启动的话，可以用docker-compose up -d 用deamon方式启动。 Nginx配置 启动后，docker 暴露出来的端口是 18340.访问的话，就是 http://ip:18340 所以我打算给它绑定一个域名，让它访问要更方便一点。 1234567891011121314151617server &#123; listen 80; server_name webhook.xxx.com; root html; index index.html index.htm index.php; location / &#123; proxy_pass http://127.0.0.1:18340/; #Proxy Settings proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125; 至此git-webhook就安装好了。 用github账号登录进去，先添加服务器，再添加git仓库。得到的url填到git.oschina.net webhook那里就行了。 添加好项目后，在箭头方向复制URL 登录码云，填写URL到webhook那里 参考资料 安装说明]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>webhook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[代码从SVN迁移到GIT]]></title>
    <url>%2Farticle%2F20170612%2Fsvn-to-git%2F</url>
    <content type="text"><![CDATA[GIT可以选择有很多，国外有github，国内有coding和git.oschina.net。 因为不可描述的原因，我们选了国内的。注册和管理其实和github很像。 我再做了ssh公钥认证后，将远程仓库git clone一份回本地。这样它就会自动生成一个.git目录了。 其实自己在本地现有的项目下用git remote add 也是可以的，但是感觉要略为麻烦点。 将SVN仓库代码更新至最新，复制多一份。 进入SVN代码目录，删除原来SVN的隐藏目录，.svn，这个内容占了很大空间。 1find . -type d -name &quot;.svn&quot;|xargs rm -rf 将内容复制的到git目录，并提交去远程仓库。 123git add -Agit commit -m &quot;first commit&quot;git push origin master done.]]></content>
      <categories>
        <category>operations</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>operations</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VIM配置推荐-K-VIM]]></title>
    <url>%2Farticle%2F20170607%2Fvim-plugins-k-vim%2F</url>
    <content type="text"><![CDATA[归类到工具吧，算是可以提升效率的东西。自己也折腾过，VIM配置插件还是挺麻烦的。直到看到这个，一键配置，这个项目再github居然有3K的star。 https://github.com/wklken/k-vim 安装方法不赘述，帮助文档有。 用来写Python和其它脚步，做些小修改，算是一个好的补充吧。毕竟大部分时候还是专业的IDE比较方便。]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MariaDB Root密码恢复]]></title>
    <url>%2Farticle%2F20170527%2Fmariadb-root-password-recovery%2F</url>
    <content type="text"><![CDATA[本机装了MariaDB，很久不用，把密码给忘记了。 然后刚刚把密码恢复了下，记录一份这里方便以后索引。 停止MySQL服务。 # systemctl stop mysql 我是Ubuntu 这里服务名是这个 用无权限管理方式启动 # mysqld_safe --skip-grant-tables &amp; 登录修改密码 # mysql -uroot 修改密码的SQL1234&gt; use mysql;&gt; update user set password=PASSWORD(&quot;gjdEdufD93J&quot;) where User=&apos;root&apos;;&gt; flush privileges;&gt; quit 停止mysql进程 /etc/init.d/mysql stop 启动服务 systemctl restart mysql done. 全部流程记录 1234567891011121314151617181920212223242526272829303132fate phan # systemctl stop mysqlfate phan # mysqld_safe --skip-grant-tables &amp;[1] 14391fate phan # 170527 11:46:39 mysqld_safe Logging to syslog.170527 11:46:39 mysqld_safe Starting mysqld daemon with databases from /var/lib/mysqlfate phan # mysql -urootWelcome to the MariaDB monitor. Commands end with ; or \g.Your MariaDB connection id is 2Server version: 10.0.29-MariaDB-0ubuntu0.16.04.1 Ubuntu 16.04Copyright (c) 2000, 2016, Oracle, MariaDB Corporation Ab and others.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.MariaDB [(none)]&gt; use mysql;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedMariaDB [mysql]&gt; update user set password=PASSWORD("gjdEdufD93J") where User='root';Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0MariaDB [mysql]&gt; flush privileges;Query OK, 0 rows affected (0.00 sec)MariaDB [mysql]&gt; quitByefate phan # /etc/init.d/mysql stop[ ok ] Stopping mysql (via systemctl): mysql.service.fate phan # systemctl restart mysql 参考资料 Setting, Changing And Resetting MySQL Root Passwords]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mariadb</tag>
        <tag>recovery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fabric运行run命令执行nohup异常]]></title>
    <url>%2Farticle%2F20170526%2Ffabric-troubleshooting-1%2F</url>
    <content type="text"><![CDATA[写了一个脚本用fabric发布和运行java包。需要用到nohup，或者screen -d -m命令。 我习惯了nohup，但是执行完毕，没有出错，但是程序也压根没有执行。 最后才找到资料说是fabric执行nohup命令的时候，过早关闭session，导致出问题。 官方推荐的做法是在命令后面增加一点延迟，比如&amp;&amp; sheep 1或者用screen命令。]]></content>
      <categories>
        <category>troubleshooting</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>fabric</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python词频统计]]></title>
    <url>%2Farticle%2F20170525%2Fpython-words-counter%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233#!/usr/bin/env python#coding:utf-8from random import randint""" 词的频次统计 统计重复的词的次数，用字典的形式展现"""data = [randint(0,10) for _ in xrange(0,20)]print data## 常规处理# 根据键生成一个字典，赋值0ddata = dict.fromkeys(data,0)print ddata# 迭代统计for x in data: ddata[x]+=1print ddata## 用collections 的counterfrom collections import Counterddata2 = Counter(data)# 统计最高的4位print ddata2.most_common(4) 输出： 1234[1, 0, 5, 6, 6, 4, 8, 7, 3, 1, 2, 10, 9, 5, 9, 3, 10, 9, 5, 4]&#123;0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0&#125;&#123;0: 1, 1: 2, 2: 1, 3: 2, 4: 2, 5: 3, 6: 2, 7: 1, 8: 1, 9: 3, 10: 2&#125;[(5, 3), (9, 3), (1, 2), (3, 2)]]]></content>
      <categories>
        <category>python</category>
        <category>foundation</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python列表、字典的筛选]]></title>
    <url>%2Farticle%2F20170525%2Fpython-list-dict-filter%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#!/usr/bin/env python#coding:utf-8from random import randint""" 列表筛选 生成一个有20个随机数的数组 data 从 data 列表中筛选出大于0的数字"""data = [randint(-100,100) for _ in xrange(10)]print data## 迭代def test1(d): s = [] for x in data: if x &gt;=0: s.append(x) return s## 用filterdef test2(d): return filter(lambda x:x&gt;=0,d)## 用列表解析def test3(d): return [x for x in data if x&gt;=0]print test1(data)print test2(data)print test3(data)## 迭代最慢、列表解析最快""" 字典的筛选 生成键值在56-100之间的随机数10个 找出大于90的数"""data = &#123;x:randint(56,100) for x in xrange(1,11)&#125;print datadef test4(d): return &#123;k:v for k,v in d.iteritems() if v&gt;=90&#125;print test4(data) 输出： 123456[61, -31, 2, -45, -1, 19, -41, -8, -17, 48][61, 2, 19, 48][61, 2, 19, 48][61, 2, 19, 48]&#123;1: 59, 2: 99, 3: 97, 4: 83, 5: 89, 6: 79, 7: 69, 8: 58, 9: 73, 10: 58&#125;&#123;2: 99, 3: 97&#125;]]></content>
      <categories>
        <category>python</category>
        <category>foundation</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>dict</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python简单的socket通讯例子]]></title>
    <url>%2Farticle%2F20170522%2Fpython-simply-socket%2F</url>
    <content type="text"><![CDATA[公司有块业务是靠socket提供端口供给业务查询的。 之前每次测试socket发送数据都略麻烦，所以自己用python搞了一次。 根据业务之前的逻辑，检测字段包含EOF结束读取。 12345678910111213141516171819202122232425262728import socket#import codecs#encoder = codecs.getencoder("utf-8")senddata = '&#123;"action":"compute","device":"ios","map":"0","start":"2017-05-19","day":"25","type":"17","orientation":"0","order_total_id":"950","store_id":"12"&#125;EOF\n's = socket.socket(socket.AF_INET, socket.SOCK_STREAM)s.connect(('dev.xxxx.net', 31))s.send(senddata)buffer = []while True: d = s.recv(65535) if d: buffer.append(d) else: break if 'EOF' in d[-5:-1]: break# while True:# d = s.recv(1024)# if d:# buffer.append(d)# else:# breakdata = ''.join(buffer)print datas.close()]]></content>
      <categories>
        <category>python</category>
        <category>foundation</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>socket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python递归和迭代实现求斐波那契数]]></title>
    <url>%2Farticle%2F20170519%2Fpython-algorithms-fibonacci%2F</url>
    <content type="text"><![CDATA[Python实现求第N位斐波那契数。迭代用来队列来保存，用其它也是可以的。 123456789101112131415161718192021222324252627282930313233#!/bin/env python#coding:utf-8from collections import dequeimport datetime# 递归版def fibonacci(num): if num&lt;=2: return 1 else: return fibonacci(num-1)+fibonacci(num-2)# 迭代版def fibonacci2(num): s=deque() result=0 for i in range(1,num+1): if i&lt;=2: result=1 s.append(result) else: result=s[0]+s[1] s.append(result) s.popleft() return resultn=40print(datetime.datetime.now())print('fibonacci(%d)=%d' % (n, fibonacci(n)))print(datetime.datetime.now())print('fibonacci2(%d)=%d' % (n, fibonacci2(n)))print(datetime.datetime.now()) 结果： 123452017-05-19 18:00:52.194334fibonacci(40)=1023341552017-05-19 18:01:09.535270fibonacci2(40)=1023341552017-05-19 18:01:09.535328 递归效率还是比较底下，但是语法简明。]]></content>
      <categories>
        <category>python</category>
        <category>algorithms</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>algorithms</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[walle一些莫名其妙的报错]]></title>
    <url>%2Farticle%2F20170519%2Ftroubleshooting-walle-profile%2F</url>
    <content type="text"><![CDATA[这前天walle部署出现了一些莫名其妙的问题。检测配置是通过的，但是部署的时候遇到前后置任务的时候总是报错。 开始以为是数据库问题，后来排查了，又以为是php执行函数exec被禁用的问题。但是并不是。 真是百思不得骑姐啊。 回想最近的改动，只有我安装过一个运维工具的agent，但是已经卸载了。 料想应该是修改了哪里的配置。 最后才定位到 /etc/profile 多了一条 #ulimit -n 204800 修改了文件符打开数量。最后我把它注释掉就好了。 至于为什么这个会影响到walle，还没深究，等找到原因再来补充。]]></content>
      <categories>
        <category>walle</category>
      </categories>
      <tags>
        <tag>walle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7配置LNMP nginx10+mariadb+php5.6]]></title>
    <url>%2Farticle%2F20170516%2Fcentos7-nginx10-mariadb-php5-6%2F</url>
    <content type="text"><![CDATA[今天给一台测试机配个环境，顺道记录下，一直觉得webtatic比官方源好用。但是老是容易忘记名字，这次就贴这里了。 安装环境所需的包mariadb yum groupinstall -y mariadb mairadb-client php5.6 Repo 源12345678910CentOS 5.X rpm -Uvh http://mirror.webtatic.com/yum/el5/latest.rpmCentOS 6.x rpm -Uvh http://mirror.webtatic.com/yum/el6/latest.rpmCentOS 7.X # rpm -Uvh https://mirror.webtatic.com/yum/el7/epel-release.rpm yum install epel-release rpm -Uvh https://mirror.webtatic.com/yum/el7/webtatic-release.rpm yum install php56w.x86_64 php56w-cli.x86_64 php56w-common.x86_64 php56w-gd.x86_64 php56w-ldap.x86_64 php56w-mbstring.x86_64 php56w-mcrypt.x86_64 php56w-mysql.x86_64 php56w-pdo.x86_64 php-fpm yum install php56w-fpm nginx 1.10 yum install -y nginx1w.x86_64 配置nginx /etc/nginx/nginx.conf123456789101112server字段里面，要配置root项，指向你网站的根目录。另外去掉一下注释，让它支持php。里面的127.0.0.1:9000 是php-fpm所在的端口。root字段同样要指向根目录。fastcgi_param这个要修改正确执行web根目录，否则用$document_root 然后配置好root路径就好。root /www/web;fastcgi_pass 127.0.0.1:9000;fastcgi_index index.php;# fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name;fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;include fastcgi_params;yum包安装的，它用户都给你创建好和修改好了。 php-fpm 其实user和group用默认的也是没问题的。但是为了以后方便自定义点，我用了一个叫www的账户12# groupadd www-data# useradd -g www-data www-data /etc/php-fpm.d/www.conf12user=wwwgroup=www 为了更好的性能，建议对nginx.conf 配置一下worker的数量，php-fpm 配置一下池，常驻进程数量。 mysql 先运行mysql_secure_installation这个脚本来改一下root密码，关闭远程连接和删除测试数据库之类的东西。 启动服务12# systemctl start php-fpm mariadb nginx# systemctl enable php-fpm mariadb nginx 参考资料 webtatic]]></content>
      <categories>
        <category>operations</category>
      </categories>
      <tags>
        <tag>lnmp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 异常接管/引出]]></title>
    <url>%2Farticle%2F20170515%2Fpython-foundation-exception-handing%2F</url>
    <content type="text"><![CDATA[异常处理Python 的异常接管和很多程序的都差不多，尤其是Pascal。 常见的异常类型有123456ImportError:an import fails 导入失败，一般导入了无效的模块IndexError:a list is indexed with an out of range number 超出列表最大长度NameError:an unknown variable is used 未定义的变量SyntaxError:the code can't be parsed properly 不能匹配的语法TypeError:a funxtion is called on a value of an inappropriate type 错误的类型ValueError:a function is called on a value of the correct type but with an inappropriate value 错误的值 异常的接管1234try: # do sthexcept &lt;具体要接管的错误类型，留空则接管所有异常&gt;: # 异常处理部分 比如除以0的时候都会抛出一个ZeroDivisionError异常。 而接管异常处理示例1234try: result = 1 / 0except ZeroDivisionError: print('error') 又或者留空，默认接管所有异常。1234try: result = 1 / 0except: print('error') 又或者使用多个except接管多个不同类型的异常。123456try: result = 1 / 0except ZeroDivisionError: print('ZeroDivisionError')except IOError: print('IOError') 以上只是列举了异常类型的小部分 异常类型列表如果想查看更多异常类型，可以导入exceptions模块，用dir查看。如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455In [1]: import exceptionsIn [2]: dir(exceptions)Out[2]: ['ArithmeticError', 'AssertionError', 'AttributeError', 'BaseException', 'BufferError', 'BytesWarning', 'DeprecationWarning', 'EOFError', 'EnvironmentError', 'Exception', 'FloatingPointError', 'FutureWarning', 'GeneratorExit', 'IOError', 'ImportError', 'ImportWarning', 'IndentationError', 'IndexError', 'KeyError', 'KeyboardInterrupt', 'LookupError', 'MemoryError', 'NameError', 'NotImplementedError', 'OSError', 'OverflowError', 'PendingDeprecationWarning', 'ReferenceError', 'RuntimeError', 'RuntimeWarning', 'StandardError', 'StopIteration', 'SyntaxError', 'SyntaxWarning', 'SystemError', 'SystemExit', 'TabError', 'TypeError', 'UnboundLocalError', 'UnicodeDecodeError', 'UnicodeEncodeError', 'UnicodeError', 'UnicodeTranslateError', 'UnicodeWarning', 'UserWarning', 'ValueError', 'Warning', 'ZeroDivisionError', '__doc__', '__name__', '__package__'] 对象安全释放这个和许多语言都有点类似。一般在发生异常的时候，执行就被中断了。而有些被打开的数据有可能会被丢失。 尤其是用open打开文件的时候，很有可能导致内容丢失。所以为了让代码在出现异常的时候，一样能执行特定的代码。比如释放对象，安全关闭文件等。就有了 try ... finally语句。 1234try: result = 1 / 0finally: print('still working.') 比如常见安全关闭文件12345try: f = open('test.txt','wb') result = 1 / 0finally: f.close() 不过对于安全打开关闭文件，一般更推荐的做法是用with 123with open("test.txt","wb") as f: result = 1 / 0 #or do sth. 提起/引出异常 raise有时候在处理潜在有问题的代码的时候，你希望主动引出一个异常，可以用raise语句。 比如引出一个 ValueError raise ValueError 异常带参数描述异常raise ValueError(&#39;值错误&#39;) 断言assert断言使用，可能都是用于自己调试程序的时候才会用到。 assert 1!=1 当后面表达式不为True的时候，就会引发AssertionError错误。]]></content>
      <categories>
        <category>python</category>
        <category>foundation</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>exception</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python冒泡排序算法]]></title>
    <url>%2Farticle%2F20170510%2Fpython-algorithms-bubble-sort%2F</url>
    <content type="text"><![CDATA[需要将json的数据，按program属性的数组大小进行排序。Python实现特别轻松，主要在交换值方面轻松，以前用Delphi代码量起码是这个两倍。 代码如下： 123456789101112131415#coding:utf-8import jsonjsonraw='[&#123;"scores":0,"program":[&#123;"type_name":"标准间","type_id":"15","orientation_id":"19","orientation_name":"东","map_name":"格局三","start":"2017-05-09","floor_name":"东2楼","number":"2009","map_id":"16","days":"25","end":"2017-06-02","floor_id":"64","id":"104"&#125;]&#125;,&#123;"scores":0,"program":[&#123;"type_name":"标准间","type_id":"15","orientation_id":"21","orientation_name":"西","map_name":"格局三","start":"2017-05-09","floor_name":"东2楼","number":"2011","map_id":"16","days":"25","end":"2017-06-02","floor_id":"64","id":"105"&#125;]&#125;,&#123;"scores":0,"program":[&#123;"type_name":"普通房","type_id":"16","orientation_id":"19","orientation_name":"东","map_name":"格局二","start":"2017-05-09","floor_name":"东3楼","number":"3009","map_id":"15","days":"25","end":"2017-06-02","floor_id":"65","id":"106"&#125;]&#125;,&#123;"scores":0,"program":[&#123;"type_name":"标准间","type_id":"15","orientation_id":"19","orientation_name":"东","map_name":"格局二","start":"2017-05-09","floor_name":"东5楼","number":"5005","map_id":"15","days":"25","end":"2017-06-02","floor_id":"67","id":"108"&#125;]&#125;,&#123;"scores":0,"program":[&#123;"type_name":"普通房","type_id":"16","orientation_id":"22","orientation_name":"南","map_name":"格局二","start":"2017-05-09","floor_name":"东5楼","number":"5006","map_id":"15","days":"25","end":"2017-06-02","floor_id":"67","id":"109"&#125;]&#125;,&#123;"scores":0,"program":[&#123;"type_name":"标准间","type_id":"15","orientation_id":"21","orientation_name":"西","map_name":"格局二","start":"2017-05-09","floor_name":"东5楼","number":"5007","map_id":"15","days":"25","end":"2017-06-02","floor_id":"67","id":"110"&#125;]&#125;,&#123;"scores":0,"program":[&#123;"type_name":"标准间","type_id":"15","orientation_id":"23","orientation_name":"北","map_name":"格局三","start":"2017-05-09","floor_name":"东5楼","number":"5008","map_id":"16","days":"25","end":"2017-06-02","floor_id":"67","id":"111"&#125;]&#125;,&#123;"scores":0,"program":[&#123;"type_name":"标准间","type_id":"15","orientation_id":"21","orientation_name":"西","map_name":"格局二","start":"2017-05-09","floor_name":"东5楼","number":"5009","map_id":"15","days":"25","end":"2017-06-02","floor_id":"67","id":"112"&#125;]&#125;,&#123;"scores":0,"program":[&#123;"type_name":"标准间","type_id":"15","orientation_id":"19","orientation_name":"东","map_name":"格局三","start":"2017-05-09","floor_name":"东2楼","number":"2009","map_id":"16","days":"22","end":"2017-05-30","floor_id":"64","id":"104"&#125;,&#123;"type_name":"普通房","type_id":"16","orientation_id":"19","orientation_name":"东","map_name":"格局11","start":"2017-05-31","floor_name":"东6楼","number":"6007","map_id":"14","days":"3","end":"2017-06-02","floor_id":"68","id":"114"&#125;]&#125;,&#123;"scores":0,"program":[&#123;"type_name":"标准间","type_id":"15","orientation_id":"21","orientation_name":"西","map_name":"格局三","start":"2017-05-09","floor_name":"东2楼","number":"2011","map_id":"16","days":"22","end":"2017-05-30","floor_id":"64","id":"105"&#125;,&#123;"type_name":"普通房","type_id":"16","orientation_id":"19","orientation_name":"东","map_name":"格局11","start":"2017-05-31","floor_name":"东6楼","number":"6007","map_id":"14","days":"3","end":"2017-06-02","floor_id":"68","id":"114"&#125;]&#125;,&#123;"scores":0,"program":[&#123;"type_name":"普通房","type_id":"16","orientation_id":"19","orientation_name":"东","map_name":"格局二","start":"2017-05-09","floor_name":"东3楼","number":"3009","map_id":"15","days":"22","end":"2017-05-30","floor_id":"65","id":"106"&#125;,&#123;"type_name":"普通房","type_id":"16","orientation_id":"19","orientation_name":"东","map_name":"格局11","start":"2017-05-31","floor_name":"东6楼","number":"6007","map_id":"14","days":"3","end":"2017-06-02","floor_id":"68","id":"114"&#125;]&#125;,&#123;"scores":0,"program":[&#123;"type_name":"标准间","type_id":"15","orientation_id":"19","orientation_name":"东","map_name":"格局二","start":"2017-05-09","floor_name":"东5楼","number":"5005","map_id":"15","days":"22","end":"2017-05-30","floor_id":"67","id":"108"&#125;,&#123;"type_name":"普通房","type_id":"16","orientation_id":"19","orientation_name":"东","map_name":"格局11","start":"2017-05-31","floor_name":"东6楼","number":"6007","map_id":"14","days":"3","end":"2017-06-02","floor_id":"68","id":"114"&#125;]&#125;,&#123;"scores":0,"program":[&#123;"type_name":"普通房","type_id":"16","orientation_id":"22","orientation_name":"南","map_name":"格局二","start":"2017-05-09","floor_name":"东5楼","number":"5006","map_id":"15","days":"22","end":"2017-05-30","floor_id":"67","id":"109"&#125;,&#123;"type_name":"普通房","type_id":"16","orientation_id":"19","orientation_name":"东","map_name":"格局11","start":"2017-05-31","floor_name":"东6楼","number":"6007","map_id":"14","days":"3","end":"2017-06-02","floor_id":"68","id":"114"&#125;]&#125;,&#123;"scores":0,"program":[&#123;"type_name":"标准间","type_id":"15","orientation_id":"21","orientation_name":"西","map_name":"格局二","start":"2017-05-09","floor_name":"东5楼","number":"5007","map_id":"15","days":"22","end":"2017-05-30","floor_id":"67","id":"110"&#125;,&#123;"type_name":"普通房","type_id":"16","orientation_id":"19","orientation_name":"东","map_name":"格局11","start":"2017-05-31","floor_name":"东6楼","number":"6007","map_id":"14","days":"3","end":"2017-06-02","floor_id":"68","id":"114"&#125;]&#125;,&#123;"scores":0,"program":[&#123;"type_name":"标准间","type_id":"15","orientation_id":"23","orientation_name":"北","map_name":"格局三","start":"2017-05-09","floor_name":"东5楼","number":"5008","map_id":"16","days":"22","end":"2017-05-30","floor_id":"67","id":"111"&#125;,&#123;"type_name":"普通房","type_id":"16","orientation_id":"19","orientation_name":"东","map_name":"格局11","start":"2017-05-31","floor_name":"东6楼","number":"6007","map_id":"14","days":"3","end":"2017-06-02","floor_id":"68","id":"114"&#125;]&#125;,&#123;"scores":0,"program":[&#123;"type_name":"标准间","type_id":"15","orientation_id":"21","orientation_name":"西","map_name":"格局二","start":"2017-05-09","floor_name":"东5楼","number":"5009","map_id":"15","days":"22","end":"2017-05-30","floor_id":"67","id":"112"&#125;,&#123;"type_name":"普通房","type_id":"16","orientation_id":"19","orientation_name":"东","map_name":"格局11","start":"2017-05-31","floor_name":"东6楼","number":"6007","map_id":"14","days":"3","end":"2017-06-02","floor_id":"68","id":"114"&#125;]&#125;]'jsonarr=json.loads(jsonraw)arrlen = len(jsonarr)for i in range(0,arrlen): for j in range(i+1,arrlen): if len(jsonarr[i]['program']) &gt; len(jsonarr[j]['program']): jsonarr[i],jsonarr[j] = jsonarr[j], jsonarr[i]print jsonarr]]></content>
      <categories>
        <category>python</category>
        <category>algorithms</category>
      </categories>
      <tags>
        <tag>bubble sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python用栈实现匹配括号对语法是否正确]]></title>
    <url>%2Farticle%2F20170506%2Fpython-match-symbol-syntax%2F</url>
    <content type="text"><![CDATA[要实现对括号对的匹配。 假如不能双双配对，就是不合适的。举个例子 123456正确&apos;sd&#123;sfsfs&#125;[(s)]&apos;&apos;[&#123;()&#125;]&apos;不正确&apos;[[]&#123;()&#125;&apos; 思路就是用一个栈存储匹配到的左括号，匹配到右括号的话，就和栈顶的数据对比。因为两个括号的ASCII码，一般右括号总比左括号大1或者2.通过判断差值是否在这个区间，基本可以确定。匹配到一对括号，便消除一个。到最后如果栈为空，就是合格的。反之，不为空就是不合格的。 实现代码如下： 1234567891011121314151617181920212223#!/usr/bin/python#coding:utf-8leftChar=['&#123;','[','(']rightChar=['&#125;',']',')']def check_format(sPath): s=[] for x in sPath: if x in leftChar: s.append(x) if x in rightChar: if s: if abs(ord(x)-ord(s[-1]))&lt;=2: s.pop() else: s.append(x) else: s.append(x) if s: print u"不合格" else: print u"合格" 结果如下 1234check_format(&apos;sd&#123;sfsfs&#125;[(s)]&apos;)合格check_format(&apos;[[]&#123;()&#125;&apos;)不合格]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python下载阿里云RDS实例备份]]></title>
    <url>%2Farticle%2F20170505%2Fpython-backup-aliyun-rds-instance%2F</url>
    <content type="text"><![CDATA[很多数据都做了备份，而且全都用脚本完成。并定时下载一份回我们本地，等于多多点异地备份了，避免被一锅端了的情况。 像代码，这个是分发的，而且开发人手一份，这个就不备份了。用户静态数据也都定时做了rsync同步备份，压缩保存。 连测试环境的数据库都做了自动的MySQL逻辑备份。唯独线上环境，存在RDS中的MySQL数据库，虽然有RDS定时备份实例，但是不经常上去下载一份保存回本地你是不得安心的。 这万一被盗号了呢。。。岂不是辛辛苦苦几十年，一删回到解放前。 本来是可以用mysqldump -h 远程IP 这样备份的。但是RDS可能是防止脱裤，搞了限制。所以，往日都是我自己上阿里云官网，手动点击下载备份。 为了减少这一部分的重复劳动，我决定用阿里云的SDK搞一个自动下载实例。 以为会遇到很多麻烦，没想到SDK封装得还不错，使用异常简单。 步骤分为如下几步 安装阿里云API封装的Python SDK 里面几乎有阿里云所有产品的SDK，这给我们定制自己的工具提供了很大的便利。 这里我们要用的是RDS相关的功能，所以 sudo pip install aliyun-python-sdk-rds就行了。 申请访问API需要用的Access Key。 最好先新建RAM账号，再申请AK。 编码 整个备份逻辑很简单，就是查看指定日期区间备份列表，获取备份信息。然后下载备份。 主要用到SDK DescribeBackupsRequest 这个类。 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839from aliyunsdkcore import client#from aliyunsdkrds.request.v20140815 import DescribeRegionsRequestfrom aliyunsdkrds.request.v20140815 import DescribeBackupsRequestimport jsonimport requestsimport datetime#import timesaveRoot='/home/phan/backups/' #设置备份根目录# 下载链接def downLink(url,dateStr): downFile = requests.get(url) # 设置备份目录 savePath = '%s%s.tar.gz'%(saveRoot，dateStr) with open(savePath,'wb') as backup_file: backup_file.write(downFile.content)# 获取今日和明日的日期today=datetime.date.today();yesterday=datetime.date.today() - datetime.timedelta(1)clt = client.AcsClient('你的AK','你的ASK','cn-shenzhen') #这里的地区ID非必须的request = DescribeBackupsRequest.DescribeBackupsRequest()## 以下请求的参数都是必须的 尤其实例名和查询区间request.set_accept_format('json')request.set_action_name('DescribeBackups')request.set_DBInstanceId('rm-xxxxxxxxxxx') # 你的实例IDrequest.set_StartTime('%sT00:00Z'%(yesterday))request.set_EndTime('%sT00:00Z'%(today))result = clt.do_action_with_exception(request)## 下载RDS备份if result: json_rds = json.loads(result) if json_rds['Items']['Backup'][0]['BackupStatus']=='Success': downLink(json_rds['Items']['Backup'][0]['BackupDownloadURL'],today)print u"数据库备份完成" 至此，加入crontab，备份基本全自动了。 参考资料Aliyun Python SDKAliyun RDS Help]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>rds</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php根据路径列表生成bootstrap treeview]]></title>
    <url>%2Farticle%2F20170504%2Fphp-bootstrap-treeview-generate-json%2F</url>
    <content type="text"><![CDATA[有这么一个需求，需要根据svn生成的版本之间差异的文件列表，生成一个treeview。 数据样本如下： 1234567891011$defaultStr = [ 'Public/images/list/order.png', 'Public/images/list/reverse.png', 'Application/Crm/View/ReturnWork/visitRecord.html', 'Application/Crm/View/ReturnWork/myVisit.html', 'Application/Crm/View/ReturnWork/memberReturn.html', 'Application/Crm/View/ReturnWork/fitReturn.html', 'Application/Crm/View/ReturnWork/emergencReturn.html', 'Application/Crm/View/UserManagement/user_list.html', 'Application/Crm/View/UserManagement/add_maternal.html', 'ver.txt']; 思路如下，先根据 / 符号拆分路径成数组，拼凑tree数组。最后根据tree数组递归生成json数组。 生成数组 12345678910111213141516171819$tree=array();function pushNode($subtree,$name)&#123; if(!empty($name))&#123; $tmpname=end($name); if(!array_key_exists(end($name),$subtree))&#123; $subtree[$tmpname]=array(); &#125; array_pop($name); $subtree[$tmpname]=pushNode($subtree[$tmpname],$name); return $subtree; &#125;&#125;for($i=0;$i&lt;count($defaultStr);$i++)&#123; $path_str=array_reverse(explode('/', $defaultStr[$i])); $tree = pushNode($tree,$path_str);&#125;var_dump($tree); 生成类似如下的数组1234567891011121314151617181920212223242526272829303132333435363738394041424344454647array(3) &#123; ["Public"]=&gt; array(1) &#123; ["images"]=&gt; array(1) &#123; ["list"]=&gt; array(2) &#123; ["order.png"]=&gt; NULL ["reverse.png"]=&gt; NULL &#125; &#125; &#125; ["Application"]=&gt; array(1) &#123; ["Crm"]=&gt; array(1) &#123; ["View"]=&gt; array(2) &#123; ["ReturnWork"]=&gt; array(5) &#123; ["visitRecord.html"]=&gt; NULL ["myVisit.html"]=&gt; NULL ["memberReturn.html"]=&gt; NULL ["fitReturn.html"]=&gt; NULL ["emergencReturn.html"]=&gt; NULL &#125; ["UserManagement"]=&gt; array(2) &#123; ["user_list.html"]=&gt; NULL ["add_maternal.html"]=&gt; NULL &#125; &#125; &#125; &#125; ["ver.txt"]=&gt; NULL&#125; 递归生成树123456789101112131415//递归生成树function makeJsonTree($tree)&#123; $json=[]; if(!empty($tree))&#123; foreach ($tree as $key =&gt; $value)&#123; $jsonNode=[]; $jsonNode['text']=$key; if($value!==null)&#123; $jsonNode['nodes']=makeJsonTree($value); &#125; array_push($json,$jsonNode); &#125; &#125; return $json;&#125; 生成最终符合bootstrap treeview的格式123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172[ &#123; text: "Public", nodes: [ &#123; text: "images", nodes: [ &#123; text: "list", nodes: [ &#123; text: "order.png" &#125;, &#123; text: "reverse.png" &#125; ] &#125; ] &#125; ] &#125;, &#123; text: "Application", nodes: [ &#123; text: "Crm", nodes: [ &#123; text: "View", nodes: [ &#123; text: "ReturnWork", nodes: [ &#123; text: "visitRecord.html" &#125;, &#123; text: "myVisit.html" &#125;, &#123; text: "memberReturn.html" &#125;, &#123; text: "fitReturn.html" &#125;, &#123; text: "emergencReturn.html" &#125; ] &#125;, &#123; text: "UserManagement", nodes: [ &#123; text: "user_list.html" &#125;, &#123; text: "add_maternal.html" &#125; ] &#125; ] &#125; ] &#125; ] &#125;, &#123; text: "ver.txt" &#125;]]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>bootstrap treeview</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rsyslog7.4.7集中管理nginx日志配置实践]]></title>
    <url>%2Farticle%2F20170424%2Frsyslog7-4-7-nginx-remote-logging%2F</url>
    <content type="text"><![CDATA[未雨绸缪，考虑到以后可能服务器增多，如果日志不集中管理，单台日志查看，还是显得比较麻烦。 有常查看nginx日志的需求，所以，打算利用rsyslog对nginx日志做个集中管理。 这里假设日志中心为center，节点1为node1 服务器 IP Center 192.168.1.2 Node1 192.168.1.3 配置都是基于Centos7 默认的rsyslog版本 7.4.7 V5、V7、V8配置差别似乎挺大的，所以尽量用同样的版本吧 Center配置12345678910111213# vim /etc/rsyslog.conf# 开启端口给node传送数据。这里吧tcp和udp端口都打开了# 配置前面加了$的都代表是全局配置$ModLoad imudp$UDPServerRun 514$ModLoad imtcp$InputTCPServerRun 514# 允许特定IP段才能连接端口$AllowedSender tcp, 192.168.1.0/24# 新建一个模板$template Remote,&quot;/data/log/%fromhost-ip%/%fromhost-ip%_%$YEAR%-%$MONTH%-%$DAY%.log&quot;# 过滤本地消息:fromhost-ip, !isequal, &quot;127.0.0.1&quot; ?Remote 配置好rsyslog，就可以重启一下服务了。 #systemctl restart rsyslog 如果没意外，netstat -antp | grep rsyslog 就能看到开放的514端口了。 Node1配置123## 将所有等于或者大于info级别的信息传到Center*.info;mail.none;authpriv.none;cron.none @@192.168.1.2$template myFormat,&quot;%timestamp% %fromhost-ip%%msg%\n&quot; 重启服务systemctl restart rsyslog,这个时候用logger &quot;test&quot; 在Center的/var/log/messages日志应该就能看到了。 配置nginx日志传输 同理也可以用到其它日志传输上。新版本的nginx基本都支持在nginx配置中，直接配置syslog。 但是我这里还是用老办法。现在rsyslog配置读取nginx的日志文件，然后传送过去，这个办法也试用于其它服务的日志。 Node1 新建一个rsyslog配置nginx.conf 1234567vim /etc/rsyslog.d/nginx.conf# 关键是路径和tag、statefilemodule(load=&quot;imfile&quot; PollingInterval=&quot;5&quot;)$InputFileName /var/log/nginx/access.log$InputFileTag nginx-access-1:$InputFileStateFile state-nginx-access-1$InputRunFileMonitor 我在一台V5版本上是这样配的1234567$ModLoad imfile$InputFileName /var/log/nginx/access.log$InputFileTag nginx-access-1:$InputFileStateFile state-nginx-access-1$InputFileFacility local5$InputFileSeverity info$InputRunFileMonitor Center 这个配置例子好匮乏，找了好多资料，终于谷爹那里找到了。见文末参考资料。根据配置的tag导出日志到特定文件。同样新建一个rsyslog配置文件nginx.conf，使用omfile模块,用dynaFile参数实现动态文件名。这个很多国内文章基本都没提到，还是看帮助文档发现这个的。否则我就用logrotate了。12345678910vim /etc/rsyslog.d/nginx.conftemplate(name=&quot;OnlyMsg&quot; type=&quot;string&quot; string=&quot;%msg:2:$%\n&quot;)template(name=&quot;dynaname&quot; type=&quot;string&quot; string=&quot;/logfiles/%fromhost-ip%/access-%$YEAR%%$MONTH%%$DAY%.log&quot;)if( $syslogtag == &apos;nginx-access-1:&apos;) then &#123; # write to file action(type=&quot;omfile&quot; dynaFile=&quot;dynaname&quot; template=&quot;OnlyMsg&quot;) # forward over network call sendToLogserver stop&#125; 重启rsyslog，应该就没问题了。 参考资料 Rsyslog configuration Output modules]]></content>
      <categories>
        <category>operations</category>
      </categories>
      <tags>
        <tag>rsyslog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网站访问过慢原因排查几点考虑]]></title>
    <url>%2Farticle%2F20170422%2Fwebsite-slowness-troubleshooting%2F</url>
    <content type="text"><![CDATA[基于我们团队现在业务还在处于比较初期的阶段。访问量并不大，性能问题就成了一个重要但是不紧急的任务。 我而目前主要在发布、监控自动化、可视化。尽可能减少人为操作的问题上努力。 最近深圳那边同事说服务器有点问题，主要是网站访问缓慢，叫如果有空帮忙看看。 我09年左右就开始运营自己的小网站，可以说也是经历过很多这类问题的排查。 也遇过很多奇葩的问题导致网站访问过慢，甚至打不开的情况，但是从未记录下来。 所以，打算开一篇博文记录一下，一方面当做一种笔记，一方面也帮助自己理清一下整个流程。 是哪个环节导致的问题？很多时候我们习惯访问一慢，就往服务器上看。看看是不是服务器出什么问题了。 其实，在访问网站的过程，任何一个环节都可能会出问题。 但是，最为常见的原因无非以下几种。 website slowness troubleshooting往大来分类 自己电脑-&gt;网络运营商-&gt;DNS-&gt;主机服务商-&gt;服务器 而前面几个大多时候是我们不可控的。除了选择的时候 :D 但是，也得在我们考虑范围内，否则有时候可能白忙碌一场。 抛开不可控的因素，服务器上发生的所有一切才是我们最为关心的。 常见外在因素1. 遭受攻击这个问题，其实攻击都是有成本的，如果没有业务冲突，规模不大，很多时候是没人闲的蛋疼跑去攻击你。这个大多情况都是可以被排除的。 常见攻击 DDoS、RDDoS 拒绝服务攻击 WebCC 这两个其实还是比较简单粗暴的。这个的防护，小规模的，现在很多大的云主机商多少都提供了这类的防护。节点少的，尽可能隐藏自己的源IP可以少很多麻烦 大规模的攻击，基本都是要上升到讨论成本的东西，软硬件防护，多节点，负载均衡等杂七杂八的，增加自己的成本，提高攻击者的攻击成本。 一些服务器上做的配置防护，在这类分布式多IP的大规模攻击下，效果微乎其微。 2.访问量过大整个对于大多网站来说，是喜闻乐见的。不过这些访问，不单单包括自然访问，还有一些非自然访问量。 自然访客 搜索引擎/爬虫/采集器的蜘蛛 （一些网站被采集器爬到到整个网站访问缓慢也是挺常见的） 一些无目的的攻击扫描等 常见内在因素根据木桶原理，任何一个短板，都有可能导致整个服务流程出现缓慢。 1.基础服务-硬件 CPU 内存 网络IO 硬盘IO 如果硬件到了瓶颈，那就该考虑，是不是该升级配置了？是不是该做CDN加速了？是不是该做负载均衡了？ 如果排除前面提到的一些不可控和被攻击的问题，而硬件负载都很低，那基本问题就出现在服务和业务相关问题上了。 2.高级服务-软件服务 web服务 （Nginx/Apache/IIS等） 数据库 （MySQL/Oracle/MSSQL/redis等） 业务依赖的其它服务 服务的配置是否针对当前服务器的配置进行过针对性的优化？是否能发挥了当前硬件的潜能？ 3.逻辑问题-业务问题 代码效率问题 （比方算法，有些查询语句） 业务逻辑问题 （ 比如优化资源访问方式，比如说分拆业务合并业务，减少请求数 ） 资源没有复用 （ 比方一些静态资源不缓存，一些连接没有复用，动态常用使用的资源不缓存 ） 简而言之，哪个拖后腿整哪个。剩下的就是定位问题和解决问题，这也是最重要的部分。 先挖坑，以后再填。]]></content>
      <tags>
        <tag>slowness</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL Workbench 6.3.6 CE版导出 5.5.52 MariaDB报错]]></title>
    <url>%2Farticle%2F20170422%2Fmariadb-export-error-troubleshooting%2F</url>
    <content type="text"><![CDATA[报错：mysqldump: unknown variable ‘set-gtid-purged=OFF’ 完整出错如下：123456789101111:45:51 AM Dumping xxx_logview (gef_infos)Running: mysqldump --defaults-file=&quot;/tmp/tmpePBoof/extraparams.cnf&quot; --set-gtid-purged=OFF --user=root --host=119.23.xxx.xxx --protocol=tcp --port=3306 --default-character-set=utf8 --no-data --skip-triggers &quot;xxx_logview&quot; &quot;gef_infos&quot;mysqldump: unknown variable &apos;set-gtid-purged=OFF&apos;Operation failed with exitcode 711:45:51 AM Dumping xxx_logview (gef_users)Running: mysqldump --defaults-file=&quot;/tmp/tmpbh7vOY/extraparams.cnf&quot; --set-gtid-purged=OFF --user=root --host=119.23.xxx.xxx --protocol=tcp --port=3306 --default-character-set=utf8 --no-data --skip-triggers &quot;xxx_logview&quot; &quot;gef_users&quot;mysqldump: unknown variable &apos;set-gtid-purged=OFF&apos;Operation failed with exitcode 711:45:51 AM Export of /home/xxx/dumps/Dump20170422-1 has finished with 2 errors 出错很明显是mysqldump 不支持这个set-gtid-purged。我用的是MairaDB自带的mysqldump工具，版本如下。可能移除了这个特性。 mysqldump Ver 10.15 Distrib 10.0.29-MariaDB, for debian-linux-gnu (x86_64) 而MySQL Workbench在export data的时候，默认是加上–set-gtid-purged=OFF参数的。 所以，我能想到的方法如下： 理论上去掉它这个默认设置就可以了。但是很遗憾，我不知道workbench在哪里改这参数。。。找了半天。 安装一个MySQL数据库，然后在MySQL Workbench -&gt; Edit -&gt; Perferences -&gt; Administration -&gt; Path to mysqldump 指定你MySQL版本数据带的mysqldump工具的路径。 用其它数据库管理工具，比如我，最后用了DBeaver CE 算是Linux下一个很万能的数据库管理工具了。大部分场景下，和Navicat有得拼。关键还是免费！]]></content>
      <categories>
        <category>troubleshooting</category>
      </categories>
      <tags>
        <tag>mariadb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7.2 Git Clone 编译安装 GoAccess]]></title>
    <url>%2Farticle%2F20170418%2Fgoaccess-build-on-centos7%2F</url>
    <content type="text"><![CDATA[GoAccess GoAccess Download 作为一个轻量的日志分析，还是不错的。之前一直都是用命令安装。直到前几天为了体验最新版的UI，自己尝试在Ubuntu 16.04上编译安装，比较轻松。 可能是我自己的机子用了段时间，很多依赖包都装好了。但是在生产环境CentOS7.2上还是遇到了几个小问题。 安装依赖包1yum install ncurses-devel geoip-devel tokyocabinet-devel openssl-devel 安装完GeoIP记得更新一下 # geoipupdate 把数据库下载回来，之前不知道这个，导致老是觉得数据库太简陋了。 我的话是Clone git的源码安装的，步骤如下： $ git clone https://github.com/allinurl/goaccess.git $ cd goaccess $ autoreconf -fiv 这一步你可能会遇到像我一样的错误。 错误11-bash: autoreconf: command not found 这个安装 yum install －y autoconf 即可 错误21Can't exec "autopoint": No such file or directory 安装gettext-tools1yum install gettext-common-devel gettext-devel gettext-libs 错误31Can't exec "aclocal": No such file or directory at /usr/share/autoconf/Autom4te/FileUtils.pm line 326. 安装automake即可1yum install -y automake 或者干脆yum groupinstall &quot;Development tools&quot;直接大杂烩，一锅炖了。 $ make $ make install]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>goaccess</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Walle部署高级任务配置测试]]></title>
    <url>%2Farticle%2F20170410%2Fwalle-pre-deploy-test%2F</url>
    <content type="text"><![CDATA[walle高级任务设置所以试试发布自己的线上业务看看。 理论部署的前后，会触发四个任务。 pre_deploy、post_deploy、pre_release和post_release 名字来看，就比较好理解，部署前、部署后，发布前，发布后。 官方给出的流程如下： 以下是上线任务的发布进度条 很明显，触发的deploy任务是在宿主机。 我整理了如下表格： 任务 执行点 时间时间 pre_deploy 宿主机 代码检出前 post_deploy 宿主机 代码检出后，传送之前 pre_release 目标机 创建链接之前 post_release 目标机 创建链接之后 使用场景举例我们拉取开发环境的代码部署至宿主机，乃至线上环境的时候。有一些配置是要替换的，比如数据库账户之类的。有一些文件是要删除，一些目录是需要合并的。 但是，怎么做呢？ 这就用到这些任务了。大多数场景，我想就用pre-deploy或者pre release就够了。 用法基本都一样，差别就在执行顺序。 使用任务宿主机要用web执行系统命令，所以需要额外添加一句到sudoers文件里面。 visudo1Defaults:www !requiretty www 是web执行PHP的用户。 我们是有几个东西要替换。一个是配置目录、另外两个是用户的上传目录。用户上传的静态内容，开发环境是没有了。 考虑到每次复制替换，一个是费系统资源。 所以，我打算在传输之前，先删除掉静态资源。再传去服务器的时候，打上线上的资源的链接。 如此就能实现动态更新了。 有个官方没有说明的是。每次执行任务之前，都是进去到当前目录的。所以删除移动项目目录之类的，都用相对路径即可。]]></content>
      <categories>
        <category>walle</category>
      </categories>
      <tags>
        <tag>walle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx和php-fpm添加到服务 开启开机自启动]]></title>
    <url>%2Farticle%2F20170406%2Fnginx-php-fpm-autorun%2F</url>
    <content type="text"><![CDATA[接手管理某台ERP服务器的生产环境。主要配有LNMP环境，前两天发现，这些服务居然都没有配置自启动。 这完全不考虑服务器意外重启导致服务未能启动，从而引起长时间的服务中断么？ 所以，今天就特地添加了自启动。 本来，添加自启动是很简单的。尤其是yum安装出来的服务。 CentOS 71systemctl enable nginx php-fpm CentOS 5/612chkconfig nginx onchkconfig php-fpm on 然而，这台是自己下载的软件包，还是自己编译的不得而知。反正/etc/init.d/ 完全没这两货的影子。 没有那就添加吧，两个bash脚本。 我从网上扒拉了两段自己修改了一下。代码如下： nginx123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#!/bin/bash# chkconfig: - 85 15PATH=/app/nginxDESC="nginx daemon"NAME=nginxDAEMON=$PATH/sbin/$NAMECONFIGFILE=$PATH/conf/$NAME.confPIDFILE=$PATH/logs/$NAME.pidscriptNAME=/etc/init.d/$NAMEset -e[ -x "$DAEMON" ] || exit 0do_start() &#123; $DAEMON -c $CONFIGFILE || echo -n "nginx already running"&#125;do_stop() &#123; $DAEMON -s stop || echo -n "nginx not running"&#125;do_reload() &#123; $DAEMON -s reload || echo -n "nginx can't reload"&#125;case "$1" in start) echo -n "Starting $DESC: $NAME" do_start echo "." ;; stop) echo -n "Stopping $DESC: $NAME" do_stop echo "." ;; reload|graceful) echo -n "Reloading $DESC configuration..." do_reload echo "." ;; restart) echo -n "Restarting $DESC: $NAME" do_stop do_start echo "." ;; *) echo "Usage: $scriptNAME &#123;start|stop|reload|restart&#125;" &gt;&amp;2 exit 3 ;;esacexit 0 nginx 主程序一般自带了好多方法，比如好用的 stop、reload。所以nginx的代码显得比较简洁。 关于找nginx路径，一般其实用which nginx 或者 whereis nginx就够了。 但是想补充一个更加可靠的。 先找到nginx的pid号，ps -aux | grep nginx ll /proc/pid号 看到 exe 文件的链接路径就是我们要找的程序全路径了。1234567$ ps -aux | grep nginxWarning: bad syntax, perhaps a bogus '-'? See /usr/share/doc/procps-3.2.8/FAQroot 1147 0.0 0.0 46328 2488 ? Ss Mar14 0:00 nginx: master process nginxroot 3870 0.0 0.0 47280 3772 ? S Mar29 2:27 nginx: worker process$ sudo ls -l /proc/1147/ | grep exelrwxrwxrwx 1 root root 0 Mar 14 10:17 exe -&gt; /app/nginx/sbin/nginx php-fpm1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# pidfile: /var/run/php-fpm.pid# config: /usr/local/php/etc/php-fpm.confphp_command=/app/php56/sbin/php-fpmphp_config=/app/php56/etc/php-fpm.confphp_pid=/app/php56/var/run/php-fpm.pidRETVAL=0prog="php-fpm"#start functionphp_fpm_start() &#123; /app/php56/sbin/php-fpm #-c /app/php56/lib/php.ini -y $&#123;php_config&#125;&#125;start()&#123; if [ -e $php_pid ] then echo "php-fpm already start..." exit 1 fi php_fpm_start&#125;stop()&#123; if [ -e $php_pid ] then parent_pid=`cat $php_pid` all_pid=`ps -ef | grep php-fpm | awk '&#123;if('$parent_pid' == $3)&#123;print $2&#125;&#125;'` for pid in $all_pid do kill $pid done kill $parent_pid fi exit 1&#125;restart()&#123;# stop# start kill -USR2 `cat /app/php56/var/run/php-fpm.pid`&#125;# See how we were called.case "$1" instart) start ;;stop) stop ;;restart)# stop# start restart ;;status) status $prog RETVAL=$? ;;*) echo $"Usage: $prog &#123;start|stop|restart|status&#125;" exit 1esacexit $RETVAL 这个代码就有点随意了，我做了少量修改，注意修改下执行程序的路径和PID文件的路径就行了，这里代码并没有用到配置文件路径其实。如果无法正确加载配置，可以把我加上的#-c /app/php56/lib/php.ini -y ${php_config} 这句代码注释去掉。 另外 php-fpm的配置路径在ps -aux | grep php-fpm 即可看到。记得修改，去掉pid路径的注释。 虽然代码在没找到pid文件的时候，会自己尝试提取pid，但是建议还是去掉注释。 添加服务，开启自启动两个文件一个保存为 /etc/init.d/nginx 一个保存为 /etc/init.d/php-fpm 名字可以自己改，但是不推荐。 添加进chkconfig chkconfig --add nginx &amp;&amp; chkconfig -add php-fpm 开启开机启动 chkconfig nginx on &amp;&amp; chkconfig php-fpm on 可以直接在 /etc/rc.local 修改吗可以的。 比如12/app/nginx/sbin/nginx -c /app/nginx/conf/nginx.conf/app/php56/sbin/php-fpm 为何不这样做，为了以后管理服务，比如重启方便一点。 参考资料 https://my.oschina.net/yearnfar/blog/284862]]></content>
      <categories>
        <category>operations</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>php-fpm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu16.04LTS Centos7 安装Docker CE]]></title>
    <url>%2Farticle%2F20170329%2Fubuntu-dockerce-installation%2F</url>
    <content type="text"><![CDATA[近日需要频繁测试各种环境，奔波于各种虚拟机之间，虽然自己制作了诸多虚拟机环境模板，平时直接克隆软连接使用。 但是还是感受到了世界满满的恶意。 所以决定安装一下docker 减轻一下工作量。一个人kubernetes就没必要装了吧。 觉得如果用kubernetes去管理团队各个机器的开发者的环境，减轻他们平时环境搭建的麻烦还是挺不错的。 不过，还没到时候。 本文主要参考docker的官方文档。 安装docker ce 社区版如果之前安装了旧版本的docker，旧版本docker名字是docker或者docker-engine sudo apt-get remove docker docker-engine 因为新版本的docker仓库改为使用https链接，所以，还要运行以下语句，让apt允许使用https方式链接 1$ sudo apt-get install apt-transport-https ca-certificates curl software-properties-common 安装官方源的GPG key，关闭GPG check应该也是可以的。1$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - 安装docker源如果和我一样是使用linux mint的话，$(lsb_release -cs)并不能获取Ubuntu的版本代号，获取的是自己的。自行修改，比如我的是16.04 那就是 xenial。1234$ sudo add-apt-repository \ &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu \ xenial \ stable&quot; 更新源123sudo apt-get updatesudo apt-get install docker-ce done. 建私有仓库先下载一个docker的registry镜像。 其实，应该 sudo apt install docker-registry就能直接装一个的，当服务管理。 这里就用docker镜像实现吧。 我直接用root账户用docker 123456789# docker pull registry# mkdir /e/docker/registry #搞个目录给仓库挂载# docker run -d -p 5000:5000 -v /e/docker/registry:/tmp/registry registry# deamon方式运行registry镜像 暴露5000端口# docker run -d -p 5000:5000 -v /e/docker/registry:/tmp/registry registryad0169c6aa3fdf64e00157698f3c4938d55039661916c536b6e2dcce56ab5a40# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESad0169c6aa3f registry &quot;/entrypoint.sh /e...&quot; 14 seconds ago Up 14 seconds 0.0.0.0:5000-&gt;5000/tcp musing_davinci 尝试push一个镜像到自己仓库我本地docker环境IP是 192.168.1.88 那么仓库地址就是 http://192.168.1.88:5000首先给本地镜像打个tag12# docker pull centos # 先从官方镜像仓库拉一个centos回来测试# docker tag centos 192.168.1.88:5000/centos 这个时候 # docker push 192.168.1.88:5000/centos 遇到了错误。 docker现在版本默认仓库都是使用https协议连接的，要使用本地仓库，还能自定义添加非安全的仓库地址。 步骤如下： 1.修改 /etc/default/docker 1DOCKER_OPTS="--registry-mirror=http://xxxxxxxx.m.daocloud.io --insecure-registry 192.168.1.88:5000 --dns 8.8.8.8 --dns 8.8.4.4" 重点是--insecure-registry 192.168.1.88:5000这句以往这样修改就没问题了。然而今天发现重启docker后，居然没生效。systemctl status docker 没看到启动参数有我们添加的内容 2.修改服务文件，增加指定启动参数 其实直接在ExecStart直接添加--insecure-registry 192.168.1.88:5000是一样可以的。但是为了管理方便，和以后便于修改，就改成如下形式。从/etc/default/docker读取$DOCKER_OPTS的配置。 12345# vim /lib/systemd/system/docker.serviceEnvironmentFile=/etc/default/docker # 新增加这句到 [service]ExecStart=-/usr/bin/dockerd -H fd:// $DOCKER_OPTS # 引用 $DOCKER_OPTS# systemctl daemon-reload# systemctl restart docker 这个时候再systemctl status docker 就能看到我们添加的参数了。 ps. docker.service文件也可以通过systemctl status docker查看到。 3.Push 到本地仓库 1234# docker push 192.168.1.88:5000/centosThe push refers to a repository [192.168.1.88:5000/centos]9b198ff9ff5b: Pushedlatest: digest: sha256:d7f3db1caf4ea76117abce89709ebfc66c9339e13866016b8b2e4eee3ab4bea0 size: 529 这个时候就能很愉快地完成push到本地仓库了。 更方便的安装看到这个的我眼泪留下来，daocloud.io搞的东西。 http://get.daocloud.io 1234567891011在 Linux上 安装 DockerDocker 的 安装资源文件 存放在Amazon S3，会间歇性连接失败。所以安装Docker的时候，会比较慢。你可以通过执行下面的命令，高速安装Docker。curl -sSL https://get.daocloud.io/docker | sh适用于Ubuntu，Debian,Centos等大部分Linux，会3小时同步一次Docker官方资源安装体验版或测试版，体验最新Docker。curl -sSL https://get.daocloud.io/docker-experimental | shcurl -sSL https://get.daocloud.io/docker-test | sh Centos7 1234567yum install -y yum-utilsyum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repoyum makecache fast#Docker CE yum install docker-ce#Docker EE yum install docker-ee 阿里云无外网IP,内网环境安装Docker今天遇到,所以补充一下.阿里云提供了一个镜像源https://mirrors.cloud.aliyun.com/docker-ce/ 但是没外网的时候是访问不了的,经过一番观察,只需做如下改动即可. 阿里云提供了一个内网访问的域名.将链接改成如下信息即可 http://mirrors.cloud.aliyuncs.com/docker-ce/ 12345678910yum install -y yum-utilsyum-config-manager --add-repo http://mirrors.cloud.aliyuncs.com/docker-ce/linux/centos/docker-ce.repo# 印象中就改了两处 反正目的就是吧repo的外网链接改为阿里云内网的.sed -i 's/https/http/g' /etc/yum.repos.d/docker-ce.reposed -i 's/aliyun/aliyuncs/g' /etc/yum.repos.d/docker-ce.repoyum makecache fast# Docker CEyum install docker-ce# Docker EEyum install docker-ee 参考资料 Docker Document Docker Cheat Sheet]]></content>
      <categories>
        <category>docker</category>
        <category>installation</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>installation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python基于Scrapy框架写个麻雀虽小五脏俱全的爬虫]]></title>
    <url>%2Farticle%2F20170328%2Fpython-scrapy-ipproxy%2F</url>
    <content type="text"><![CDATA[这个东西写有半个月了，最近工作忙没空理会，看了下数据，跑得还不错。 用各种框架和开源项目配合，站在巨人的肩膀上，轻轻松松完成一个麻雀虽小五脏俱全的爬虫。 采集URL，大规模URL去重，分类，入库，反爬虫。而完成这些，只需要寥寥不到三百行代码。 Scrapy工程目录如下12345678910111213141516171819202122232425262728293031323334353637383940414243./├── crawls # 开启持久化会产生一些记录文件├── sbdspider│ ├── __init__.py│ ├── __init__.pyc│ ├── items.py # 定义要采集的字段│ ├── items.pyc│ ├── middlewares # 中间件 主要是随机选择 UserAgent和代理IP 主要用来反爬虫│ │ ├── __init__.py│ │ ├── __init__.pyc│ │ ├── RandomProxy.py│ │ ├── RandomProxy.pyc│ │ ├── RandomUserAgent.py│ │ └── RandomUserAgent.pyc│ ├── middlewares.py│ ├── pipelines.py # 入库MySQL│ ├── pipelines.pyc│ ├── scrapy_redis # 用的九茶的模块 用Bloomfilter+redis去重│ │ ├── BloomfilterOnRedis.py│ │ ├── BloomfilterOnRedis.pyc│ │ ├── connection.py│ │ ├── connection.pyc│ │ ├── dupefilter.py│ │ ├── dupefilter.pyc│ │ ├── __init__.py│ │ ├── __init__.pyc│ │ ├── isExists.py│ │ ├── pipelines.py│ │ ├── queue.py│ │ ├── queue.pyc│ │ ├── scheduler.py│ │ ├── scheduler.pyc│ │ ├── spiders.py│ │ ├── spiders.pyc│ │ └── tests.py│ ├── settings.py # 配置 pipeline、middlewares的引用声明主要在这里│ ├── settings.pyc│ └── spiders│ ├── __init__.py│ ├── __init__.pyc│ ├── sobaidupan.py # 爬虫主体 主要是提取数据 分类│ └── sobaidupan.pyc└── scrapy.cfg 首先是字段的定义，我需要保存哪些信息1234567891011121314151617import scrapyclass SbdspiderItem(scrapy.Item): # define the fields for your item here like: # name = scrapy.Field() tid = scrapy.Field() # 网盘类型ID cid = scrapy.Field() # 资源分类ID uid = scrapy.Field() # 资源用户ID name = scrapy.Field() avatar = scrapy.Field() title = scrapy.Field() # 资源标题 size = scrapy.Field() # 资源大小 url = scrapy.Field() # 资源URL pwd = scrapy.Field() # 资源密码 description = scrapy.Field() # 资源描述 available = scrapy.Field() # 是否可用 sharetime = scrapy.Field() # 分享时间 然后我设计了这样的数据库表来保存它们：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158-- phpMyAdmin SQL Dump-- version 4.6.6-- https://www.phpmyadmin.net/---- Host: localhost-- Generation Time: 2017-03-10 05:44:53-- 服务器版本： 5.5.53-log-- PHP Version: 5.5.38SET SQL_MODE = "NO_AUTO_VALUE_ON_ZERO";SET time_zone = "+00:00";/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;/*!40101 SET NAMES utf8mb4 */;---- Database: `yzy_data`---- ------------------------------------------------------------ 表的结构 `yzy_class`--CREATE TABLE `yzy_class` ( `id` int(11) NOT NULL, `cname` varchar(10) NOT NULL) ENGINE=MyISAM DEFAULT CHARSET=utf8mb4;---- 转存表中的数据 `yzy_class`---- 这样我以后保存分类ID就够了，避免重复字段太多，占用太多数据库，也不方便数据大后索引INSERT INTO `yzy_class` (`id`, `cname`) VALUES(1, '其它'),(2, '音乐'),(3, '图片'),(4, '电子书'),(5, '文档'),(6, '种子'),(7, '手机APP'),(8, '影视'),(9, '无损音乐'),(10, '教程');-- ------------------------------------------------------------ 表的结构 `yzy_resources`---- 这个表才是重点 基本Items.py定义的都是保存到这里来CREATE TABLE `yzy_resources` ( `id` int(11) NOT NULL, `tid` tinyint(3) UNSIGNED NOT NULL, `cid` tinyint(3) UNSIGNED NOT NULL, `uid` int(11) NOT NULL, `title` varchar(80) NOT NULL, `size` varchar(10) NOT NULL, `url` varchar(255) NOT NULL, `pwd` varchar(10) NOT NULL, `description` varchar(100) NOT NULL, `available` tinyint(1) NOT NULL) ENGINE=MyISAM DEFAULT CHARSET=utf8mb4;-- ------------------------------------------------------------ 表的结构 `yzy_type`---- 留一个表保存资源类别，为以后多个类型网盘资源采集打下基础CREATE TABLE `yzy_type` ( `id` int(11) NOT NULL, `name` char(10) NOT NULL, `ename` char(10) NOT NULL, `shortname` char(4) NOT NULL, `url` varchar(255) NOT NULL) ENGINE=MyISAM DEFAULT CHARSET=utf8mb4;---- 转存表中的数据 `yzy_type`--INSERT INTO `yzy_type` (`id`, `name`, `ename`, `shortname`, `url`) VALUES(1, '百度网盘', 'dupan', '度盘', 'https:/pan.baidu.com/');-- ------------------------------------------------------------ 表的结构 `yzy_users`---- 保存网盘用户信息CREATE TABLE `yzy_users` ( `id` int(11) NOT NULL, `tid` tinyint(4) NOT NULL, `uid` varchar(20) NOT NULL, `uname` varchar(20) NOT NULL, `avatar` varchar(255) NOT NULL) ENGINE=MyISAM DEFAULT CHARSET=utf8mb4;---- Indexes for dumped tables------ Indexes for table `yzy_class`--ALTER TABLE `yzy_class` ADD PRIMARY KEY (`id`);---- Indexes for table `yzy_resources`--ALTER TABLE `yzy_resources` ADD PRIMARY KEY (`id`);---- Indexes for table `yzy_type`--ALTER TABLE `yzy_type` ADD PRIMARY KEY (`id`);---- Indexes for table `yzy_users`--ALTER TABLE `yzy_users` ADD PRIMARY KEY (`id`);---- 在导出的表使用AUTO_INCREMENT------ 使用表AUTO_INCREMENT `yzy_class`--ALTER TABLE `yzy_class` MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=11;---- 使用表AUTO_INCREMENT `yzy_resources`--ALTER TABLE `yzy_resources` MODIFY `id` int(11) NOT NULL AUTO_INCREMENT;---- 使用表AUTO_INCREMENT `yzy_type`--ALTER TABLE `yzy_type` MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=2;---- 使用表AUTO_INCREMENT `yzy_users`--ALTER TABLE `yzy_users` MODIFY `id` int(11) NOT NULL AUTO_INCREMENT;/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */; 注意看注释，还是很好理解这些表干嘛用的。 pipelines.py获取到的Items怎么处理 这里有两个类，其实是两种处理方式，一种是默认的，我改了一下，采集到的数据，以JSON的形式保存。 sobaiduPipeline才是重点，主要有两次插入数据，一次是插入用户数据，一次获取到用户ID后，插入到yzy_resources表。 数据库的定义在 settings.py 里面 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162import json import MySQLdbfrom scrapy.exceptions import DropItemimport settings class SbdspiderPipeline(object): def __init__(self): self.file = open('items.jl', 'wb') def process_item(self, item, spider): line = json.dumps(dict(item)) + "\n" self.file.write(line) return item# 入库到MySQLclass sobaiduPipeline(object): # 初始化连接 def __init__(self): self.conn=MySQLdb.connect(host=settings.MYSQL_HOST, user=settings.MYSQL_USER, passwd=settings.MYSQL_PASS, db=settings.MYSQL_NAME, charset='utf8', use_unicode=True) self.curosr = self.conn.cursor() # 处理item def process_item(self,item,spider): try: userid = self.insert_user(item['uid'],item['name'],item['avatar']) sql="""INSERT INTO yzy_resources(tid,cid,uid,title,size,url,pwd,description,available,sharetime) VALUES('%d','%d','%d','%s','%s','%s','%s','%s','%d','%s') """%(item['tid'],item['cid'],userid,item['title'],item['size'],item['url'],item['pwd'],item['description'],item['available'],item['sharetime']) vsql=sql.encode('utf8') self.curosr.execute(vsql) except MySQLdb.Error,e: print "Error:%d:%s" % (e.args[0],e.args[1]) return item # 插入用户数据 def insert_user(self,uid,name,pic): try: userid=0 bSginal=self.curosr.execute("SELECT * FROM yzy_users WHERE uid='%s'"%(uid)) if bSginal==1: results=self.curosr.fetchone() userid=results[0] else: sql = """INSERT INTO yzy_users(uid,uname,avatar) VALUES('%s','%s','%s')"""%(uid,name,pic) vsql = sql.encode('utf8') if self.curosr.execute(vsql)==1: userid=self.curosr.lastrowid except MySQLdb.Error,e: print "Error:%d:%s" % (e.args[0], e.args[1]) return userid sobaidupan.py 蜘蛛的主体123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123# -*- coding: utf-8 -*-from sbdspider.scrapy_redis.spiders import RedisSpider# 这里我引入的是九茶的模块 RedisSpiderfrom scrapy.http import Requestfrom sbdspider.items import SbdspiderItemimport requestsimport reimport datetimeclass SobaidupanSpider(RedisSpider): name = "sobaidu" # class type keymap ckm_music=('mp3','wav','mid','wma','cda','acc') # id 2 ckm_picture=('jpg','jpeg','png','gif','psd','bmp','svg','tga') # id 3 ckm_ebook=('txt','pdf','mobi','azw','mbp','ebx') # id 4 ckm_docfile=('doc','docx','wps','ppt','xls','xlsx') # id 5 ckm_app=('apk','ipa','sis','sisx','xap') # id 6 ckm_torrent=('torrent') # id 7 ckm_movie=('mkv','rmvb','mp4','rm','avi','wmv','asf','asx','mpg','mpeg','mpe','3gp','flv','f4v','vob','mov') # id 8 ckm_apeflac=('ape','flac') # id 9 ckm_teach=(u'教程',u'入门',u'精讲',u'详解',u'课程') # id 10 allowed_domains = ["www.sobaidupan.com"] redis_key = "sobaidupan:start_urls" start_urls = ['http://www.sobaidupan.com/'] def start_requests(self): for u in self.start_urls: yield Request(u,callback=self.parse, errback=self.errback) def parse(self, response): yield self.parse_item(response) for a in response.css('a::attr(href)').extract(): if not a: continue next_url = response.urljoin(a) yield Request(next_url,callback=self.parse) # 匹配字段 def parse_item(self,response): uid = re.search('user-(\d*)-1\.html',response.text) name = re.search(u'&lt;div align="center"&gt;用户名：(.+?)&lt;/div&gt;&lt;/td&gt;',response.text) avatar = re.search('&lt;img src="(.+?)" width="100" height="100" border="0"&gt;',response.text) title = re.search('&lt;h1&gt;(.+?)&lt;/h1&gt;',response.text) ressize = re.search(u'&lt;B&gt;资源大小：&lt;/B&gt;(.+?)&amp;nbsp;&lt;b&gt;',response.text) description = re.search(u'&lt;B&gt;资源类别：&lt;/B&gt;(.+?)&lt;/div&gt;',response.text) sharetime = re.search(u'&lt;b&gt;分享日期：&lt;/b&gt;(.+?)&lt;/div&gt;',response.text) res = re.search('href="(http://sbdp\.baidudaquan\.com/down\.asp\?id=.+?)"',response.text) if res is not None and title is not None: ssource = requests.get(res.group(1)) ssource.encoding = 'utf-8' resurl = re.search("URL=(.+?)'",ssource.text) # re.search("URL=(http://pan\.baidu\.com/share/link\?shareid=.+?)'",ssource.text) if resurl is not None: item = SbdspiderItem() item['tid'] = 1 item['cid'] = self.classifyRes(title.group(1)) item['uid'] = uid.group(1) item['name'] = name.group(1) item['avatar'] = avatar.group(1) item['title'] = title.group(1) if ressize is not None: item['size'] = ressize.group(1) else: item['size'] = '未知' item['url'] = resurl.group(1) item['pwd'] = '' if description is not None: item['description'] = description.group(1) else: item['description'] = '' item['available'] = 1 if sharetime is not None: item['sharetime'] = sharetime.group(1) else: dt = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") item['sharetime'] = dt return item # 大致给数据分类 def classifyRes(self,title): ext_title='' classid=1 # 初始化ID为1 # 尝试提取后缀 if len(title.split('.'))&gt;=2: ext_title = title.split('.')[-1] else: ext_title = title ext_title.encoding = 'utf-8' # 按keymap分类 if ext_title in self.ckm_music: classid = 2 elif ext_title in self.ckm_picture: classid = 3 elif ext_title in self.ckm_ebook: classid = 4 elif ext_title in self.ckm_docfile: classid = 5 elif ext_title in self.ckm_torrent: classid = 6 elif ext_title in self.ckm_app: classid = 7 elif ext_title in self.ckm_movie: classid = 8 elif ext_title in self.ckm_apeflac: classid = 9 else: for s in self.ckm_teach: if s in ext_title: classid = 10 return classid def errback(self, failure): pass 多IP代理采集反爬虫 IPProxys+RandomUserAgent 先下载安装这个 IPProxyPool 。 搭建成功后，运行有采集到数据的话，curl http://127.0.0.1:8000/?types=0&amp;count=5&amp;country=国内 可以看到返回json格式的数据。这样就成功一半了。 主要调用接口和随机切换代码 RandomProxy.py123456789101112class RandomProxy(object): def __init__(self): self.r = requests.get(u'http://127.0.0.1:8000/?types=0&amp;count=&amp;country=国内') self.ip_ports=json.loads(self.r.text) def process_request(self, request, spider): # 数组中随机取一个 ip_port=random.choice(self.ip_ports) # 拼接起来 http_proxy="http://%s:%s"%(ip_port[0],ip_port[1]) # 设置代理 request.meta['proxy'] = http_proxy 最后怎么在服务器上挂机采集，爬虫持久化 1nohup scrapy crawl sobaidu -s JOBDIR=crawls/sobaidu-1 1&gt;/dev/null 2&gt;logfile.log &amp; 数据样本，5天28万的数据，主要是代理IP质量不高，否则速度还能上一个台阶，还不是分布式。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130MariaDB [yzy_data]&gt; select count(*) from yzy_resources;+----------+| count(*) |+----------+| 283888 |+----------+1 row in set (0.00 sec)MariaDB [yzy_data]&gt; select * from yzy_resources limit 10 \G;*************************** 1. row *************************** id: 1 tid: 1 cid: 1 uid: 0 title: 《帝王师刘伯温[精品]》.epub size: 2.65 MB url: http://pan.baidu.com/share/link?shareid=2676964745&amp;uk=4194551491&amp;fid=646837282049387 pwd: description: 人物传记 available: 1 sharetime: 2015-11-17 04:59:00*************************** 2. row *************************** id: 2 tid: 1 cid: 4 uid: 0 title: 余念.txt size: 338.77 KB url: http://pan.baidu.com/s/1jIRZs7W pwd: description: / available: 1 sharetime: 2017-02-14 07:37:00*************************** 3. row *************************** id: 3 tid: 1 cid: 4 uid: 0 title: 《千山记》石头与水（晋江金牌推荐超高积分01-13更新至完结）.txt size: 4.07 MB url: http://pan.baidu.com/s/1geJHGll pwd: description: / available: 1 sharetime: 2017-02-14 07:37:00*************************** 4. row *************************** id: 4 tid: 1 cid: 8 uid: 0 title: （微博：小小精灵玩家520）政宗くんのリベンジ 09.mp4 size: 195.44 MB url: http://pan.baidu.com/s/1c13Bcp6 pwd: description: 高清动漫下载区/2017年1月新番/政宗君的复仇/（微博：小小精灵玩家520）政宗くんのリベンジ 09.mp4 available: 1 sharetime: 2017-03-04 05:31:00*************************** 5. row *************************** id: 5 tid: 1 cid: 1 uid: 0 title: 04 Take It （Previously Unreleased）.m4a size: 5.71 MB url: http://pan.baidu.com/s/1ntAxIZJ pwd: description: / available: 1 sharetime: 2017-03-12 17:16:00*************************** 6. row *************************** id: 6 tid: 1 cid: 1 uid: 0 title: 表情.zip size: 4.96 MB url: http://pan.baidu.com/s/1gdd1XYV pwd: description: / available: 1 sharetime: 2017-03-12 17:16:00*************************** 7. row *************************** id: 7 tid: 1 cid: 1 uid: 0 title: 【艾薇儿饭团】07年Flare杂志.rar size: 563.13 KB url: http://pan.baidu.com/share/link?shareid=3408670202&amp;uk=1042245391 pwd: description: / available: 1 sharetime: 2017-03-12 17:16:00*************************** 8. row *************************** id: 8 tid: 1 cid: 1 uid: 0 title: 【艾薇儿饭团】2003滚石杂志.rar size: 3 MB url: http://pan.baidu.com/share/link?shareid=424894405&amp;uk=1042245391 pwd: description: / available: 1 sharetime: 2017-03-12 17:16:00*************************** 9. row *************************** id: 9 tid: 1 cid: 1 uid: 0 title: 【饭团资源】致敬艾薇儿.rar size: 75.64 MB url: http://pan.baidu.com/share/link?shareid=1371654997&amp;uk=1042245391 pwd: description: / available: 1 sharetime: 2017-03-12 17:16:00*************************** 10. row *************************** id: 10 tid: 1 cid: 1 uid: 0 title: AVRIL.Candy.zip size: 4.33 MB url: http://pan.baidu.com/s/1ntCy8sx pwd: description: / available: 1 sharetime: 2017-03-12 17:16:0010 rows in set (0.00 sec) 项目下载地址 sbdspider 参考资料 Scrapy入门教程 基于Redis的Bloomfilter去重 IPProxyPool python开源IP代理池–IPProxys]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Scrapy</tag>
        <tag>IPProxy</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx日志分割处理]]></title>
    <url>%2Farticle%2F20170327%2Fnginx-logfile-rotate%2F</url>
    <content type="text"><![CDATA[nginx现在用yum源安装的话，都自带了logrotate，默认是每天定时分割日志并压缩。 但是公司目前有一台生产环境的nginx不是用yum安装的。所以就得自己手动分割下日志了。 目前就是bash脚本+crontab实现，具体代码如下： 12345678910111213141516171819202122232425262728#!/bin/bash#初始化# 日志路径LOGS_PATH=/app/nginx/logsYESTERDAY=$(date -d "yesterday" +%Y%m%d)# 访问日志路径+名字ACCESS_FILE_NAME=$&#123;LOGS_PATH&#125;/sxyz_erp_nginx_access_$&#123;YESTERDAY&#125;# 错误日志路径+名字ERROR_FILE_NAME=$&#123;LOGS_PATH&#125;/sxyz_erp_nginx_error_$&#123;YESTERDAY&#125;#移动重命名访问日志 压缩并删除源文件mv $&#123;LOGS_PATH&#125;/access.log $&#123;ACCESS_FILE_NAME&#125;.logtar -zcf $&#123;ACCESS_FILE_NAME&#125;.tar.gz $&#123;ACCESS_FILE_NAME&#125;.logrm -rf $&#123;ACCESS_FILE_NAME&#125;.log#移动重命名错误日志 压缩并删除源文件mv $&#123;LOGS_PATH&#125;/error.log $&#123;ERROR_FILE_NAME&#125;.logtar -zcf $&#123;ERROR_FILE_NAME&#125;.tar.gz $&#123;ERROR_FILE_NAME&#125;.logrm -rf $&#123;ERROR_FILE_NAME&#125;.log# 向nginx进程发送 USR1 让它重新读取配置生成日志kill -USR1 $(cat /app/nginx/logs/nginx.pid)#删除20天前的日志cd $&#123;LOGS_PATH&#125;find . -mtime +20 -name "sxyz_erp_nginx_*" | xargs rm -fexit 0]]></content>
      <categories>
        <category>operations</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>logfile</tag>
        <tag>rotate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[密码的管理和使用]]></title>
    <url>%2Farticle%2F20170326%2Fsecurity-password-level%2F</url>
    <content type="text"><![CDATA[一个弱口令往往是入侵的突破口之一。拿IT从业者云集的CSDN600多万个密码统计出来的一个使用频次最高的密码列表，绝对是弱口令的佼佼者。 如下，弱口令不仅限于以下密码： 重复次数 密码 占比 235012 123456789 (5.82013097845522) 212749 12345678 (5.26878221339919) 76346 11111111 (1.89072779126658) 46053 dearbook (1.14051406715741) 34952 00000000 (0.865595024760297) 19986 123123123 (0.494958290365624) 17790 1234567890 (0.440573800940881) 15033 88888888 (0.372296006157632) 6995 111111111 (0.173232925102949) 5965 147258369 (0.14772471740373) 5553 987654321 (0.137521434324042) 5459 aaaaaaaa (0.135193500805861) 5145 1111111111 (0.127417212245128) 5025 66666666 (0.124445382221918) 4435 a123456789 (0.109833884607803) 4096 11223344 (0.101438464792234) 3667 1qaz2wsx (0.0908141724592587) 3649 xiazhili (0.0903683979557772) 3610 789456123 (0.0894025531982339) 3501 password (0.0867031409271515) 3281 87654321 (0.0812547858845999) 3277 qqqqqqqq (0.0811557248838262) 3175 000000000 (0.0786296693640977) 3143 qwertyuiop (0.0778371813579084) 3094 qq123456 (0.076623684098431) 3080 iloveyou (0.0762769705957231) 3061 31415926 (0.0758064308420482) 2985 12344321 (0.0739242718273486) 2885 0000000000 (0.0714477468080069) 2826 asdfghjkl (0.0699865970465953) 2796 1q2w3e4r (0.0692436395407928) 2580 123456abc (0.0638943454990148) 2578 0123456789 (0.063844814998628) 2573 123654789 (0.0637209887476609) 2540 12121212 (0.0629037354912782) 2515 qazwsxedc (0.0622846042364428) 2396 abcd1234 (0.0593375394634262) 2380 12341234 (0.0589412954603315) 2348 110110110 (0.0581488074541422) 2296 asdasdasd (0.0568610144440845) 2243 22222222 (0.0555484561838334) 2166 123321123 (0.0536415319189404) 2160 abc123456 (0.0534929404177799) 2138 a12345678 (0.0529481049135247) 2131 123456 (0.0527747481621708) 2113 123456123 (0.0523289736586893) 2106 a1234567 (0.0521556169073354) 2100 1234qwer (0.0520070254061749) 1989 qwertyui (0.0492580826347056) 1986 123456789a (0.0491837868841254) 1971 aa123456 (0.0488123081312241) 1918 asdfasdf (0.047499749870973) 1891 99999999 (0.0468310881157508) 1859 123456aa (0.0460386001095615) 1859 999999999 (0.0460386001095615) 1854 123456123456 (0.0459147738585944) 1699 520520520 (0.0420761600786148) 1656 963852741 (0.0410112543202979) 1652 55555555 (0.0409121933195242) 1652 741852963 (0.0409121933195242) 1589 33333333 (0.039351982557339) 1480 qwer1234 (0.0366525702862566) 1384 asd123456 (0.0342751062676886) 1339 77777777 (0.0331606700089848) 1316 qweasdzxc (0.0325910692545363) 1285 code8925 (0.0318233464985403) 1273 11112222 (0.0315261634962193) 1268 ms0083jxj (0.0314023372452523) 1245 zzzzzzzz (0.0308327364908037) 1214 111222333 (0.0300650137348078) 1206 qweqweqwe (0.0298668917332604) 1200 3.1415926 (0.0297183002320999) 1183 123456qq (0.0292972909788118) 1148 147852369 (0.0284305072220423) 1136 521521521 (0.0281333242197213) 1119 asdf1234 (0.0277123149664332) 1111 123698745 (0.0275141929648858) 1109 1123581321 (0.027464662464499) 1058 asdfghjk (0.0262016347046348) 1054 q1w2e3r4 (0.0261025737038611) 1037 12345678a (0.025681564450573) 1003 woaini1314 (0.0248395459439969) 991 1234abcd (0.0245423629416759) 988 123qweasd (0.0244680671910956) 975 1qazxsw2 (0.0241461189385812) 967 woaiwojia (0.0239479969370339) 920 321321321 (0.0227840301779433) 910 05962514787 (0.0225363776760091) 894 123456987 (0.0221401336729144) 892 kingcom5 (0.0220906031725276) 882 5845201314 (0.0218429506705934) 882 zxcvbnm123 (0.0218429506705934) 852 0987654321 (0.0210999931647909) 847 wwwwwwww (0.0209761669138239) 835 11111111111111111111 (0.0206789839115029) 805 12345600 (0.0199360264057004) 783 11235813 (0.0193911909014452) 777 1q2w3e4r5t (0.0192425994002847) 772 10101010 (0.0191187731493176) 770 123456asd (0.0190692426489308) 765 lilylily (0.0189454163979637) 744 12345612 (0.018425346143902) 741 5201314520 (0.0183510503933217) 740 1234554321 (0.0183262851431283) 732 12301230 (0.018128163141581) 729 woshishui (0.0180538673910007) 727 123456654321 (0.0180043368906139) 726 xiaoxiao (0.0179795716404205) 713 qwe123456 (0.017657623387906) 708 woaini123 (0.017533797136939) 702 111111 (0.0173852056357785) 693 1122334455 (0.0171623183840377) 685 12369874 (0.0169641963824904) 680 12345679 (0.0168403701315233) 669 100200300 (0.0165679523793957) 657 ffffffff (0.0162707693770747) 651 buzhidao (0.0161221778759142) 650 44444444 (0.0160974126257208) 649 woainima (0.0160726473755274) 642 z123456789 (0.0158992906241735) 623 1234567a (0.0154287508704985) 621 123456aaa (0.0153792203701117) 618 qazwsx123 (0.0153049246195315) 616 ssssssss (0.0152553941191446) 608 wojiushiwo (0.0150572721175973) 601 25257758 (0.0148839153662434) 592 123321aa (0.0146610281145026) 589 1357924680 (0.0145867323639224) 585 aaa123456 (0.0144876713631487) 578 369258147 (0.0143143146117948) 572 321654987 (0.0141657231106343) 571 q123456789 (0.0141409578604409) 570 qaz123456 (0.0141161926102475) 567 1233211234567 (0.0140418968596672) 567 9876543210 (0.0140418968596672) 565 wocaonima (0.0139923663592804) 562 1234567b (0.0139180706087001) 562 zhang123 (0.0139180706087001) 561 woaini520 (0.0138933053585067) 559 csdncsdn (0.0138437748581199) 559 google250 (0.0138437748581199) 556 yangyang (0.0137694791075396) 553 5845211314 (0.0136951833569594) 536 369369369 (0.0132741741036713) 535 20082008 (0.0132494088534779) 532 135792468 (0.0131751131028976) 525 299792458 (0.0130017563515437) 521 dddddddd (0.0129026953507701) 519 zxczxczxc (0.0128531648503832) 504 computer (0.012481686097482) 501 qwerasdf (0.0124073903469017) 为什么我们要使用弱口令还有比方便和便于记忆这个更好的理由吗？ 弱口令戳中了哪些痛点？ 便于记忆 便于输入 弱口令就不能使用吗？这倒未必，看使用场景吧。 比如一些安全性较低的网站，而你注册后，可能又不会登记敏感的资料，这就可以使用弱口令。 从而避免网站被入侵后，黑客获取你的密码，社工渗透到你其它敏感的账户。 那么问题来了，应该在怎样的网站使用怎样的密码呢？ 这里我说说我个人管理密码的一些策略吧。 密码的使用场景和应用 高频次使用，可以记录密码 高频次使用，不能记录密码，要手动输入 低频次密码，可以记录密码 低频次密码，要手动输入 1、 3、 4这种情况，建议还是使用生成的密码，无规律，很大程度可以防止被社工出密码，然后在登录的时候选择记住密码就可以了，现在基本浏览器、app大多都支持记住密码。再配合密码管理工具防止遗忘密码，基本不会与什么问题。 一次麻烦长久受益！ 我觉得问题最大这种是高频次使用，但是不能记录密码的。 举个栗子：支付宝等支付密码、keepassx 建议使用比较强壮的密码，可以的话，大小写数字特殊符号混合，长度不小于8位。 这类密码自己可以设计多几套，按场景使用。 密码管理工具个人是强烈建议使用Keepass的,如果配合TrueCrypt，那就安全性大大增强了。 KeePass官方网站 它有如下优点： 跨平台 windows mac linux Android iPhone 均可以使用 自动输入密码 密码生成 密码记录 密码分类管理 你还会因为怕输入麻烦和忘记密码而使用弱口令吗？ 其它密码生成网站推荐： 在线随机密码生成工具 参考资料 CSDN杯我最喜欢的CSDN密码评选]]></content>
      <categories>
        <category>security</category>
      </categories>
      <tags>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下不错的Gif录制工具推荐]]></title>
    <url>%2Farticle%2F20170325%2Fscreen-record-on-linux%2F</url>
    <content type="text"><![CDATA[Windows下有很多优秀的录屏工具，前一天，我为了录个GIF，又开了自己的Windows 10. 现在的Ubuntu，越来越优秀了，很多Windows的工具，都能在这里找到替代品，我用Windows似乎越来越少了。 但是两个系统都有自己的优势，都有一些好用到哭的软件。 录屏这方面，其实我用比较多也就OBS Studio和Camtasia Studio，推荐的也就这两个比较多。 前者一般我用于录MP4格式的，后者用于录制GIF。录出来的体积小得感人，清晰度也不错。 OBS现在已经有了for linux版本，提前走向了all platform。Camtasia还没有Linux版本，倒是有了Mac版的。 这让我很眼红Mac。Gif有时候还是要录制的，Linux下有没有过得去的替代品呢？ 一番查找还是有的。比如byzanz、peek、OBS+ffmepg等等，还有ttyrc这等奇葩。 byzanz这个工具录制出来体积其实是最小的，但是有个很不方便的地方，就是必须先设定录制时长。 我特么大多时候怎么知道我录制屏幕要多久。不过这个就作为备选方案吧，毕竟有时候我还是知道我应该录多久的。1sudo apt install byzanz peek相对于 byzanz，有好用的GUI界面，简单的操作，可以拖动选定录制区域，自由决定录制时间。 这个也是我个人的主选方案 安装：123sudo add-apt-repository ppa:peek-developers/stablesudo apt updatesudo apt install peek Peek Github项目地址 OBS+ffmepg这个我逗你玩。正常情况下，录制MP4再转GIF体积会比MP4还要大。不过如果用OBS录制的时候，调低速率，和减少每秒的帧数，再转换，还是能有不错的体积的。但是，麻不麻烦？ OBS 官网 OBS Github项目地址]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>tools</tag>
        <tag>screen record</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[svn泄露网站信息]]></title>
    <url>%2Farticle%2F20170324%2Fsvn-leaking-web-information%2F</url>
    <content type="text"><![CDATA[今天老板请团队吃饭，我和小林瞎侃，聊到信息安全。 突然想到之前上线每次都是整个目录复制发布，很有可能存在svn信息泄露问题。 最近一直在忙着架构方面的东西，把这茬的测试给忘了。 一回到家就开了电脑测试，惊出一身冷汗，简直是核弹。 话不多说，看图， 这里面图片仅仅是展示能够根据这些东西读取出文件目录。这里就发现了一个备份数据库。 实际危害比图片看到的大得多。 这件事情也是对我敲响了一个警钟，安全问题，还是刻不容缓。 怎么修复？ 治标方法，删除所有.svn目录。 进入要发布的目录执行，会将所有.svn目录删除 1find . -type d -name &apos;.svn&apos; | xargs rm -rf 治本方法，规范整个代码发布流程。 比如walle。如果用svn这类代码版本管理工具，最好用导出功能，别直接复制，.svn是隐藏目录。或者发布的时候，自己过滤掉这类敏感文件。 未雨绸缪, 设置web服务器拒绝访问这类后缀的文件,顺便把sql文件也捎上。 nginx -t 可以找到你的nginx配置文件 12345 location ~ .*.(svn|git|cvs|sql) &#123; deny all; &#125;#nginx -s reload 搞定，睡觉，明天估计要修改一大堆东西。 相关工具下载SVN泄露文件利用工具 其实工具展示的信息是阉割版的了。有兴趣的自己下载相关文件分析，信息量爆炸。]]></content>
      <categories>
        <category>security</category>
      </categories>
      <tags>
        <tag>svn</tag>
        <tag>information security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运维日志 数据备份同步的几个方案]]></title>
    <url>%2Farticle%2F20170317%2Fops-log-backup-rsysnc-sersync-inotify-tools%2F</url>
    <content type="text"><![CDATA[最近公司有这么一个需求。某ERP并发不高，web数据不大，单台服务器就能满足需求，暂时不需要负载均衡。 但是有对于服务高可用和数据安全需求比较高。所以想搞多一台服务器做灾备，实现高可用和数据备份。 选择服务器目前业务主要面向华南地区的店，所以服务器得选华南地区的。 主服务在阿里云，从服务器也选阿里云，方便管理，内网同步速度略优。缺点就是阿里云出问题，大家一起挂，另外使用同个账户管理的机器，账户泄露两个机子都遭殃。 选非阿里云的服务器，能更大程度避免单点故障情况发生，缺点是管理略为麻烦，同步可能会稍微慢一点点，占用出口带宽， 怎么备份目前打算至少存在两份异地备份。一份高频近乎实时同步的备份，一份低频定时备份到运维人员机子本地。 前面高频备份是高可用的基础，否则单点故障，备份服务器不能提供完整的数据。 而低频的本地备份可以在出现恶意的攻击，删库等行为后，依然有数据。 而这次备份的重点也是在线的同步备份。 昨天尝试使用 inotify-tools + rsync 用来发现创建修改文件等动作，然后触发 rsync 进行同步。 业务需求能满足，但是不好的是，每次事件触发都进行一次全局扫描，然后坐差异备份有点耗资源。 假如一次性通过命令创建几千个命令，那可能会触发几千次同步。 我想遇到这个问题的肯定不是我一人，度娘之，果然有针对这个问题的解决方案，那就是 sersync + rsync 根据设想的备份流程做了如下图 (绘图软件 dia 不能输入中文 囧) ERP服务器上运行 sersync 当inotify发现文件读写相关事件的时候，就向备份服务器发起同步，进行差异备份。 运维定时主动向备份服务器发起同步请求，同步备份数据回本地。 服务器配置备份服务器配置 新建一个账户sync_backup作为同步的专用账户，设置用户shell为/sbin/nologin，直接用root太危险了，这样就算密码泄露了，也不会直接导致系统沦陷。 12useradd sync_backup -s /sbin/nologinpasswd sync_backup --stdin #建议用密码生成工具生成一个足够强壮的密码复制黏贴过来。 配置rsync服务 这玩意，你得指定它备份的项目名字，路径，用哪个账户验证，指定认证用户的密码文件。 并设置将密码文件权限设置为600，保证只有root用户才能获取它内容。 12345678910111213141516171819202122232425[root@yzy ~]# vim /etc/rsyncd.conf# 2017-03-27 By YYYuid = rootgid = rootuse root = trueuse chroot = no # 限制用户只能在备份目录transfer logging = trueread only = nomax connections = 3600slp refresh = 300hosts allow = 1X0.X6.1X8.XXX # 源服务器IP 只允许源服务器连接host deny = 0.0.0.0/32pid file = /var/run/rsyncd.pidlock file = /var/run/rsyncd.locklog file = /var/log/rsyncd.log##log format = %h %o %f %l %b#[web]path = /www/web # 备份根路径comment = Mirror to web serverlist = falseread only = no # 设置非只读auth users = sync_backup # 指定认证用户secrets file = /etc/rsyncd.secrets # 指定密码文件##exclude from = /etc/rsync/exclude.txt # 排除不做同步的列表 这里注释了 有需要再启用 密码文件 12#vim /etc/rsyncd.secretssync_backup:用户密码 1chmod 600 /etc/rsyncd.secrets 启动rsync的守护进程并设置开机启动 尽量用vim改 别echo 误操作一次就坑爹了，别问我为什么特别注明这个 123#/usr/bin/rsync --deamon#vim /etc/rc.local/usr/bin/rsync --deamon 配置源服务器为什么是先配置备份服务器的rsync,这样可以到源服务器，先尝试先同步看看备份服务器看看是否能正确同步。 这样利于一步一步排错。 1sudo #rsync -avzP /测试同步的目录/ --password-file=/etc/rsyncd.secrets sync_backup@备份服务IP::web/ /etc/rsyncd.secrets 格式 密码，直接就是密码。 我这里测试没问题，就接着部署了sersync 部署sersync 下载安装 sersync 由于上Google Code要翻墙，我从GitHub下载了一份。 1wget --no-check-certificate https://raw.githubusercontent.com/orangle/sersync/master/release/sersync2.5.4_64bit_binary_stable_final.tar.gz Google Code sersync项目地址 sersync项目GitHub镜像 下载项目、解压、移动去 /usr/local/sersync/ 123wget --no-check-certificate https://raw.githubusercontent.com/orangle/sersync/master/release/sersync2.5.4_64bit_binary_stable_final.tar.gztar zxvf sersync2.5.4_64bit_binary_stable_final.tar.gzsudo mv GNU-Linux-x86/ /usr/local/sersync/ 配置sersync 关键的配置我都已经注释了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;?xml version="1.0" encoding="ISO-8859-1"?&gt;&lt;head version="2.5"&gt; &lt;host hostip="localhost" port="8008"&gt;&lt;/host&gt; &lt;debug start="false"/&gt; &lt;fileSystem xfs="false"/&gt; &lt;filter start="true"&gt; # 开启文件过滤 &lt;exclude expression="(.*)\.svn"&gt;&lt;/exclude&gt; # 过滤内容 有些敏感文件不同步 &lt;exclude expression="(.*)\.gz"&gt;&lt;/exclude&gt; &lt;!--exclude expression="^info/*"&gt;&lt;/exclude--&gt; &lt;!--exclude expression="^static/*"&gt;&lt;/exclude--&gt; &lt;/filter&gt; &lt;inotify&gt; # 监控哪些事件 默认就好 &lt;delete start="true"/&gt; &lt;createFolder start="true"/&gt; &lt;createFile start="false"/&gt; &lt;closeWrite start="true"/&gt; &lt;moveFrom start="true"/&gt; &lt;moveTo start="true"/&gt; &lt;attrib start="false"/&gt; &lt;modify start="false"/&gt; &lt;/inotify&gt; &lt;sersync&gt; &lt;localpath watch="/www/web/shixin_dev_sync_test"&gt; # 需要同步的目录 &lt;remote ip="123.184.19.202" name="web"/&gt; # 备份服务器信息 &lt;!--&lt;remote ip="192.168.8.39" name="tongbu"/&gt;--&gt; &lt;!--&lt;remote ip="192.168.8.40" name="tongbu"/&gt;--&gt; &lt;/localpath&gt; &lt;rsync&gt; &lt;commonParams params="-artuz"/&gt; # rsync 参数 &lt;auth start="true" users="sync_backup" passwordfile="/etc/rsyncd.secrets"/&gt; # 备份服务器账户信息 记得 开启 true &lt;userDefinedPort start="false" port="874"/&gt;&lt;!-- port=874 --&gt; 备份的默认端口 &lt;timeout start="false" time="100"/&gt;&lt;!-- timeout=100 --&gt; &lt;ssh start="false"/&gt; &lt;/rsync&gt; &lt;failLog path="/tmp/rsync_fail_log.sh" timeToExecute="60"/&gt;&lt;!--default every 60mins execute once--&gt; &lt;crontab start="false" schedule="600"&gt;&lt;!--600mins--&gt; &lt;crontabfilter start="false"&gt; &lt;exclude expression="*.php"&gt;&lt;/exclude&gt; &lt;exclude expression="info/*"&gt;&lt;/exclude&gt; &lt;/crontabfilter&gt; &lt;/crontab&gt; &lt;plugin start="false" name="command"/&gt; &lt;/sersync&gt; &lt;plugin name="command"&gt; &lt;param prefix="/bin/sh" suffix="" ignoreError="true"/&gt; &lt;!--prefix /opt/tongbu/mmm.sh suffix--&gt; &lt;filter start="false"&gt; &lt;include expression="(.*)\.php"/&gt; &lt;include expression="(.*)\.sh"/&gt; &lt;/filter&gt; &lt;/plugin&gt; &lt;plugin name="socket"&gt; &lt;localpath watch="/opt/tongbu"&gt; &lt;deshost ip="192.168.138.20" port="8009"/&gt; &lt;/localpath&gt; &lt;/plugin&gt; &lt;plugin name="refreshCDN"&gt; &lt;localpath watch="/data0/htdocs/cms.xoyo.com/site/"&gt; &lt;cdninfo domainname="ccms.chinacache.com" port="80" username="xxxx" passwd="xxxx"/&gt; &lt;sendurl base="http://pic.xoyo.com/cms"/&gt; &lt;regexurl regex="false" match="cms.xoyo.com/site([/a-zA-Z0-9]*).xoyo.com/images"/&gt; &lt;/localpath&gt; &lt;/plugin&gt;&lt;/head&gt; 启动并设置开机启动 123sudo /usr/local/sersync/sersync2 -r -d -o /usr/local/sersync/confxml.xml # 启动守护进程vim /etc/rc.local/usr/local/sersync/sersync2 -r -d -o /usr/local/sersync/confxml.xml 参考资料 sersync+rsync原理及部署 sersync github镜像 二进制包 CentOs 6.4 rsync+sersync安装配置及调试笔记]]></content>
      <categories>
        <category>operations</category>
      </categories>
      <tags>
        <tag>opslog</tag>
        <tag>rsync</tag>
        <tag>rersync</tag>
        <tag>inotify-tools</tag>
        <tag>backup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7安装Scrapy和一些爬虫会用到的服务]]></title>
    <url>%2Farticle%2F20170308%2Fcentos7-install-scrapy%2F</url>
    <content type="text"><![CDATA[讯云这几天搞活动，免费领了三个月的免费VPS。所以想把本地虚拟机的scrapy爬虫迁移上去。 Scrapy是基于Python写的。本来是要安装Python的，但是现在Linux基本都默认安装到Python了，所以这步略过。 我本地是Ubuntu，服务器我装了CentOS7.2。别问我为啥不用Debian，我瞎选的，没啥特别理由。 自己私人使用，为了方便，直接是root开干。 安装pip包管理 1yum install -y python-pip 配置pip安装源为阿里云 http://mirrors.aliyun.com/help/pypi。 我觉得这是天朝必备的一个步骤，否则安装软件那龟速不忍直视。123456789mkdir ~/.pipvim ~/.pip/pip.conf# 改为如下内容[global]index-url = http://mirrors.aliyun.com/pypi/simple/[install]trusted-host=mirrors.aliyun.com 3, 安装编译器和开发库之类的，假如你们也没安装的话 1yum -y install gcc gcc-c++ kernel-devel python-devel libxslt-devel libffi-devel openssl-devel 安装主角Scrapy 1pip install scrapy 安装MySQL-python Python连接MySQL的模块 1easy_install MySQL-python 如果遇到mysql_config not found之前的博文有提过这个错误，不过是在Ubuntu下的解决方案-安装libmysqlclient-dev然而在CentOS的源中并没有这个包。而安装mysql-devel即可。 1yum install -y mysql-devel 安装MySQL数据库 yum groupinstall mariadb mariadb-client MariaDB其实可以看做MySQL新版吧，具体缘由自行百度。 安装redisNoSQL数据库会用到配合bloomfilter做url去重。 1yum install -y redis 安装 BloomFilter 模块 1pip install bloomfilter 至此就差不多了，目前我就用到这些，另外requests和beautifulsoup4模块也装一下。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python从零写一个采集器:入库MySQL]]></title>
    <url>%2Farticle%2F20170220%2Fpython-mysql-rw%2F</url>
    <content type="text"><![CDATA[采集到的数据，总归是要保存起来，保存到文件，或者数据库，方便以后取用。 思前想后，还是决定采用MySQL数据库，新版本叫MariaDB了，不过都是通用的。 安装MySQL-python模块1sudo easy_install MySQL-python Issue:安装MySQL-Python出错mysql_config not found 插入数据我这里MySQL位于我虚拟机172.25.254.18，数据库名yzy_data,用户名yzy_data，密码pass 我新建了一个表用于保存标题、用户ID、网盘URL表结构如下 123456789101112CREATE TABLE `test` ( `id` int(11) NOT NULL, `title` varchar(255) NOT NULL, `uid` varchar(30) NOT NULL, `purl` varchar(255) NOT NULL) ENGINE=MyISAM DEFAULT CHARSET=utf8mb4;ALTER TABLE `test` ADD PRIMARY KEY (`id`);ALTER TABLE `test` MODIFY `id` int(11) NOT NULL AUTO_INCREMENT; 新增了一个ID的字段，方便索引数据，这个字段我设置是自增的，所以平时插入数据留空即可。 插入一条数据，标题：测试插入、用户ID：123321、网盘URL：http://pan.baidu.com/xxx 代码如下 1234567891011121314# 导入mysql库import MySQLdb#连接数据库 指定编码utf8conn = MySQLdb.connect(host=&quot;172.25.254.18&quot;,user=&quot;yzy_data&quot;,passwd=&quot;pass&quot;,db=&quot;yzy_data&quot;,charset=&quot;utf8&quot;)cursor = conn.cursor()# 执行插入数据sql = &quot;insert into `test`(title,uid,purl) values(%s,%s,%s)&quot;param = (&quot;测试插入&quot;,&quot;123321&quot;,&quot;http://pan.baidu.com/xxx&quot;)n = cursor.execute(sql,param)print &quot;insert&quot;,ncursor.close() 我这里是用的是MyISAM表引擎，所以并不需要插入后conn.commit()来提交才能插入数据。像Innodb这类支持事务的表都需要。 参考资料 python下的MySQLdb使用]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LANMP环境一键部署工具]]></title>
    <url>%2Farticle%2F20170218%2Fresources-lanmp-tools%2F</url>
    <content type="text"><![CDATA[部署Linux+Apache+nginx+MySQL+phpmyadmin。平时部署还是略显麻烦，尤其用于非生产环境的话，感觉好浪费体力。之前也一直想写个类似的脚本，一直懒得真正动手付诸实践。偶然遇见这个工具，感觉好方便。能满足需要。 https://lnmp.org/]]></content>
      <categories>
        <category>resources</category>
      </categories>
      <tags>
        <tag>resources</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装MySQL-Python出错mysql_config not found]]></title>
    <url>%2Farticle%2F20170218%2Fissue-mysql-python-mysql-config-not-found%2F</url>
    <content type="text"><![CDATA[用python需要用到mysql，遂想安装一个MySQL-Python.但是遇到如下错误：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061➜ ~ git:(master) ✗ sudo easy_install MySQL-python[sudo] password for phan: Searching for MySQL-pythonReading https://pypi.python.org/simple/MySQL-python/Best match: MySQL-python 1.2.5Downloading https://pypi.python.org/packages/a5/e9/51b544da85a36a68debe7a7091f068d802fc515a3a202652828c73453cad/MySQL-python-1.2.5.zip#md5=654f75b302db6ed8dc5a898c625e030cProcessing MySQL-python-1.2.5.zipWriting /tmp/easy_install-oRVY0O/MySQL-python-1.2.5/setup.cfgRunning MySQL-python-1.2.5/setup.py -q bdist_egg --dist-dir /tmp/easy_install-oRVY0O/MySQL-python-1.2.5/egg-dist-tmp-tj3z87sh: 1: mysql_config: not foundTraceback (most recent call last): File &quot;/usr/bin/easy_install&quot;, line 9, in &lt;module&gt; load_entry_point(&apos;setuptools==20.7.0&apos;, &apos;console_scripts&apos;, &apos;easy_install&apos;)() File &quot;/usr/lib/python2.7/dist-packages/setuptools/command/easy_install.py&quot;, line 2293, in main distclass=DistributionWithoutHelpCommands, **kw File &quot;/usr/lib/python2.7/distutils/core.py&quot;, line 151, in setup dist.run_commands() File &quot;/usr/lib/python2.7/distutils/dist.py&quot;, line 953, in run_commands self.run_command(cmd) File &quot;/usr/lib/python2.7/distutils/dist.py&quot;, line 972, in run_command cmd_obj.run() File &quot;/usr/lib/python2.7/dist-packages/setuptools/command/easy_install.py&quot;, line 414, in run self.easy_install(spec, not self.no_deps) File &quot;/usr/lib/python2.7/dist-packages/setuptools/command/easy_install.py&quot;, line 663, in easy_install return self.install_item(spec, dist.location, tmpdir, deps) File &quot;/usr/lib/python2.7/dist-packages/setuptools/command/easy_install.py&quot;, line 693, in install_item dists = self.install_eggs(spec, download, tmpdir) File &quot;/usr/lib/python2.7/dist-packages/setuptools/command/easy_install.py&quot;, line 873, in install_eggs return self.build_and_install(setup_script, setup_base) File &quot;/usr/lib/python2.7/dist-packages/setuptools/command/easy_install.py&quot;, line 1101, in build_and_install self.run_setup(setup_script, setup_base, args) File &quot;/usr/lib/python2.7/dist-packages/setuptools/command/easy_install.py&quot;, line 1087, in run_setup run_setup(setup_script, args) File &quot;/usr/lib/python2.7/dist-packages/setuptools/sandbox.py&quot;, line 246, in run_setup raise File &quot;/usr/lib/python2.7/contextlib.py&quot;, line 35, in __exit__ self.gen.throw(type, value, traceback) File &quot;/usr/lib/python2.7/dist-packages/setuptools/sandbox.py&quot;, line 195, in setup_context yield File &quot;/usr/lib/python2.7/contextlib.py&quot;, line 35, in __exit__ self.gen.throw(type, value, traceback) File &quot;/usr/lib/python2.7/dist-packages/setuptools/sandbox.py&quot;, line 166, in save_modules saved_exc.resume() File &quot;/usr/lib/python2.7/dist-packages/setuptools/sandbox.py&quot;, line 141, in resume six.reraise(type, exc, self._tb) File &quot;/usr/lib/python2.7/dist-packages/setuptools/sandbox.py&quot;, line 154, in save_modules yield saved File &quot;/usr/lib/python2.7/dist-packages/setuptools/sandbox.py&quot;, line 195, in setup_context yield File &quot;/usr/lib/python2.7/dist-packages/setuptools/sandbox.py&quot;, line 243, in run_setup DirectorySandbox(setup_dir).run(runner) File &quot;/usr/lib/python2.7/dist-packages/setuptools/sandbox.py&quot;, line 273, in run return func() File &quot;/usr/lib/python2.7/dist-packages/setuptools/sandbox.py&quot;, line 242, in runner _execfile(setup_script, ns) File &quot;/usr/lib/python2.7/dist-packages/setuptools/sandbox.py&quot;, line 46, in _execfile exec(code, globals, locals) File &quot;/tmp/easy_install-oRVY0O/MySQL-python-1.2.5/setup.py&quot;, line 17, in &lt;module&gt; File &quot;/tmp/easy_install-oRVY0O/MySQL-python-1.2.5/setup_posix.py&quot;, line 43, in get_config File &quot;/tmp/easy_install-oRVY0O/MySQL-python-1.2.5/setup_posix.py&quot;, line 25, in mysql_configEnvironmentError: mysql_config not found 度娘后，安装了libmysqlclient-dev解决 1➜ ~ git:(master) ✗ sudo apt-get install libmysqlclient-dev 安装MySQL-python搞定123456789101112131415➜ ~ git:(master) ✗ sudo easy_install MySQL-python Searching for MySQL-pythonReading https://pypi.python.org/simple/MySQL-python/Best match: MySQL-python 1.2.5Downloading https://pypi.python.org/packages/a5/e9/51b544da85a36a68debe7a7091f068d802fc515a3a202652828c73453cad/MySQL-python-1.2.5.zip#md5=654f75b302db6ed8dc5a898c625e030cProcessing MySQL-python-1.2.5.zipWriting /tmp/easy_install-RxRikL/MySQL-python-1.2.5/setup.cfgRunning MySQL-python-1.2.5/setup.py -q bdist_egg --dist-dir /tmp/easy_install-RxRikL/MySQL-python-1.2.5/egg-dist-tmp-oH_bfizip_safe flag not set; analyzing archive contents...Moving MySQL_python-1.2.5-py2.7-linux-x86_64.egg to /usr/local/lib/python2.7/dist-packagesAdding MySQL-python 1.2.5 to easy-install.pth fileInstalled /usr/local/lib/python2.7/dist-packages/MySQL_python-1.2.5-py2.7-linux-x86_64.eggProcessing dependencies for MySQL-pythonFinished processing dependencies for MySQL-python]]></content>
      <categories>
        <category>troubleshooting</category>
      </categories>
      <tags>
        <tag>issue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python从零写一个采集器:获取网页信息]]></title>
    <url>%2Farticle%2F20170216%2Fpython-extarct-html-info%2F</url>
    <content type="text"><![CDATA[前言 获取内容，比较纠结是用BeautifulSoup还是直接用正则匹配好。BeautifulSoup简单清晰，但是不够灵活。正则则相反。 正文信息位置的分析像网盘，我们要提取的信息主要有共享者ID、资源名、网盘URL、资源大小、创建时间等等。搞清楚这些信息的位置，不是本文的重点，所以这里假设已经清楚了信息的位置，然后提取就行了。用共享者ID、资源名、网盘URL做个示范。 举个栗子，比如莽荒纪.zip的资源，URL是：http://www.sobaidupan.com/file-106010793.html从HTML中我们可以获得如下信息: 资源名：莽荒纪.zip 共享者ID： http://www.sobaidupan.com/user-2082813876-1.html 网盘URL： http://sbdp.baidudaquan.com/down.asp?id=106010793&amp;token=c4e0d8de4bf94fe0d86a6b4f675fe176 而 2082813876是sobaidupan.com的站内ID，也是百度云盘的用户ID。这就好办了。但是资源的URL还要进一步加载http://sbdp.baidudaquan.com/down.asp?id=16166237&amp;token=301efbbe2c138d150b41b5813a3d4077才能知道。源码如下：123&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=utf-8&quot; /&gt;&lt;div style=&quot;margin:0 auto;margin-top:10%;width:600px;border: 1px solid #ff0000;line-height:30px;padding:10px 10px 10px 10px; &quot;&gt;提示:亲,正在为您跳转,请稍等2秒..... &lt;meta http-equiv=&apos;refresh&apos; content=&apos;2;URL=http://pan.baidu.com/share/link?shareid=3994307345&amp;uk=2755655514&amp;fid=45639734040097&apos;&gt;&lt;/div&gt; 源码里的http://pan.baidu.com/share/link?shareid=3994307345&amp;uk=2755655514&amp;fid=45639734040097正是我们要的资源。 也就是说，要提取莽荒纪的资源名称，至少得加载两次URL，才能将信息提取全。 第一次加载：http://www.sobaidupan.com/user-2082813876-1.html得到资源名、共享者ID和网盘的站内地址http://sbdp.baidudaquan.com/down.asp?id=106010793&amp;token=c4e0d8de4bf94fe0d86a6b4f675fe176 第二次加载： http://sbdp.baidudaquan.com/down.asp?id=106010793&amp;token=c4e0d8de4bf94fe0d86a6b4f675fe176提取出网盘的真实地址。 提取信息获取网站源码上一篇日志提到如何提取源码。我把它放到一个叫yzyPublic.py文件里。所以等下得先导入这个文件再使用。 1234import yzyPublicres = yzyPublic.get_web_source(&apos;http://www.sobaidupan.com/file-106010793.html&apos;)print res res内容如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272&lt;!DOCTYPE html&gt;&lt;html xmlns=http://www.w3.org/1999/xhtml&gt;&lt;head&gt;&lt;meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"&gt;&lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8" /&gt;&lt;link rel="stylesheet" type="text/css" href="style.css" /&gt;&lt;title&gt;莽荒纪.zip_zgh*****1617_百度云盘下载 - 搜百度盘&lt;/title&gt;&lt;meta name="keywords" content="莽荒纪.zip" /&gt;&lt;meta name="description" content="小说/修真/莽荒纪.zip" /&gt;&lt;style type="text/css"&gt;&lt;!--.f_color &#123; color: #FFFFFF; font-weight: bold;&#125;--&gt; &lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="headtop"&gt; &lt;div class="headtop_f"&gt;&lt;B&gt;搜百度盘（SoBaiduPan.com）&lt;/B&gt;&amp;nbsp;是基于百度云搜索，最大的百度云盘资源搜索中心，千万级大数据量，让您一网打尽所有的百度网盘资源.&lt;/div&gt; &lt;/div&gt;&lt;div class="site_head w c"&gt; &lt;div class="sitelogo"&gt;&lt;a href="/"&gt;&lt;img src="image/logo.gif" border="0" title="SoBaiduPan.com"&gt;&lt;/a&gt;&lt;/div&gt; &lt;div class="top_allsite" id="top_allsite"&gt;&lt;ul&gt; &lt;script type="text/javascript" src="top_txtad.asp"&gt;&lt;/script&gt; &lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="menu w c"&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="http://www.sobaidupan.com"&gt;首 页&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="list-1-1.html"&gt;最新资源&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="zhuan-1-1.html"&gt;影视目录&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="zhuan-2-1.html"&gt;小说目录&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="list-28-1.html"&gt;影视资源&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="list-30-1.html"&gt;动漫资源&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="list-29-1.html"&gt;小说资源&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="zhuan-3-1.html"&gt;综合资源&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="http://soft.sobaidupan.com" target="_blank" title="百度云下载器"&gt;云下载器&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="m.asp" title="移动端访问"&gt;手机专版&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="http://weipan.sobaidupan.com" title="新浪微盘资源搜索" target="_blank"&gt;新浪微盘&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="about.asp?id=2" title="在线发布共享资源"&gt;发布资源&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="http://bbs.sobaidupan.com" title="建议留言" target="_blank"&gt;&lt;font color="#FFFF00"&gt;建议留言&lt;/font&gt;&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;/div&gt;&lt;div class="smenu c"&gt; &lt;div class="smenu_nav"&gt; &lt;a href="list-3-1.html"&gt;torrent&lt;/a&gt;&lt;a href="list-5-1.html"&gt;rmvb&lt;/a&gt;&lt;a href="list-4-1.html"&gt;mp4&lt;/a&gt;&lt;a href="list-7-1.html"&gt;mp3&lt;/a&gt;&lt;a href="list-9-1.html"&gt;avi&lt;/a&gt;&lt;a href="list-8-1.html"&gt;epub&lt;/a&gt;&lt;a href="list-10-1.html"&gt;mkv&lt;/a&gt;&lt;a href="list-11-1.html"&gt;flv&lt;/a&gt;&lt;a href="list-12-1.html"&gt;pdf&lt;/a&gt;&lt;a href="list-13-1.html"&gt;pps&lt;/a&gt;&lt;a href="list-15-1.html"&gt;psd&lt;/a&gt;&lt;a href="list-16-1.html"&gt;iso&lt;/a&gt;&lt;a href="list-17-1.html"&gt;ghost&lt;/a&gt;&lt;a href="list-19-1.html"&gt;exe&lt;/a&gt;&lt;a href="list-20-1.html"&gt;txt&lt;/a&gt;&lt;a href="list-21-1.html"&gt;apk&lt;/a&gt;&lt;a href="list-22-1.html"&gt;ipa&lt;/a&gt;&lt;a href="list-24-1.html"&gt;wps&lt;/a&gt;&lt;a href="list-25-1.html"&gt;rtf&lt;/a&gt;&lt;a href="list-26-1.html"&gt;vob&lt;/a&gt;&lt;a href="list-13-1.html"&gt;ppt/pptx&lt;/a&gt;&lt;a href="list-27-1.html"&gt;xls/xlsx&lt;/a&gt;&lt;a href="list-14-1.html"&gt;doc/docx&lt;/a&gt;&lt;a href="list-18-1.html"&gt;rar/zip&lt;/a&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="search w c"&gt;&lt;table width="100%" height="90" border="0" align="center" cellpadding="0" cellspacing="1"&gt; &lt;tr&gt; &lt;td&gt; &lt;script type="text/javascript" src="ad/top1_580x90.js"&gt;&lt;/script&gt; &lt;/td&gt; &lt;td&gt; &lt;a href="adgo.asp?id=30" target="_blank"&gt;&lt;img src="ad/ad2.jpg"&gt;&lt;/a&gt; &lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;div class="fgx"&gt;&lt;/div&gt; &lt;form id="form1" name="form1" method="get" action="search.asp" &gt;&lt;img src="image/s.png" width="32" height="32" align="absmiddle"&gt;&amp;nbsp;请您输入搜索内容： &lt;input name="wd" id="wd" placeholder="共108,789,857个资源，今日已更新2382..." type="text" size="30" value="" autocomplete="off" /&gt; &lt;input type="submit" id="Su" tabindex="2" value="网盘搜索" style="cursor:hand;"&gt;&amp;nbsp;&lt;img src="image/soso.gif" width="23" height="21" align="absmiddle"&gt;&lt;a href="about.asp?id=1" target="_blank"&gt;&lt;font color="red"&gt;&lt;b&gt;点击打赏本站&lt;/b&gt;&lt;/font&gt;&amp;nbsp;&amp;nbsp;&lt;a href="http://koubei.baidu.com/s/www.sobaidupan.com" target="_blank"&gt;&lt;b&gt;点击支持本站&lt;/b&gt;&lt;/a&gt;&amp;nbsp;&lt;img src="image/new.gif" width="22" height="14" align="absmiddle"&gt;&amp;nbsp;&lt;a href="http://soft.sobaidupan.com" target="_blank"&gt;&lt;font color="red"&gt;&lt;b&gt;百度云搜索器&lt;/b&gt;&lt;/font&gt;&lt;/a&gt; &lt;/form&gt;&lt;/div&gt;&lt;script type="text/javascript" charset="gbk" src="opensug.js"&gt;&lt;/script&gt;&lt;script type="text/javascript"&gt;var txtObj = document.getElementById("alertSpan");function show(str)&#123;window.location.href="search.asp?r=0&amp;wd="+encodeURIComponent(str);&#125;var params = &#123;"XOffset":0,"YOffset":0,"width":204,"fontColor":"#f70","fontColorHI":"#FFF","fontSize":"15px","fontFamily":"宋体","borderColor":"gray","bgcolorHI":"#03c","sugSubmit":false&#125;;BaiduSuggestion.bind("wd",params,show);&lt;/script&gt; &lt;div class="main w c"&gt; &lt;div class="art_bt_box w c"&gt;&lt;ul&gt;&lt;li&gt;&lt;h1&gt;莽荒纪.zip&lt;/h1&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt; &lt;div class="art_box"&gt; &lt;table border="0"&gt; &lt;tr&gt; &lt;td width="250" valign="top" &gt;&lt;table width="250" border="0" cellpadding="0" cellspacing="1" bordercolor="#3E92CF" bgcolor="#3E92CF"&gt; &lt;tr&gt; &lt;td width="250" height="119" bgcolor="#FFFFFF" &gt;&lt;div align="center"&gt;&lt;a href="user-2082813876-1.html"&gt;&lt;img src="http://himg.bdimg.com/sys/portrait/item/797c6b21.jpg" width="100" height="100" border="0"&gt;&lt;/a&gt;&lt;/div&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td height="40" bgcolor="#FFFFFF" &gt;&lt;div align="center"&gt;用户名：zgh*****1617&lt;/div&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td height="40" bgcolor="#FFFFFF" &gt;&lt;div align="center"&gt;&lt;a href="user-2082813876-1.html"&gt;&lt;img src="image/jrzy.gif" width="89" height="24" border="0"&gt;&lt;/a&gt;&lt;/div&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td bgcolor="#FFFFFF" &gt; &lt;script src="ad/250x250.js" type="text/javascript"&gt;&lt;/script&gt;&lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td height="35" bgcolor="#3E92CF" &gt;&amp;nbsp;&lt;span class="f_color"&gt;Ta 分享的其它资源：&lt;/span&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td height="40" bgcolor="#FFFFFF"&gt; &lt;ul&gt; &lt;li&gt;&amp;nbsp;&lt;a href="file-1266183.html" title=网游——屠龙巫师.zip&gt;网游——屠龙巫师.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-1266216.html" title=网游-梦幻现实.zip&gt;网游-梦幻现实.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-1266234.html" title=神也玩转网游.zip&gt;神也玩转网游.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-1668670.html" title=魔兽英雄.zip&gt;魔兽英雄.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-1668832.html" title=阿亚罗克年代记.zip&gt;阿亚罗克年代记.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-1668883.html" title=重生之福星道士.zip&gt;重生之福星道士.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-1668930.html" title=重生之极限风流.zip&gt;重生之极限风流.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-1669255.html" title=英雄无敌之大航海时代.zip&gt;英雄无敌之大航海时代.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-1674467.html" title=网游之霸世神偷.zip&gt;网游之霸世神偷.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-2013963.html" title=霸王怒.zip&gt;霸王怒.zip&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td bgcolor="#FFFFFF" &gt; &lt;script src="ad/250x250-2.js" type="text/javascript"&gt;&lt;/script&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td height="35" bgcolor="#3E92CF" &gt;&amp;nbsp;&lt;span class="f_color"&gt;其它网友正在下载的资源：&lt;/span&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td bgcolor="#FFFFFF" &gt; &lt;ul&gt; &lt;li&gt;&amp;nbsp;&lt;a href="file-830.html" title=橄榄油 - 副本5.psd&gt;橄榄油 - 副本5.psd&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-829.html" title=百度云管家 v4.8.0 绿色版 i2i2.cn.rar&gt;百度云管家 v4.8.0 绿色版 i2i2.cn.rar&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-828.html" title=百度云管家 v4.8.0 单文件版 i2i2.cn.rar&gt;百度云管家 v4.8.0 单文件版 i2i2.cn.rar&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-827.html" title=第1天上午.5.mp3&gt;第1天上午.5.mp3&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-826.html" title=第2天下午.8.mp3&gt;第2天下午.8.mp3&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-825.html" title=第2天上午.7.mp3&gt;第2天上午.7.mp3&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-824.html" title=第1天下午.5.mp3&gt;第1天下午.5.mp3&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-823.html" title=第1天上午.4.mp3&gt;第1天上午.4.mp3&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-822.html" title=第2天下午.6.mp3&gt;第2天下午.6.mp3&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-821.html" title=第1天下午.7.mp3&gt;第1天下午.7.mp3&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/td&gt; &lt;td height="61" align="left" valign="top" &gt; &lt;table width="100%" border="0" align="left" cellpadding="0" cellspacing="0" bordercolor="#3E92CF" bgcolor="#3E92CF"&gt; &lt;tr&gt; &lt;td bgcolor="#FFFFFF" &gt; &lt;script type='text/javascript' src='http://m1.sobaidupan.com/fr3a1ec292ffc2f63fdb146392acb024e057e3d4002ef230ec51322bda.js'&gt;&lt;/script&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td bgcolor="#FFFFFF" &gt;&lt;div class="fgx"&gt;&lt;/div&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td style="line-height: 30px" bgcolor="#FFFFFF" &gt;&lt;div align="left"&gt;&amp;nbsp;&lt;B&gt;资源名称：&lt;/B&gt;莽荒纪.zip&lt;/div&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td style="line-height: 30px" bgcolor="#FFFFFF" &gt;&lt;div align="left"&gt;&amp;nbsp;&lt;B&gt;资源类别：&lt;/B&gt;小说/修真&lt;/div&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td style="line-height: 30px" bgcolor="#FFFFFF" &gt;&lt;div align="left"&gt;&amp;nbsp;&lt;B&gt;资源大小：&lt;/B&gt;3.83 MB&amp;nbsp;&lt;b&gt;资料扩展名：&lt;/b&gt;.zip&amp;nbsp;&lt;b&gt;访问/下载次数&lt;/b&gt;：10/9&amp;nbsp;&lt;b&gt;分享日期：&lt;/b&gt;2016/9/5 11:13:00&lt;/div&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td bgcolor="#FFFFFF" &gt;&lt;div class="fgx"&gt;&lt;/div&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td bgcolor="#FFFFFF" &gt; &lt;table width="100%" border="0" align="left"&gt; &lt;tr&gt; &lt;td width="155"&gt; &lt;div align="center"&gt; &lt;a href="http://sbdp.baidudaquan.com/down.asp?id=106010793&amp;token=c4e0d8de4bf94fe0d86a6b4f675fe176" title="莽荒纪.zip -百度网盘下载" target="_blank"&gt;&lt;img src="image/wpdown.gif" width="137" height="34" border="0"&gt;&lt;/a&gt;&lt;/div&gt;&lt;/td&gt; &lt;td width="152" bgcolor="#FFFFFF" &gt;&lt;div align="center"&gt;&lt;a href="#" onclick="javascript:alert('违法信息举报信箱：sobaidupan@126.com')"&gt;&lt;img src="image/zaixjb.gif" width="137" height="34" border="0" title="举报资源" style="cursor:pointer" id="police" &gt;&lt;/a&gt;&lt;/div&gt;&lt;/td&gt; &lt;td width="497" bgcolor="#FFFFFF" &gt; &lt;div class="bdsharebuttonbox"&gt;&lt;a href="#" class="bds_more" data-cmd="more"&gt;分享到：&lt;/a&gt;&lt;a href="#" class="bds_qzone" data-cmd="qzone" title="分享到QQ空间"&gt;QQ空间&lt;/a&gt;&lt;a href="#" class="bds_tieba" data-cmd="tieba" title="分享到百度贴吧"&gt;百度贴吧&lt;/a&gt;&lt;a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信"&gt;微信&lt;/a&gt;&lt;a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"&gt;新浪微博&lt;/a&gt;&lt;a href="#" class="bds_douban" data-cmd="douban" title="分享到豆瓣网"&gt;豆瓣网&lt;/a&gt;&lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td bgcolor="#FFFFFF" &gt;&lt;div class="fgx"&gt;&lt;/div&gt; &lt;script src="ad/728x90_2.js" type="text/javascript"&gt;&lt;/script&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td bgcolor="#FFFFFF" &gt; &lt;div id="hm_t_97521"&gt;&lt;/div&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td bgcolor="#FFFFFF" &gt;&lt;div class="fgx"&gt;&lt;/div&gt;&lt;div align="left"&gt; &lt;script src="ad/336x280.js" type="text/javascript"&gt;&lt;/script&gt; &lt;/div&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td height="35" bgcolor="#3E92CF" &gt;&amp;nbsp;&lt;span class="f_color"&gt;相关资源：&lt;/span&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td height="40" bgcolor="#FFFFFF" &gt; &lt;ul&gt; &lt;li&gt;&amp;nbsp;&lt;a href="file-12334474.html" title=仙符问道.zip&gt;仙符问道.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-12335167.html" title=随身副本闯仙界.zip&gt;随身副本闯仙界.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-12335453.html" title=齐宇问道.zip&gt;齐宇问道.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-12335876.html" title=猫行天下.zip&gt;猫行天下.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-12336124.html" title=极品修真邪少.zip&gt;极品修真邪少.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-12424570.html" title=极品丹师.zip&gt;极品丹师.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-12744895.html" title=重生之唯我独仙.zip&gt;重生之唯我独仙.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-14281154.html" title=仙缘五行.zip&gt;仙缘五行.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-15903276.html" title=与狐仙双修的日子.zip&gt;与狐仙双修的日子.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-15903375.html" title=修真之位面交易系统.zip&gt;修真之位面交易系统.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-15903925.html" title=拜师八戒.zip&gt;拜师八戒.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-15904006.html" title=重生在白蛇的世界里.zip&gt;重生在白蛇的世界里.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-15904154.html" title=巫也是道.zip&gt;巫也是道.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-15979622.html" title=僵尸问道.zip&gt;僵尸问道.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-16005591.html" title=大地之皇.zip&gt;大地之皇.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-16484435.html" title=猪八戒重生记.zip&gt;猪八戒重生记.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-16484613.html" title=至神传说.zip&gt;至神传说.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-16484713.html" title=星空战神.zip&gt;星空战神.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-16484798.html" title=现代封神榜.zip&gt;现代封神榜.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-16735997.html" title=仙侠世界之天才掌门.zip&gt;仙侠世界之天才掌门.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-16888626.html" title=物理高材修仙记.zip&gt;物理高材修仙记.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-16889125.html" title=灵枢.zip&gt;灵枢.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-17136845.html" title=极品仙君.zip&gt;极品仙君.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-17175592.html" title=将修仙进行到底.zip&gt;将修仙进行到底.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-17175765.html" title=合成修仙传.zip&gt;合成修仙传.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-17257619.html" title=我做许仙的日子.zip&gt;我做许仙的日子.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-17349180.html" title=少年武仙在都市.zip&gt;少年武仙在都市.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-17349336.html" title=超级修仙之旅.zip&gt;超级修仙之旅.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-17349557.html" title=娇美仙妻爱上我.zip&gt;娇美仙妻爱上我.zip&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-18057326.html" title=极品仙商.zip&gt;极品仙商.zip&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td bgcolor="#FFFFFF" &gt; &lt;div class="fgx"&gt;&lt;/div&gt; &lt;!-- UJian Button BEGIN --&gt;&lt;div class="ujian-hook"&gt;&lt;/div&gt;&lt;script type="text/javascript"&gt;var ujian_config = &#123;num:16,target:1,picSize:72,textHeight:45,hoverTextColor:'#FA1B02'&#125;;&lt;/script&gt;&lt;script type="text/javascript" src="http://v1.ujian.cc/code/ujian.js?uid=2087333"&gt;&lt;/script&gt;&lt;a href="http://www.ujian.cc" style="border:0;"&gt;&lt;img src="http://img.ujian.cc/pixel.png" alt="友荐云推荐" style="border:0;padding:0;margin:0;" /&gt;&lt;/a&gt;&lt;!-- UJian Button END --&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td bgcolor="#FFFFFF" &gt; &lt;div class="fgx"&gt;&lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td height="40" bgcolor="#3E92CF" &gt;&amp;nbsp;&lt;span class="f_color"&gt;相关说明：&lt;/span&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td height="40" bgcolor="#FFFFFF" &gt;&lt;div class="art_foot"&gt;莽荒纪.zip为搜百度盘收集整理的结果，下载地址直接跳转到百度网盘进行下载，该文件的安全性和完整性需要您自行判断。感谢您对本站的支持.&lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td height="80" bgcolor="#FFFFFF" &gt; &amp;nbsp;上一个：&lt;a href="file-106010792.html" title="netplan.zip"&gt;netplan.zip&lt;/a&gt; &lt;div class="fgx"&gt;&lt;/div&gt; &amp;nbsp;下一个：&lt;a href="file-106010794.html" title="斗战西游.zip"&gt;斗战西游.zip&lt;/a&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt;&lt;/td&gt; &lt;td width="200" align="left" valign="top" &gt; &lt;script src="ad/200x200.js" type="text/javascript"&gt;&lt;/script&gt; &lt;div class="art_left_bt"&gt;&lt;img src="image/hot.gif" width="22" height="11"&gt;&amp;nbsp;您可能需要的资源：&lt;/div&gt; &lt;ul&gt; &lt;li&gt;&amp;nbsp;&lt;a href="file-23821718.html" title=重生之婚后试爱.txt&gt;重生之婚后试爱.txt&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-23827473.html" title=时光，浓淡相宜.txt&gt;时光，浓淡相宜.txt&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-25264047.html" title=[书包网]亲爱的爱情（重生演艺圈）.txt&gt;[书包网]亲爱的爱情（重生演艺圈）.txt&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-25650524.html" title=[古装言情]《二货娘子》作者：雾矢翊（晋江VIP2014-03-17完结）金牌高积分.txt&gt;[古装言情]《二货娘子》作者：雾矢翊（晋江VIP2014-03-17完结）金牌高积分.txt&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-25651309.html" title=系统之宠妃.txt&gt;系统之宠妃.txt&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-25651440.html" title=后宫翻身记（重生） .txt&gt;后宫翻身记（重生） .txt&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-29456136.html" title=重生之汤圆儿.txt&gt;重生之汤圆儿.txt&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-29456254.html" title=《重生之换我疼你》作者：森中一小妖.txt&gt;《重生之换我疼你》作者：森中一小妖.txt&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-29717792.html" title=《宠妃》作者：月非娆.txt&gt;《宠妃》作者：月非娆.txt&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&lt;a href="file-30877984.html" title=[网游]舍我娶谁.txt&gt;[网游]舍我娶谁.txt&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;script src="ad/160x600.js" type="text/javascript"&gt;&lt;/script&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt;&lt;/div&gt;&lt;script charset='gbk' src='http://p.tanx.com/ex?i=mm_113468001_12740314_57802967'&gt;&lt;/script&gt;&lt;div class="cl"&gt;&lt;/div&gt;&lt;div class="fgx"&gt;&lt;/div&gt;&lt;div class="foot"&gt; &lt;p&gt;&lt;img src="image/wj.png" width="36" height="43" align="absmiddle"&gt;&amp;nbsp;&amp;nbsp;搜百度盘（&lt;a href="http://www.sobaidupan.com" title="搜百度盘"&gt;www.sobaidupan.com&lt;/a&gt;）&amp;nbsp;2015-2018 All Rights Reserved&amp;nbsp;&lt;a href="zhaoshang.asp" title="广告合作及投放"&gt;广告合作&lt;/a&gt;&amp;nbsp;&lt;a href="about.asp" title="关于本站"&gt;关于本站&lt;/a&gt; &amp;nbsp;QQ群：&lt;a href="http://jq.qq.com/?_wv=1027&amp;k=a2uzxT" target="_blank"&gt;385379281&lt;/a&gt;&lt;/p&gt; &lt;p&gt;本站仅提供百度网盘资源搜索和百度网盘资源下载的网站，本站只抓取百度网盘的链接而不保存任何资源. &lt;script&gt;var _hmt = _hmt || [];(function() &#123; var hm = document.createElement("script"); hm.src = "//hm.baidu.com/hm.js?f9d133598d63eabee77f59430aefa2ab"; var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);&#125;)();&lt;/script&gt;&lt;script type="text/javascript"&gt;var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1254604262'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s11.cnzz.com/stat.php%3Fid%3D1254604262' type='text/javascript'%3E%3C/script%3E"));&lt;/script&gt; &lt;a href="setxml.asp"&gt;sitemap.xml&lt;/a&gt;&lt;/p&gt; &lt;p&gt;本站所有资源均来自互联网，本站只负责技术收集和整理，均不承担任何法律责任，如有侵权违规等其它行为请联系我们. &lt;img src="image/e.jpg" width="163" height="20" align="absmiddle"&gt;&lt;/p&gt;&lt;/div&gt;&lt;br /&gt;&lt;script&gt;window._bd_share_config=&#123;"common":&#123;"bdSnsKey":&#123;&#125;,"bdText":"","bdMini":"2","bdMiniList":["mshare","qzone","tsina","bdysc","weixin","tieba","douban","sqq","qq","hi","baidu","share189","fx","mail","copy"],"bdPic":"","bdStyle":"0","bdSize":"16"&#125;,"share":&#123;"bdSize":16&#125;&#125;;with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;&lt;script src="count.asp?id=106010793" type="text/javascript"&gt;&lt;/script&gt; 提取用户ID、资源名、网盘URL想了良久，还是决定使用BeautifulSoup和re正则共同完成信息的提取。其实我个人是比较倾向于只使用正则提取，在以往我写的其它采集器基本都是用这个完成信息的提取。抱着学习的目的，加入了beautifulsoup。 导入相关的模块: BeautifulSoup和re 12from bs4 import BeautifulSoupimport re 提取标题标题这里都是存在h1标签里面。提取如下： 12soup = BeautifulSoup(res,"html.parser")print soup.h1.text res是前面获取的网页源码’html.parser’解析，可以理解为让BeautifulSoup明白这个页面是什么语言写的。另外还有常用的lxml. 提取UIDuid这里的提取，我用了正则，觉得会简单点。BeautifulSoup的话，我还是会用到正则，后面我把两种方法都贴出来。 方法1 直接正则匹配 12uid = re.search(&apos;user-(\d*)-1\.html&apos;,res)print uid.group(1) 方法2 BeautifulSoup配合正则找出符合的href属性 12uid2 = soup.find(href=re.compile(&apos;user-\d*-1\.html&apos;))[&apos;href&apos;]print uid2.split(&apos;-&apos;)[1] 提取网盘URL这里需要先提取出站内下载的地址，加载源码，再提取出百度网盘地址。文章前面有提到过了。 提取站内下载URL 123rurl = re.search(&apos;href=&quot;(http://sbdp\.baidudaquan\.com/down\.asp\?id=.+?)&quot;&apos;,res)print rurl.group(1) 提取百度网盘地址 123dres = yzyPublic.get_web_source(rurl.group(1))purl = re.search(&quot;URL=(http://pan\.baidu\.com/share/link\?shareid=.+?)&apos;&quot;,dres)print purl.group(1) 封装成函数提高代码复用按自己习惯自己搞。不赘述。 参考资料 Beautiful Soup 4.2.0 文档]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>spider</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python从零写一个采集器:获取网页源码]]></title>
    <url>%2Farticle%2F20170206%2Fpython-get-web-source%2F</url>
    <content type="text"><![CDATA[前言 过完年无聊，想学学Python，想了半天，从实用的角度出发，打算边学边做。想了半天，还是写一个采集器好点。目标嘛，就是采集 www.sobaidupan.com 的内容入库。因为是初学，有很多不懂，所以一切从简，实现目的第一，性能第二。 正文既然要采集，肯定得先获取网页源码。其中使用urllib和requests模块最多。而其中requests模块提供的api来看，友好度最高，所以打算采用requests。但是requests是一个第三方模块。所以 安装requests模块 pip install requests 获取网页源码导入requests模块，调用get的方法。不清楚http的get、post、put、delete等方法的，度娘http协议了解。简单来说，一般获取网页信息，绝大部分都是用的get，而提交信息，基本都是用post。我说是绝大部分。下面就来一段代码演示如何获取www.baidu.com首页的源码。简直好用到哭。 获取源码123import requestsres = requests.get(&apos;http://www.baidu.com&apos;)print res.text 结果如下： 12&lt;!DOCTYPE html&gt;&lt;!--STATUS OK--&gt;&lt;html&gt; &lt;head&gt;&lt;meta http-equiv=content-type content=text/html;charset=utf-8&gt;&lt;meta http-equiv=X-UA-Compatible content=IE=Edge&gt;&lt;meta content=always name=referrer&gt;&lt;link rel=stylesheet type=text/css href=http://s1.bdstatic.com/r/www/cache/bdorz/baidu.min.css&gt;&lt;title&gt;ç¾åº¦ä¸ä¸ï¼ä½ å°±ç¥é&lt;/title&gt;&lt;/head&gt; &lt;body link=#0000cc&gt; &lt;div id=wrapper&gt; &lt;div id=head&gt; &lt;div class=head_wrapper&gt; &lt;div class=s_form&gt; &lt;div class=s_form_wrapper&gt; &lt;div id=lg&gt; &lt;img hidefocus=true src=//www.baidu.com/img/bd_logo1.png width=270 height=129&gt; &lt;/div&gt; &lt;form id=form name=f action=//www.baidu.com/s class=fm&gt; &lt;input type=hidden name=bdorz_come value=1&gt; &lt;input type=hidden name=ie value=utf-8&gt; &lt;input type=hidden name=f value=8&gt; &lt;input type=hidden name=rsv_bp value=1&gt; &lt;input type=hidden name=rsv_idx value=1&gt; &lt;input type=hidden name=tn value=baidu&gt;&lt;span class=&quot;bg s_ipt_wr&quot;&gt;&lt;input id=kw name=wd class=s_ipt value maxlength=255 autocomplete=off autofocus&gt;&lt;/span&gt;&lt;span class=&quot;bg s_btn_wr&quot;&gt;&lt;input type=submit id=su value=ç¾åº¦ä¸ä¸ class=&quot;bg s_btn&quot;&gt;&lt;/span&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=u1&gt; &lt;a href=http://news.baidu.com name=tj_trnews class=mnav&gt;æ°é»&lt;/a&gt; &lt;a href=http://www.hao123.com name=tj_trhao123 class=mnav&gt;hao123&lt;/a&gt; &lt;a href=http://map.baidu.com name=tj_trmap class=mnav&gt;å°å¾&lt;/a&gt; &lt;a href=http://v.baidu.com name=tj_trvideo class=mnav&gt;è§é¢&lt;/a&gt; &lt;a href=http://tieba.baidu.com name=tj_trtieba class=mnav&gt;è´´å§&lt;/a&gt; &lt;noscript&gt; &lt;a href=http://www.baidu.com/bdorz/login.gif?login&amp;amp;tpl=mn&amp;amp;u=http%3A%2F%2Fwww.baidu.com%2f%3fbdorz_come%3d1 name=tj_login class=lb&gt;ç»å½&lt;/a&gt; &lt;/noscript&gt; &lt;script&gt;document.write(&apos;&lt;a href=&quot;http://www.baidu.com/bdorz/login.gif?login&amp;tpl=mn&amp;u=&apos;+ encodeURIComponent(window.location.href+ (window.location.search === &quot;&quot; ? &quot;?&quot; : &quot;&amp;&quot;)+ &quot;bdorz_come=1&quot;)+ &apos;&quot; name=&quot;tj_login&quot; class=&quot;lb&quot;&gt;ç»å½&lt;/a&gt;&apos;);&lt;/script&gt; &lt;a href=//www.baidu.com/more/ name=tj_briicon class=bri style=&quot;display: block;&quot;&gt;æ´å¤äº§å&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=ftCon&gt; &lt;div id=ftConw&gt; &lt;p id=lh&gt; &lt;a href=http://home.baidu.com&gt;å³äºç¾åº¦&lt;/a&gt; &lt;a href=http://ir.baidu.com&gt;About Baidu&lt;/a&gt; &lt;/p&gt; &lt;p id=cp&gt;&amp;copy;2017&amp;nbsp;Baidu&amp;nbsp;&lt;a href=http://www.baidu.com/duty/&gt;ä½¿ç¨ç¾åº¦åå¿è¯»&lt;/a&gt;&amp;nbsp; &lt;a href=http://jianyi.baidu.com/ class=cp-feedback&gt;æè§åé¦&lt;/a&gt;&amp;nbsp;äº¬ICPè¯030173å·&amp;nbsp; &lt;img src=//www.baidu.com/img/gs.gif&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; 获取源码并解码源码是有了，但是中文变成了乱码。该网页用的是utf-8，所以还要指定编码名。这样程序才知道用什么编码来解码并展示出来。正确的解码才能获取到我们想要的内容。所以代码变成了下面的样子。 1234import requestsres = requests.get(&apos;http://www.baidu.com&apos;)res.encoding=&apos;utf-8&apos;print res.text 结果如下： 12&lt;!DOCTYPE html&gt;&lt;!--STATUS OK--&gt;&lt;html&gt; &lt;head&gt;&lt;meta http-equiv=content-type content=text/html;charset=utf-8&gt;&lt;meta http-equiv=X-UA-Compatible content=IE=Edge&gt;&lt;meta content=always name=referrer&gt;&lt;link rel=stylesheet type=text/css href=http://s1.bdstatic.com/r/www/cache/bdorz/baidu.min.css&gt;&lt;title&gt;百度一下，你就知道&lt;/title&gt;&lt;/head&gt; &lt;body link=#0000cc&gt; &lt;div id=wrapper&gt; &lt;div id=head&gt; &lt;div class=head_wrapper&gt; &lt;div class=s_form&gt; &lt;div class=s_form_wrapper&gt; &lt;div id=lg&gt; &lt;img hidefocus=true src=//www.baidu.com/img/bd_logo1.png width=270 height=129&gt; &lt;/div&gt; &lt;form id=form name=f action=//www.baidu.com/s class=fm&gt; &lt;input type=hidden name=bdorz_come value=1&gt; &lt;input type=hidden name=ie value=utf-8&gt; &lt;input type=hidden name=f value=8&gt; &lt;input type=hidden name=rsv_bp value=1&gt; &lt;input type=hidden name=rsv_idx value=1&gt; &lt;input type=hidden name=tn value=baidu&gt;&lt;span class=&quot;bg s_ipt_wr&quot;&gt;&lt;input id=kw name=wd class=s_ipt value maxlength=255 autocomplete=off autofocus&gt;&lt;/span&gt;&lt;span class=&quot;bg s_btn_wr&quot;&gt;&lt;input type=submit id=su value=百度一下 class=&quot;bg s_btn&quot;&gt;&lt;/span&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=u1&gt; &lt;a href=http://news.baidu.com name=tj_trnews class=mnav&gt;新闻&lt;/a&gt; &lt;a href=http://www.hao123.com name=tj_trhao123 class=mnav&gt;hao123&lt;/a&gt; &lt;a href=http://map.baidu.com name=tj_trmap class=mnav&gt;地图&lt;/a&gt; &lt;a href=http://v.baidu.com name=tj_trvideo class=mnav&gt;视频&lt;/a&gt; &lt;a href=http://tieba.baidu.com name=tj_trtieba class=mnav&gt;贴吧&lt;/a&gt; &lt;noscript&gt; &lt;a href=http://www.baidu.com/bdorz/login.gif?login&amp;amp;tpl=mn&amp;amp;u=http%3A%2F%2Fwww.baidu.com%2f%3fbdorz_come%3d1 name=tj_login class=lb&gt;登录&lt;/a&gt; &lt;/noscript&gt; &lt;script&gt;document.write(&apos;&lt;a href=&quot;http://www.baidu.com/bdorz/login.gif?login&amp;tpl=mn&amp;u=&apos;+ encodeURIComponent(window.location.href+ (window.location.search === &quot;&quot; ? &quot;?&quot; : &quot;&amp;&quot;)+ &quot;bdorz_come=1&quot;)+ &apos;&quot; name=&quot;tj_login&quot; class=&quot;lb&quot;&gt;登录&lt;/a&gt;&apos;);&lt;/script&gt; &lt;a href=//www.baidu.com/more/ name=tj_briicon class=bri style=&quot;display: block;&quot;&gt;更多产品&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=ftCon&gt; &lt;div id=ftConw&gt; &lt;p id=lh&gt; &lt;a href=http://home.baidu.com&gt;关于百度&lt;/a&gt; &lt;a href=http://ir.baidu.com&gt;About Baidu&lt;/a&gt; &lt;/p&gt; &lt;p id=cp&gt;&amp;copy;2017&amp;nbsp;Baidu&amp;nbsp;&lt;a href=http://www.baidu.com/duty/&gt;使用百度前必读&lt;/a&gt;&amp;nbsp; &lt;a href=http://jianyi.baidu.com/ class=cp-feedback&gt;意见反馈&lt;/a&gt;&amp;nbsp;京ICP证030173号&amp;nbsp; &lt;img src=//www.baidu.com/img/gs.gif&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; 这下总算能看到中文了。 封装成一个函数为了提高复用性，所以打算把它封装成一个函数，比如get_web_source，这样以后获取不同的url,和编码,将其作为参数传入就能正确获取源码了。所以我把它写成了这个样子。 12345678910import requests# 定义函数def get_web_source(url,encode=&quot;utf-8&quot;): res = requests.get(url) res.encoding = encode return res.text # 测试函数 打印出源码，第二个参数我默认填的是utf8，所以我不写。如果是GBK、GB2313或者其它的再填第二个参数。print get_web_source(&apos;http://www.baidu.com&apos;) 结果如下：12&lt;!DOCTYPE html&gt;&lt;!--STATUS OK--&gt;&lt;html&gt; &lt;head&gt;&lt;meta http-equiv=content-type content=text/html;charset=utf-8&gt;&lt;meta http-equiv=X-UA-Compatible content=IE=Edge&gt;&lt;meta content=always name=referrer&gt;&lt;link rel=stylesheet type=text/css href=http://s1.bdstatic.com/r/www/cache/bdorz/baidu.min.css&gt;&lt;title&gt;百度一下，你就知道&lt;/title&gt;&lt;/head&gt; &lt;body link=#0000cc&gt; &lt;div id=wrapper&gt; &lt;div id=head&gt; &lt;div class=head_wrapper&gt; &lt;div class=s_form&gt; &lt;div class=s_form_wrapper&gt; &lt;div id=lg&gt; &lt;img hidefocus=true src=//www.baidu.com/img/bd_logo1.png width=270 height=129&gt; &lt;/div&gt; &lt;form id=form name=f action=//www.baidu.com/s class=fm&gt; &lt;input type=hidden name=bdorz_come value=1&gt; &lt;input type=hidden name=ie value=utf-8&gt; &lt;input type=hidden name=f value=8&gt; &lt;input type=hidden name=rsv_bp value=1&gt; &lt;input type=hidden name=rsv_idx value=1&gt; &lt;input type=hidden name=tn value=baidu&gt;&lt;span class=&quot;bg s_ipt_wr&quot;&gt;&lt;input id=kw name=wd class=s_ipt value maxlength=255 autocomplete=off autofocus&gt;&lt;/span&gt;&lt;span class=&quot;bg s_btn_wr&quot;&gt;&lt;input type=submit id=su value=百度一下 class=&quot;bg s_btn&quot;&gt;&lt;/span&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=u1&gt; &lt;a href=http://news.baidu.com name=tj_trnews class=mnav&gt;新闻&lt;/a&gt; &lt;a href=http://www.hao123.com name=tj_trhao123 class=mnav&gt;hao123&lt;/a&gt; &lt;a href=http://map.baidu.com name=tj_trmap class=mnav&gt;地图&lt;/a&gt; &lt;a href=http://v.baidu.com name=tj_trvideo class=mnav&gt;视频&lt;/a&gt; &lt;a href=http://tieba.baidu.com name=tj_trtieba class=mnav&gt;贴吧&lt;/a&gt; &lt;noscript&gt; &lt;a href=http://www.baidu.com/bdorz/login.gif?login&amp;amp;tpl=mn&amp;amp;u=http%3A%2F%2Fwww.baidu.com%2f%3fbdorz_come%3d1 name=tj_login class=lb&gt;登录&lt;/a&gt; &lt;/noscript&gt; &lt;script&gt;document.write(&apos;&lt;a href=&quot;http://www.baidu.com/bdorz/login.gif?login&amp;tpl=mn&amp;u=&apos;+ encodeURIComponent(window.location.href+ (window.location.search === &quot;&quot; ? &quot;?&quot; : &quot;&amp;&quot;)+ &quot;bdorz_come=1&quot;)+ &apos;&quot; name=&quot;tj_login&quot; class=&quot;lb&quot;&gt;登录&lt;/a&gt;&apos;);&lt;/script&gt; &lt;a href=//www.baidu.com/more/ name=tj_briicon class=bri style=&quot;display: block;&quot;&gt;更多产品&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=ftCon&gt; &lt;div id=ftConw&gt; &lt;p id=lh&gt; &lt;a href=http://home.baidu.com&gt;关于百度&lt;/a&gt; &lt;a href=http://ir.baidu.com&gt;About Baidu&lt;/a&gt; &lt;/p&gt; &lt;p id=cp&gt;&amp;copy;2017&amp;nbsp;Baidu&amp;nbsp;&lt;a href=http://www.baidu.com/duty/&gt;使用百度前必读&lt;/a&gt;&amp;nbsp; &lt;a href=http://jianyi.baidu.com/ class=cp-feedback&gt;意见反馈&lt;/a&gt;&amp;nbsp;京ICP证030173号&amp;nbsp; &lt;img src=//www.baidu.com/img/gs.gif&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; 结果正确，收工！ 参考资料 Requests 2.10.0 文档]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>spider</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MathJax Test]]></title>
    <url>%2Farticle%2F20170120%2FMathJax-Test%2F</url>
    <content type="text"><![CDATA[$f(\sqrt{x}+1)=x+2\sqrt{x}$ 求 $f(x)$ 的解析式 换元法： 设 $t=\sqrt{x}+1$ ，则 $x=(t-1)^2$ ，且 ( $x\geq1$ ) $f(t)=(t-1)^2+2(t-1)=t^2-1$ $(t \geq 1)$ $f(x)=x^2-1$ $( x\geq 1 )$ 来源Markdown 公式指导手册 Special Symbols]]></content>
      <categories>
        <category>test</category>
      </categories>
      <tags>
        <tag>test</tag>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[It's You - Pari B 歌词]]></title>
    <url>%2Farticle%2F20170119%2Fits-you-lyric%2F</url>
    <content type="text"><![CDATA[前言It’s You的歌词算是首发吧，早在11还是10年我就问作者Sodeep Lama拿到了歌词。也发过在自己的QQ空间，不过后来QQ空间限制访问了。也没什么人能看到，也达不到共享的目的。直到今日，迷上了网易云音乐，想为它做点什么。恰好发现这首歌还没有歌词，就整理了一份歌词上传了上去。昨天刚刚通过审核。 歌词123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354[ti:It&apos;S You][ar:Pari B][lr:Pari B][by:YinYongYou][00:03.24]Girl I&apos;m just thinkin&apos; about you[00:06.30]fantasizin&apos;, memorizin&apos; moments you spended with me (yeah)[00:12.10]Girl I know thing can change[00:15.10]about me lately got me thinking[00:18.10]Nomatter what we&apos;re meant to be[00:19.30]You like my superstar( Your name on my guitar )[00:24.10]You&apos;re my celebrity( Your picture on my wall )[00:29.40]Just the way you are ( I love it how you are )[00:33.20]You and me ,meant to be, you should see[00:38.01]Girl it&apos;s you you you you you[00:42.10]Who changed my heart turn old into new[00:46.05]Girl it&apos;s you you you you[00:50.00]Who changed my life love story true[00:50.00]Hold up for a second how can I thank god[00:59.00]sending me this angel from above[01:03.30]You&apos;re so so perfect to crash in my life[01:08.10]Shawty you appear every night[01:11.10]Your body&apos;s calling me[01:13.40]Don&apos;t worry I&apos;ll be there girl[01:16:40]I&apos;m all yours shawty you should know[01:20.10]Don&apos;t be scared girl I ain&apos;t gonna hurt you[01:25.10]Gently , let me lead you[01:29.01]Girl it&apos;s you you you you you[01:33.10]Who changed my heart turn old into new[01:37.05]Girl it&apos;s you you you you[01:42.00]Who changed my life love story true[01:47.00]Shawty you&apos;re my dime love suffocate[01:49.00]But I&apos;ll give you my time[01:51.00]Yah girl let me intrest you[01:53.00]We equal better math when me plus you[01:55.10]Let me hold you girl I need your presence here[01:57.10]from this whole wide world[01:59.00]I can live without money anything[02:02.00]But how I can live without you[02:04.10]Girl I know I make mistakes[02:06.10]and I&apos;ll make you mine whateva it takes[02:07.10]and it hurts you the most but it hurts me too[02:09.10]When you are mad and sad baby give me a clue so[02:11.40]Let&apos;s forget about the past you and me[02:12.40]Let&apos;s make this last fasten[02:14.10]Seat belt girl you ready ready ready[02:20.00]Roger that[02:21.01]Girl it&apos;s you you you you you[02:24.10]Who changed my heart turn old into new[02:29.05]Girl it&apos;s you you you you[02:32.00]Who changed my life love story true[02:37.01]Girl it&apos;s you you you you you[02:42.10]Who changed my heart turn old into new[02:46.05]Girl it&apos;s you you you you[02:50.00]Who changed my life love story true 感谢 Sodeep Lama 手打的歌词 郑晓昕 同学的帮忙整理]]></content>
      <categories>
        <category>music</category>
      </categories>
      <tags>
        <tag>music</tag>
        <tag>lyric</tag>
      </tags>
  </entry>
</search>
